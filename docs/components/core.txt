# captured_at: 2026-01-04T12:52:14.741269+00:00

# core/__init__.py


# core/agents/__init__.py


# core/agents/base.py
# core/agents/base.py
# ==============================
# Base Agent Contract
# ==============================
"""
Base agent contract for master/.

Non-negotiable rules (master v1+):
- Agents are GOAL-DRIVEN (not prompt-driven). Apart from minimal foundational system
  instructions at the platform level, agents must not rely on prompts for behavior.
- Agents do NOT call tools directly. They may REQUEST tool usage through orchestrator
  mechanisms (e.g., returning structured tool requests in AgentResult), which are executed
  only via core/tools/executor.py.
- Agents do NOT persist state. They can read/write only to the orchestrator-managed
  artifacts/state provided via StepContext (ephemeral) and emit trace events via hooks.
- Agents do NOT read environment variables. Configuration is injected by the caller.

Interface:
- run(step_context) -> AgentResult (standard envelope in core/contracts/agent_schema.py)

Notes:
- Concrete agents MUST provide a stable `name` used in flows.
- Concrete agents MUST return structured outputs (Pydantic models via AgentResult.data).
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional

from core.contracts.agent_schema import AgentResult
from core.orchestrator.context import StepContext


class BaseAgent(ABC):
    """
    Base class for all agents (core + products).

    Naming:
        Each concrete agent must provide a stable 'name' used in flows and registries.
        Prefer namespaced names like '{product}.{agent_name}' to avoid collisions.
    """

    name: str

    def __init__(self, *, config: Optional[Dict[str, Any]] = None) -> None:
        # config is injected (e.g., from product.yaml / settings) and must not be sourced
        # from env vars directly inside agents.
        self.config: Dict[str, Any] = config or {}

    @abstractmethod
    def run(self, step_context: StepContext) -> AgentResult:
        """
        Execute the agent for a single orchestrated step.

        step_context typically provides:
        - run metadata (run_id, product, flow)
        - step definition (what is expected in this step)
        - artifacts/state (shared ephemeral state for the run)
        - trace hook(s) (emit structured trace events)

        Contract:
        - Must return an AgentResult envelope (ok/data/error/meta).
        - Must NOT raise raw exceptions outward; handle and wrap in AgentResult.error.
        - Must NOT call tools directly; request tool usage via structured outputs.
        """
        raise NotImplementedError

# core/agents/llm_reasoner.py
# ==============================
# Core LLM Reasoner Agent
# ==============================
from __future__ import annotations

from typing import Any, Dict, List, Optional
import json

from pydantic import BaseModel, Field, ConfigDict, ValidationError

from core.agents.base import BaseAgent
from core.config.loader import load_settings
from core.contracts.agent_schema import AgentError, AgentErrorCode, AgentMeta, AgentResult, AgentKind
from core.contracts.reasoning_schema import ReasoningPurpose
from core.governance.hooks import GovernanceHooks
from ..models.providers.openai_provider import OpenAIRequest
from ..models.router import ModelRouter
from core.orchestrator.context import StepContext
from core.orchestrator.templating import render_messages


class LlmReasonerParams(BaseModel):
    model_config = ConfigDict(extra="forbid")

    purpose: ReasoningPurpose = Field(..., description="Required reasoning purpose for model selection.")
    system: Optional[str] = Field(default=None, description="System instruction for the model.")
    prompt: Optional[str] = Field(default=None, description="Primary user instruction.")
    messages: List[Dict[str, Any]] = Field(default_factory=list, description="Optional pre-built message list.")
    temperature: float = Field(default=0.2)
    max_tokens: Optional[int] = Field(default=None)
    override_model: Optional[str] = Field(default=None)


class LlmReasoner(BaseAgent):
    """
    Core generic LLM agent.

    Responsibilities:
    - Build model request from params + run context
    - Enforce governance hooks (model allow/deny + token budget)
    - Emit trace events for model calls
    - Return structured AgentResult
    """

    name: str = "llm_reasoner"
    description: str = "Core LLM reasoning agent with governance + tracing."

    def run(self, step_context: StepContext) -> AgentResult:
        meta = AgentMeta(
            agent_name=self.name,
            kind=AgentKind.OTHER,
            tags={"product": step_context.product, "flow": step_context.flow},
        )
        try:
            params = LlmReasonerParams.model_validate(step_context.step.params or {})
            context = {
                "artifacts": step_context.run.artifacts,
                "payload": step_context.run.payload,
            }
            messages = self._build_messages(params)
            try:
                messages = render_messages(messages, context)
            except KeyError as exc:
                err = AgentError(code=AgentErrorCode.INVALID_INPUT, message=str(exc))
                return AgentResult(ok=False, data=None, error=err, meta=meta)
            settings = load_settings()
            governance = GovernanceHooks(settings=settings)
            router = ModelRouter.from_settings(settings)

            # Pre-flight governance decision
            model_name = router.select(product=step_context.product, purpose=params.purpose, override_model=params.override_model).model
            decision = governance.before_model_call(
                model_name=model_name,
                purpose=params.purpose,
                messages={"messages": messages},
                max_tokens=params.max_tokens,
                ctx=step_context,
            )
            step_context.emit(
                "model_call_attempt_started",
                {
                    "model": model_name,
                    "purpose": params.purpose.value,
                    "allowed": decision.allowed,
                    "reason": decision.reason,
                },
            )
            if not decision.allowed:
                err = AgentError(code=AgentErrorCode.POLICY_BLOCKED, message=decision.reason, details=decision.details)
                meta.redacted = True
                return AgentResult(ok=False, data=None, error=err, meta=meta)

            req = OpenAIRequest(
                model=model_name,
                messages=messages,
                temperature=params.temperature,
                max_tokens=params.max_tokens,
                metadata={
                    "product": step_context.product,
                    "flow": step_context.flow,
                    "step_id": step_context.step_id,
                    "reasoning_purpose": params.purpose.value,
                },
            )
            resp = router.completion_openai(
                request=req,
                product=step_context.product,
                purpose=params.purpose,
                override_model=params.override_model,
            )
            if not resp.ok:
                message = ""
                if resp.error and isinstance(resp.error, dict):
                    message = str(resp.error.get("message") or "")
                if not message:
                    message = "model_error"
                err = AgentError(code=AgentErrorCode.MODEL_ERROR, message=message, details=resp.error or {})
                step_context.emit(
                    "model_call_failed",
                    {
                        "model": model_name,
                        "purpose": params.purpose.value,
                        "reason": err.message,
                        "error": resp.error or {},
                    },
                )
                return AgentResult(ok=False, data=None, error=err, meta=meta)

            usage = resp.usage or {}
            meta.token_estimate = usage.get("total_tokens")
            tokens_used = usage.get("total_tokens")
            if tokens_used is None:
                tokens_used = params.max_tokens or 0
            try:
                tokens_used_int = int(tokens_used)
            except Exception:
                tokens_used_int = 0
            run_tokens = int(step_context.run.meta.get("tokens_used", 0))
            run_tokens += tokens_used_int
            step_context.run.meta["tokens_used"] = run_tokens
            run_budget = governance.settings.policies.max_tokens_per_run
            if run_budget is not None and run_tokens > run_budget:
                step_context.emit(
                    "model_call_budget_exceeded",
                    {
                        "model": resp.model,
                        "purpose": params.purpose.value,
                        "used": run_tokens,
                        "limit": run_budget,
                    },
                )
                err = AgentError(
                    code=AgentErrorCode.POLICY_BLOCKED,
                    message="run_token_budget_exceeded",
                    details={"used": run_tokens, "limit": run_budget},
                )
                meta.redacted = True
                return AgentResult(ok=False, data=None, error=err, meta=meta)
            step_context.emit(
                "model_call_succeeded",
                {
                    "model": resp.model,
                    "purpose": params.purpose.value,
                    "usage": usage,
                    "provider": resp.meta.get("provider") if isinstance(resp.meta, dict) else None,
                },
            )
            data = {
                "content": resp.content,
                "model": resp.model,
                "usage": usage,
                "provider": resp.meta.get("provider") if isinstance(resp.meta, dict) else None,
            }
            return AgentResult(ok=True, data=data, error=None, meta=meta)
        except ValidationError as exc:
            err = AgentError(code=AgentErrorCode.INVALID_INPUT, message="invalid_llm_reasoner_params", details=exc.errors())
            return AgentResult(ok=False, data=None, error=err, meta=meta)
        except Exception as exc:
            err = AgentError(code=AgentErrorCode.UNKNOWN, message=str(exc))
            return AgentResult(ok=False, data=None, error=err, meta=meta)

    @staticmethod
    def _build_messages(params: LlmReasonerParams) -> List[Dict[str, Any]]:
        if params.messages:
            return params.messages
        messages: List[Dict[str, Any]] = []
        if params.system:
            messages.append({"role": "system", "content": params.system})
        if params.prompt:
            messages.append({"role": "user", "content": params.prompt})
        return messages


def build() -> LlmReasoner:
    return LlmReasoner()


class RoleReasonerParams(BaseModel):
    model_config = ConfigDict(extra="forbid")

    prompt: str
    temperature: float = Field(default=0.2)
    max_tokens: Optional[int] = Field(default=None)
    override_model: Optional[str] = Field(default=None)


class InsightReasonerOutput(BaseModel):
    model_config = ConfigDict(extra="forbid")

    summary: str
    highlights: List[str] = Field(default_factory=list)
    risks: List[str] = Field(default_factory=list)


class PrioritizedItem(BaseModel):
    model_config = ConfigDict(extra="forbid")

    item: str
    priority: int
    rationale: str


class PrioritizationReasonerOutput(BaseModel):
    model_config = ConfigDict(extra="forbid")

    priorities: List[PrioritizedItem]


class ExplanationReasonerOutput(BaseModel):
    model_config = ConfigDict(extra="forbid")

    explanation: str
    assumptions: List[str] = Field(default_factory=list)
    limitations: List[str] = Field(default_factory=list)


class _RoleReasoner(BaseAgent):
    name: str = "role_reasoner"
    purpose: ReasoningPurpose = ReasoningPurpose.EXPLANATION
    output_model: type[BaseModel]

    def run(self, step_context: StepContext) -> AgentResult:
        meta = AgentMeta(
            agent_name=self.name,
            kind=AgentKind.OTHER,
            tags={"product": step_context.product, "flow": step_context.flow},
        )
        try:
            if not step_context.step:
                raise ValueError("missing_step_definition")
            params = RoleReasonerParams.model_validate(step_context.step.params or {})
            llm_params = LlmReasonerParams(
                purpose=self.purpose,
                system=self._system_prompt(),
                prompt=params.prompt,
                temperature=params.temperature,
                max_tokens=params.max_tokens,
                override_model=params.override_model,
            )
            updated_step = step_context.step.model_copy(update={"params": llm_params.model_dump(mode="json")})
            llm_ctx = step_context.run.new_step(step_def=updated_step)
            llm_result = LlmReasoner().run(llm_ctx)
            if not llm_result.ok:
                return llm_result
            content = (llm_result.data or {}).get("content")
            payload = _parse_json_payload(content)
            output = self.output_model.model_validate(payload)
            meta = llm_result.meta.model_copy(update={"agent_name": self.name})
            return AgentResult(ok=True, data=output.model_dump(mode="json"), error=None, meta=meta)
        except Exception as exc:
            err = AgentError(code=AgentErrorCode.CONTRACT_VIOLATION, message=str(exc))
            return AgentResult(ok=False, data=None, error=err, meta=meta)

    def _system_prompt(self) -> str:
        fields = list(getattr(self.output_model, "model_fields", {}).keys())
        return f"Return JSON only with keys: {', '.join(fields)}."


class InsightReasoner(_RoleReasoner):
    name = "insight_reasoner"
    purpose = ReasoningPurpose.INSIGHT
    output_model = InsightReasonerOutput


class PrioritizationReasoner(_RoleReasoner):
    name = "prioritization_reasoner"
    purpose = ReasoningPurpose.PRIORITIZATION
    output_model = PrioritizationReasonerOutput


class ExplanationReasoner(_RoleReasoner):
    name = "explanation_reasoner"
    purpose = ReasoningPurpose.EXPLANATION
    output_model = ExplanationReasonerOutput


def build_insight_reasoner() -> InsightReasoner:
    return InsightReasoner()


def build_prioritization_reasoner() -> PrioritizationReasoner:
    return PrioritizationReasoner()


def build_explanation_reasoner() -> ExplanationReasoner:
    return ExplanationReasoner()


def _parse_json_payload(content: Any) -> Dict[str, Any]:
    if isinstance(content, dict):
        return content
    if isinstance(content, str):
        try:
            return json.loads(content)
        except Exception as exc:
            raise ValueError("invalid_json_output") from exc
    raise ValueError("missing_json_output")

# core/agents/registry.py
# ==============================
# Agent Registry
# ==============================
"""
Global agent registry.

    Design:
    - Registry stores name -> agent factory (no shared instances)
- Products can register their agents during boot (gateway startup, or product loader)
- Resolution is by string name used in StepDef.agent
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional

from core.agents.base import BaseAgent
from core.agents.llm_reasoner import (
    build as build_llm_reasoner,
    build_explanation_reasoner,
    build_insight_reasoner,
    build_prioritization_reasoner,
)


AgentFactory = Callable[[], BaseAgent]


@dataclass(frozen=True)
class AgentRegistration:
    name: str
    factory: AgentFactory
    meta: Dict[str, Any]


class AgentRegistry:
    """
    Simple global registry used by orchestrator + products.

    The registry stores factories to ensure every resolution gets a fresh instance.
    Tests/products interact via classmethods to avoid passing registry handles around.
    """

    _agents: Dict[str, AgentRegistration] = {}

    @classmethod
    def clear(cls) -> None:
        cls._agents.clear()
        global _CORE_REGISTERED
        _CORE_REGISTERED = False

    @classmethod
    def register(
        cls,
        name: str,
        factory: AgentFactory | BaseAgent,
        *,
        meta: Optional[Dict[str, Any]] = None,
        overwrite: bool = False,
    ) -> None:
        norm = _norm(name)
        if not overwrite and norm in cls._agents:
            raise ValueError(f"Agent already registered: {name}")

        if isinstance(factory, BaseAgent):
            raise ValueError("AgentRegistry.register requires a factory to avoid shared state across runs.")
        actual_factory = factory

        cls._agents[norm] = AgentRegistration(name=norm, factory=actual_factory, meta=meta or {})

    @classmethod
    def resolve(cls, name: str) -> BaseAgent:
        _register_core_agents()
        norm = _norm(name)
        reg = cls._agents.get(norm)
        if reg is None:
            raise KeyError(f"Unknown agent: {name}")
        return reg.factory()

    @classmethod
    def has(cls, name: str) -> bool:
        _register_core_agents()
        return _norm(name) in cls._agents

    @classmethod
    def list(cls) -> Dict[str, Dict[str, Any]]:
        _register_core_agents()
        return {k: {"name": v.name, "meta": v.meta} for k, v in cls._agents.items()}


def _norm(name: str) -> str:
    return name.strip().lower().replace(" ", "_")


_CORE_REGISTERED = False


def _register_core_agents() -> None:
    global _CORE_REGISTERED
    if _CORE_REGISTERED:
        return
    for factory in (
        build_llm_reasoner,
        build_insight_reasoner,
        build_prioritization_reasoner,
        build_explanation_reasoner,
    ):
        name = _norm(factory().name)
        if name not in AgentRegistry._agents:
            AgentRegistry.register(name, factory)
    _CORE_REGISTERED = True

# core/config/__init__.py


# core/config/loader.py
# ==============================
# Config Loader (only env reader)
# ==============================
"""
Config loader for master/.

Rules:
- This is the ONLY place allowed to read os.environ and .env.
- This is the ONLY place allowed to read secrets/secrets.yaml.
- Everything else receives a validated Settings object.

Precedence:
env > secrets/secrets.yaml > configs/*.yaml > defaults

Testability:
- All functions accept injected paths and env dict.
- No hardcoded absolute paths.
"""

# High-level load flow:
# 1. Determine paths and environment variables (env, .env).
# 2. Load base YAML configs from configs/ directory.
# 3. Load secrets from secrets.yaml if present.
# 4. Load .env file and merge into environment variables without overriding real env.
# 5. Apply env var overrides with MASTER__ prefix to merged config.
# 6. Inject repo_root path into config to ensure deterministic path.
# 7. Validate merged config against pydantic Settings schema.
# 8. Hydrate provider secrets into models config respecting precedence.
# 9. Return validated Settings object (and optionally raw merged dict).


from __future__ import annotations

import os
import logging
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import yaml
from pydantic import ValidationError

from core.config.schema import Settings


# ==============================
# YAML Helpers
# ==============================


def _read_yaml(path: Path) -> Dict[str, Any]:
    # Return empty dict if file does not exist
    if not path.exists():
        return {}
    raw = path.read_text(encoding="utf-8").strip()
    # Return empty dict if file is empty or whitespace only
    if not raw:
        return {}
    data = yaml.safe_load(raw)
    # Guard against non-dict YAML content, return empty dict if not a dict
    return data if isinstance(data, dict) else {}


def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    """
    Deep-merge dictionaries: override wins.

    Recursively merges nested dicts, with values from 'override' taking precedence.
    """
    out: Dict[str, Any] = dict(base)
    for k, v in override.items():
        if k in out and isinstance(out[k], dict) and isinstance(v, dict):
            # Recursively merge nested dictionaries
            out[k] = _deep_merge(out[k], v)
        else:
            # Override scalar or non-dict values
            out[k] = v
    return out


def _section(data: Dict[str, Any], key: str) -> Dict[str, Any]:
    """
    Config files may either namespace their contents (app: {...}) or provide the
    raw fields directly. Normalize to the inner dict for merging.

    This supports legacy configs that either wrap all settings under a top-level key
    or flatten them at the root level.
    """
    value = data.get(key)
    if isinstance(value, dict):
        return value
    # If no top-level key or not a dict, assume data is already the inner dict
    return data


def _normalize_app_config(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Legacy configs used `name/environment/default_timeout_seconds`. Map/strip them.

    This function normalizes old config keys to current expected keys and removes deprecated ones.
    """
    out = dict(data)
    if "environment" in out and "env" not in out:
        out["env"] = out["environment"]
    # Remove deprecated keys
    out.pop("environment", None)
    out.pop("name", None)
    out.pop("default_timeout_seconds", None)
    return out


# ==============================
# .env Loader
# ==============================


def _read_dotenv(dotenv_path: Path) -> Dict[str, str]:
    """
    Minimal .env parser (KEY=VALUE).
    - Ignores comments and blank lines.
    - Strips surrounding quotes.

    Prefer python-dotenv if available; fallback to a minimal parser.
    """
    if not dotenv_path.exists():
        return {}
    try:
        from dotenv import dotenv_values  # type: ignore

        values = dotenv_values(dotenv_path)
        return {k: v for k, v in values.items() if isinstance(k, str) and isinstance(v, str)}
    except Exception:
        envs: Dict[str, str] = {}
        for line in dotenv_path.read_text(encoding="utf-8").splitlines():
            s = line.strip()
            if not s or s.startswith("#") or "=" not in s:
                continue
            key, val = s.split("=", 1)
            key = key.strip()
            val = val.strip().strip('"').strip("'")
            if key:
                envs[key] = val
        return envs


def _apply_env_overrides(cfg: Dict[str, Any], env: Dict[str, str]) -> Dict[str, Any]:
    """
    Apply environment overrides with MASTER__ style nesting.

Example:
  MASTER__APP__DEBUG=true
  MASTER__APP__PORT=8001
  MASTER__MODELS__OPENAI__API_KEY=...
  MASTER__SECRETS__OPENAI_API_KEY=...

Rules:
- Split by '__' after prefix MASTER__
- Lowercase keys for dict insertion
- Coerce booleans/ints/floats when obvious

The MASTER__ prefix is chosen to clearly namespace overrides for this application,
avoiding collisions with other env vars.

Lowercasing keys ensures consistent dict keys regardless of env var casing.

Coercion attempts to convert strings to bool/int/float for convenience.
    """
    out = dict(cfg)
    prefix = "MASTER__"

    def coerce(v: str) -> Any:
        vs = v.strip()
        if vs.lower() in {"true", "false"}:
            return vs.lower() == "true"
        # int
        try:
            if vs.isdigit() or (vs.startswith("-") and vs[1:].isdigit()):
                return int(vs)
        except Exception:
            pass
        # float
        try:
            if "." in vs:
                return float(vs)
        except Exception:
            pass
        return vs

    for k, v in env.items():
        if not k.startswith(prefix):
            continue
        path = k[len(prefix) :].split("__")
        if not path or any(not p for p in path):
            continue
        cur: Dict[str, Any] = out
        for i, seg in enumerate(path):
            key = seg.lower()
            if i == len(path) - 1:
                cur[key] = coerce(v)
            else:
                nxt = cur.get(key)
                if not isinstance(nxt, dict):
                    nxt = {}
                    cur[key] = nxt
                cur = nxt
    return out


def _is_hf_space_env(env: Dict[str, str]) -> bool:
    return "HF_HOME" in env or "SPACE_ID" in env


# ==============================
# Public Loader API
# ==============================


def load_settings(
    *,
    repo_root: Optional[str] = None,
    configs_dir: Optional[str] = None,
    secrets_file: Optional[str] = None,
    secrets_path: Optional[str] = None,
    dotenv_file: Optional[str] = None,
    env: Optional[Dict[str, str]] = None,
    include_raw: bool = False,
) -> Settings | Tuple[Settings, Dict[str, Any]]:
    """
    Load and validate Settings.

Returns:
- (Settings, merged_raw_dict)

Inputs:
- repo_root: defaults to current working directory
- configs_dir: defaults to <repo_root>/configs
- secrets_file: defaults to <repo_root>/secrets/secrets.yaml
- dotenv_file: defaults to <repo_root>/.env
- env: injected env vars (defaults to os.environ)
    """
    if secrets_file is not None and secrets_path is not None:
        raise ValueError("Provide only one of secrets_file or secrets_path.")

    def _resolve_base_path(base_path: Optional[str], fallback: Path) -> Path:
        if not base_path:
            return fallback
        base = Path(base_path).expanduser()
        if not base.is_absolute():
            base = (fallback / base).resolve()
        return base.resolve()

    # --- Environment variable resolution ---
    env_vars = dict(env) if env is not None else dict(os.environ)

    root = Path(repo_root or os.getcwd()).expanduser().resolve()
    root = _resolve_base_path(env_vars.get("APP_BASE_PATH"), root)

    # --- Load .env file and merge with env vars ---
    dotenv_path = Path(dotenv_file) if dotenv_file else (root / ".env")
    dotenv_vars = _read_dotenv(dotenv_path)
    effective_env = dict(env_vars)
    # .env should not override real env by default; real env wins
    for k, v in dotenv_vars.items():
        effective_env.setdefault(k, v)
    if "APP_BASE_PATH" not in env_vars and "APP_BASE_PATH" in dotenv_vars:
        root = _resolve_base_path(dotenv_vars.get("APP_BASE_PATH"), root)
        if dotenv_file is None:
            repo_dotenv_vars = _read_dotenv(root / ".env")
            for k, v in repo_dotenv_vars.items():
                effective_env.setdefault(k, v)

    cfg_dir = root / (configs_dir or "configs")

    # --- Load base config YAML files ---
    app_cfg = _read_yaml(cfg_dir / "app.yaml")
    models_cfg = _read_yaml(cfg_dir / "models.yaml")
    policies_cfg = _read_yaml(cfg_dir / "policies.yaml")
    logging_cfg = _read_yaml(cfg_dir / "logging.yaml")
    products_cfg = _read_yaml(cfg_dir / "products.yaml")

    merged: Dict[str, Any] = {}
    merged = _deep_merge(merged, {"app": _normalize_app_config(_section(app_cfg, "app"))})
    merged = _deep_merge(merged, {"models": _section(models_cfg, "models")})
    merged = _deep_merge(merged, {"policies": _section(policies_cfg, "policies")})
    merged = _deep_merge(merged, {"logging": _section(logging_cfg, "logging")})
    merged = _deep_merge(merged, {"products": _section(products_cfg, "products")})

    # --- Load secrets.yaml (optional) ---
    sec_path = Path(secrets_file or secrets_path) if (secrets_file or secrets_path) else (root / "secrets" / "secrets.yaml")
    secrets_cfg = _read_yaml(sec_path)
    merged = _deep_merge(merged, {"secrets": _section(secrets_cfg, "secrets")})

    if _is_hf_space_env(effective_env):
        # Hugging Face Spaces has an ephemeral filesystem; default to /data for persistence when unset.
        paths_cfg = (merged.get("app") or {}).get("paths") if isinstance(merged.get("app"), dict) else None
        storage_dir = paths_cfg.get("storage_dir") if isinstance(paths_cfg, dict) else None
        observability_dir = paths_cfg.get("observability_dir") if isinstance(paths_cfg, dict) else None
        if not storage_dir:
            merged = _deep_merge(merged, {"app": {"paths": {"storage_dir": "/data/storage"}}})
        if not observability_dir:
            merged = _deep_merge(merged, {"app": {"paths": {"observability_dir": "/data/observability"}}})

    # --- Apply MASTER__ env var overrides ---
    merged = _apply_env_overrides(merged, effective_env)

    # --- Resolve provider secret refs (non-MASTER env vars) ---
    merged = _hydrate_provider_refs(merged, effective_env)

    # --- Inject repo_root path to ensure deterministic path ---
    merged = _deep_merge(merged, {"app": {"paths": {"repo_root": str(root)}}})

    # --- Validate merged config against pydantic schema ---
    try:
        settings = Settings.model_validate(merged)
    except ValidationError as e:
        # raise with helpful context for debugging
        raise ValueError(f"Invalid configuration: {e}") from e

    # --- Hydrate provider secrets after validation ---
    # This happens after validation to avoid breaking precedence rules
    # and to ensure the final Settings object has secrets injected appropriately.
    settings = _hydrate_provider_secrets(settings)

    logger = logging.getLogger(__name__)
    logger.info("OpenAI API key resolved: %s", bool(settings.models.openai.api_key))

    if include_raw:
        return settings, merged
    return settings


def _hydrate_provider_refs(merged: Dict[str, Any], env: Dict[str, str]) -> Dict[str, Any]:
    def _get_dot(data: Dict[str, Any], path: str) -> Any:
        cur: Any = data
        for part in path.split("."):
            if not isinstance(cur, dict) or part not in cur:
                return None
            cur = cur[part]
        return cur

    def _resolve_secret(direct_key: str, ref_key: str) -> Optional[str]:
        direct = env.get(direct_key)
        if direct:
            return direct
        ref = env.get(ref_key)
        if not ref:
            return None
        secrets = merged.get("secrets", {}) or {}
        value = _get_dot(secrets, ref)
        return value

    openai_api_key = _resolve_secret("OPENAI_API_KEY", "OPENAI_API_KEY_REF")
    openai_org_id = _resolve_secret("OPENAI_ORG_ID", "OPENAI_ORG_ID_REF")

    models = merged.get("models", {}) or {}
    openai_cfg = models.get("openai", {}) or {}
    if openai_api_key is not None:
        openai_cfg.setdefault("api_key", openai_api_key)
    if openai_org_id is not None:
        openai_cfg.setdefault("org_id", openai_org_id)
    models["openai"] = openai_cfg
    merged["models"] = models
    return merged


def _hydrate_provider_secrets(settings: Settings) -> Settings:
    """
    Map secrets into provider configs without breaking precedence.

    This function injects secrets (like API keys) into the models config if they
    are not already set by higher-precedence sources (env vars or configs).

    It runs after validation to preserve the precedence and avoid validation errors.
    """
    data = settings.model_dump()
    secrets = data.get("secrets", {}) or {}
    models = data.get("models", {}) or {}
    openai = (models.get("openai", {}) or {}).copy()

    # Prefer explicit models.openai.api_key if already set
    if not openai.get("api_key"):
        if secrets.get("openai_api_key"):
            openai["api_key"] = secrets["openai_api_key"]
        elif isinstance(secrets.get("openai"), dict) and secrets["openai"].get("api_key"):
            openai["api_key"] = secrets["openai"]["api_key"]
    if not openai.get("org_id"):
        if isinstance(secrets.get("openai"), dict) and secrets["openai"].get("org_id"):
            openai["org_id"] = secrets["openai"]["org_id"]

    models["openai"] = openai
    data["models"] = models
    return Settings.model_validate(data)

# core/config/schema.py
# ==============================
# Config Schemas (Pydantic)
# ==============================
"""
Pydantic settings models for master/.

Notes:
- Keep these schemas stable: many modules will depend on them.
- No env reads here. No file IO here. Pure types + defaults.
- loader.py builds a single Settings object with precedence merging.

Precedence (implemented in loader.py):
env > secrets/secrets.yaml > configs/*.yaml > defaults
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, ConfigDict, Field


# ==============================
# App Settings
# ==============================


class PathsConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    repo_root: str = Field(default=".", description="Repo root (relative or absolute)")
    configs_dir: str = Field(default="configs", description="Configs directory")
    secrets_dir: str = Field(default="secrets", description="Secrets directory")
    storage_dir: str = Field(default="storage", description="Runtime storage directory")
    observability_dir: str = Field(default="observability", description="Observability output directory")


class AppConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    env: str = Field(default="local", description="Environment name (local/stage/prod)")
    debug: bool = Field(default=False)
    host: str = Field(default="0.0.0.0")
    port: int = Field(default=8000)
    default_product: str = Field(default="hello_world")
    default_flow: str = Field(default="hello_world")
    api_base_url: Optional[str] = Field(
        default=None,
        description="Base URL for Gateway API used by UI clients.",
    )
    paths: PathsConfig = Field(default_factory=PathsConfig)


# ==============================
# Models Settings
# ==============================


class OpenAIConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    api_base: Optional[str] = Field(default=None)
    api_key: Optional[str] = Field(default=None, description="Resolved via loader from env/secrets only")
    org_id: Optional[str] = Field(default=None, description="Optional OpenAI org id")
    timeout_seconds: float = Field(default=30.0)


class ModelRoutingConfig(BaseModel):
    model_config = ConfigDict(extra="allow")

    default_provider: str = Field(default="openai")
    default_model: str = Field(default="gpt-4o-mini")

    # Optional overrides
    by_product: Dict[str, Dict[str, Any]] = Field(default_factory=dict)
    by_purpose: Dict[str, Dict[str, Any]] = Field(default_factory=dict)


class ModelsConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    routing: ModelRoutingConfig = Field(default_factory=ModelRoutingConfig)
    openai: OpenAIConfig = Field(default_factory=OpenAIConfig)


# ==============================
# Policies / Governance Settings
# ==============================


class PoliciesConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    # High-level switches
    enforce: bool = Field(default=True)
    allow_full_autonomy: bool = Field(default=False)

    # Allow/deny lists (names resolved by registries)
    allowed_tools: List[str] = Field(default_factory=list)
    blocked_tools: List[str] = Field(default_factory=list)

    allowed_models: List[str] = Field(default_factory=list)
    blocked_models: List[str] = Field(default_factory=list)
    model_max_tokens: Optional[int] = Field(
        default=None,
        description="Optional hard ceiling for model max_tokens requests.",
    )
    max_tokens_per_run: Optional[int] = Field(
        default=None,
        description="Optional hard ceiling for total model tokens consumed per run.",
    )
    max_steps: Optional[int] = Field(
        default=None,
        description="Optional hard ceiling for total steps per run.",
    )
    max_tool_calls: Optional[int] = Field(
        default=None,
        description="Optional hard ceiling for tool calls per run.",
    )
    max_payload_bytes: Optional[int] = Field(
        default=None,
        description="Optional hard ceiling for run payload size in bytes.",
    )

    # Per-product policy overrides
    by_product: Dict[str, Dict[str, Any]] = Field(default_factory=dict)


# ==============================
# Logging / Observability Settings
# ==============================


class LoggingConfig(BaseModel):
    model_config = ConfigDict(extra="forbid", populate_by_name=True)

    level: str = Field(default="INFO")
    redact: bool = Field(default=True)
    redact_patterns: List[str] = Field(default_factory=list)
    trace_to_memory: bool = Field(default=True, description="Persist trace events via memory backend")
    console: bool = Field(default=True)


# ==============================
# Products Settings
# ==============================


class ProductsConfig(BaseModel):
    model_config = ConfigDict(extra="forbid")

    # Where products live (relative to repo_root)
    products_dir: str = Field(default="products")
    enabled: List[str] = Field(default_factory=list, description="Explicit allowlist of products to enable")
    auto_enable: bool = Field(
        default=True,
        description="If true and enabled list is empty, enable all discovered products automatically.",
    )


# ==============================
# Secrets Settings
# ==============================


class SecretsConfig(BaseModel):
    model_config = ConfigDict(extra="allow")

    # Common secret surfaces. Keep optional; loader fills.
    openai_api_key: Optional[str] = Field(default=None)
    memory_db_path: Optional[str] = Field(default=None)


# ==============================
# Top-Level Settings
# ==============================


class Settings(BaseModel):
    model_config = ConfigDict(extra="forbid")

    app: AppConfig = Field(default_factory=AppConfig)
    models: ModelsConfig = Field(default_factory=ModelsConfig)
    policies: PoliciesConfig = Field(default_factory=PoliciesConfig)
    logging: LoggingConfig = Field(default_factory=LoggingConfig)
    products: ProductsConfig = Field(default_factory=ProductsConfig)
    secrets: SecretsConfig = Field(default_factory=SecretsConfig)

    def repo_root_path(self) -> Path:
        return Path(self.app.paths.repo_root).expanduser().resolve()

# core/contracts/__init__.py


# core/contracts/agent_schema.py
# ==============================
# Agent Contracts
# ==============================
"""
Agent contracts for master/.

Agents are first-class reasoning units. They must return AgentEnvelope.
Agents do not execute tools directly. They may request tool actions via structured outputs.

Intended usage:
- Orchestrator invokes Agent.run(context) and expects AgentEnvelope
- Tracing uses AgentMeta + AgentError
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Dict, Generic, List, Optional, TypeVar
from uuid import uuid4

from pydantic import BaseModel, Field, ConfigDict, model_validator

# ==============================
# Typing
# ==============================
T = TypeVar("T")

CONTROL_FIELDS = frozenset(
    {
        "next_step",
        "retry",
        "retry_instructions",
        "branch",
        "branching",
        "branch_hint",
        "branching_hint",
    }
)


def find_control_fields(payload: Any) -> List[str]:
    violations: List[str] = []

    def _walk(value: Any, path: str) -> None:
        if isinstance(value, dict):
            for key, child in value.items():
                key_str = str(key)
                key_lower = key_str.lower()
                current = f"{path}{key_str}"
                if key_lower in CONTROL_FIELDS:
                    violations.append(current)
                _walk(child, f"{current}.")
        elif isinstance(value, list):
            for idx, child in enumerate(value):
                _walk(child, f"{path}[{idx}].")

    _walk(payload, "")
    return violations


def validate_agent_output_payload(payload: Any) -> None:
    if payload is None:
        return
    if not isinstance(payload, dict):
        raise ValueError("agent_output_not_object")
    violations = find_control_fields(payload)
    if violations:
        joined = ", ".join(violations)
        raise ValueError(f"agent_output_contains_control_fields: {joined}")


# ==============================
# Enums
# ==============================
class AgentKind(str, Enum):
    """High-level category for agents."""
    PLANNER = "planner"
    EXECUTOR = "executor"
    CRITIC = "critic"
    ROUTER = "router"
    SUMMARIZER = "summarizer"
    VALIDATOR = "validator"
    OTHER = "other"


class AgentErrorCode(str, Enum):
    """Standard error codes for agent failures."""
    INVALID_INPUT = "invalid_input"
    POLICY_BLOCKED = "policy_blocked"
    MODEL_ERROR = "model_error"
    TIMEOUT = "timeout"
    CONTRACT_VIOLATION = "contract_violation"
    UNKNOWN = "unknown"


# ==============================
# Models
# ==============================
class AgentMeta(BaseModel):
    """Metadata describing an agent run."""
    model_config = ConfigDict(extra="forbid")

    agent_name: str = Field(..., description="Registered agent name.")
    kind: AgentKind = Field(default=AgentKind.OTHER, description="Agent category.")
    request_id: str = Field(default_factory=lambda: str(uuid4()), description="Unique id for this agent call.")
    started_at: datetime = Field(default_factory=datetime.utcnow, description="Agent call start timestamp (UTC).")
    ended_at: Optional[datetime] = Field(default=None, description="Agent call end timestamp (UTC).")

    latency_ms: Optional[int] = Field(default=None, description="Measured latency in milliseconds.")
    token_estimate: Optional[int] = Field(default=None, description="Approx tokens used by agent/model calls.")
    cost_estimate: Optional[float] = Field(default=None, description="Approx cost estimate for this agent run.")

    tags: Dict[str, str] = Field(default_factory=dict, description="Arbitrary tags (product, flow, step, etc.).")
    redacted: bool = Field(default=False, description="Whether inputs/outputs were redacted/sanitized.")


class AgentError(BaseModel):
    """Structured error for agent failures. Errors are data, not control flow."""
    model_config = ConfigDict(extra="forbid")

    code: AgentErrorCode = Field(..., description="Standard agent error code.")
    message: str = Field(..., description="Human readable message.")
    recoverable: bool = Field(default=False, description="Whether retrying might succeed.")
    details: Dict[str, Any] = Field(default_factory=dict, description="Optional structured details (sanitized).")


class AgentEnvelope(BaseModel, Generic[T]):
    """
    Standard envelope for agent results.

    Pattern:
      ok: bool
      data: T | None
      error: AgentError | None
      meta: AgentMeta
    """
    model_config = ConfigDict(extra="forbid")

    ok: bool = Field(..., description="True if agent succeeded.")
    data: Optional[T] = Field(default=None, description="Agent output payload.")
    error: Optional[AgentError] = Field(default=None, description="Agent error if ok=False.")
    meta: AgentMeta = Field(..., description="Agent execution metadata.")

    @model_validator(mode="after")
    def _enforce_error_contract(self) -> "AgentEnvelope[T]":
        if self.ok and self.error is not None:
            raise ValueError("Agent error must be None when ok=True")
        if not self.ok and self.error is None:
            raise ValueError("Agent error is required when ok=False")
        return self

    def to_dict(self) -> Dict[str, Any]:
        """Stable serialization wrapper."""
        return self.model_dump(mode="python")


# Backwards-compatible default envelope used across the platform.
AgentResult = AgentEnvelope[Dict[str, Any]]

# core/contracts/flow_schema.py
# ==============================
# Flow Contracts
# ==============================
"""
Flow contracts for master/.

Flows are declarative graphs/sequences of steps executed by the orchestrator.
These models define the stable structure for flow configs (YAML/JSON).

Intended usage:
- flow_loader parses YAML/JSON into FlowDef
- orchestrator executes StepDef list/graph
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import AliasChoices, BaseModel, Field, ConfigDict, model_validator

from core.contracts.user_input_schema import UserInputRequest

# ==============================
# Enums
# ==============================
class StepType(str, Enum):
    """Supported step types in a flow."""
    AGENT = "agent"
    TOOL = "tool"
    HUMAN_APPROVAL = "human_approval"
    USER_INPUT = "user_input"
    PLAN_PROPOSAL = "plan_proposal"
    SUBFLOW = "subflow"


class AutonomyLevel(str, Enum):
    """Autonomy level for a flow."""
    SUGGEST_ONLY = "suggest_only"
    SEMI_AUTO = "semi_auto"
    FULL_AUTO = "full_auto"


class BackendType(str, Enum):
    """Execution backend for steps that need backends."""
    LOCAL = "local"
    REMOTE = "remote"
    MCP = "mcp"


# Backwards-compatible lowercase attribute access (tests/users may reference StepType.tool)
StepType.agent = StepType.AGENT  # type: ignore[attr-defined]
StepType.tool = StepType.TOOL  # type: ignore[attr-defined]
StepType.human_approval = StepType.HUMAN_APPROVAL  # type: ignore[attr-defined]
StepType.user_input = StepType.USER_INPUT  # type: ignore[attr-defined]
StepType.plan_proposal = StepType.PLAN_PROPOSAL  # type: ignore[attr-defined]
StepType.subflow = StepType.SUBFLOW  # type: ignore[attr-defined]

AutonomyLevel.suggest_only = AutonomyLevel.SUGGEST_ONLY  # type: ignore[attr-defined]
AutonomyLevel.semi_auto = AutonomyLevel.SEMI_AUTO  # type: ignore[attr-defined]
AutonomyLevel.full_auto = AutonomyLevel.FULL_AUTO  # type: ignore[attr-defined]


# ==============================
# Models
# ==============================
class RetryPolicy(BaseModel):
    """Retry policy for a step."""
    model_config = ConfigDict(extra="forbid")

    max_attempts: int = Field(default=1, ge=1, le=10, description="Max attempts including first try.")
    backoff_seconds: float = Field(default=0.0, ge=0.0, le=60.0, description="Fixed backoff between retries.")
    retry_on_codes: List[str] = Field(
        default_factory=list,
        description="Optional list of error codes eligible for retry.",
        validation_alias=AliasChoices("retry_on_codes", "retry_on"),
        serialization_alias="retry_on_codes",
    )


class StepDef(BaseModel):
    """
    Declarative step definition.

    Notes:
    - 'type' determines which fields are required (validated by orchestrator/loader logic).
    - params is a freeform dict but must be sanitized before tracing/persistence.
    """
    model_config = ConfigDict(extra="forbid")

    id: str = Field(..., min_length=1, max_length=80, description="Unique step id within the flow.")
    type: StepType = Field(..., description="Step type.")
    name: Optional[str] = Field(default=None, description="Human-friendly step name.")

    backend: Optional[BackendType] = Field(default=None, description="Execution backend (if applicable).")

    agent: Optional[str] = Field(default=None, description="Agent name when type=agent.")
    tool: Optional[str] = Field(default=None, description="Tool name when type=tool.")
    subflow: Optional[str] = Field(default=None, description="Subflow id/name when type=subflow.")

    message: Optional[str] = Field(default=None, description="Approval prompt when type=human_approval.")
    title: Optional[str] = Field(default=None, description="Optional UI title for human approval steps.")
    form: Dict[str, Any] = Field(default_factory=dict, description="Optional structured UI metadata.")

    params: Dict[str, Any] = Field(default_factory=dict, description="Step parameters/arguments.")
    retry: Optional[RetryPolicy] = Field(default=None, description="Retry policy for the step.")

    @model_validator(mode="after")
    def _validate_target_fields(self) -> "StepDef":
        if self.type == StepType.TOOL and not self.tool:
            raise ValueError("tool steps require the 'tool' field")
        if self.type == StepType.AGENT and not self.agent:
            raise ValueError("agent steps require the 'agent' field")
        if self.type == StepType.PLAN_PROPOSAL and not self.agent:
            raise ValueError("plan_proposal steps require the 'agent' field")
        if self.type == StepType.USER_INPUT:
            UserInputRequest.model_validate(self.params or {})
        if self.type == StepType.SUBFLOW:
            raise ValueError("subflow steps are not supported in v1; compose flows at the entrypoint")
        return self


class FlowDef(BaseModel):
    """
    Declarative flow definition.

    The orchestrator treats this as the authoritative spec.
    """
    model_config = ConfigDict(extra="forbid", populate_by_name=True)

    id: str = Field(
        ...,
        min_length=1,
        max_length=80,
        description="Flow id unique within product.",
        validation_alias=AliasChoices("id", "name"),
        serialization_alias="id",
    )
    description: Optional[str] = Field(default=None, description="Short description.")
    autonomy_level: AutonomyLevel = Field(default=AutonomyLevel.SEMI_AUTO, description="Autonomy behavior.")
    version: str = Field(default="v1", description="Flow version label.")

    steps: List[StepDef] = Field(..., min_length=1, description="Ordered list or graph definition of steps.")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Optional metadata for UI/runtime.")

    def to_dict(self) -> Dict[str, Any]:
        """Stable serialization wrapper."""
        return self.model_dump(mode="python")

    @property
    def name(self) -> str:
        return self.id

# core/contracts/plan_schema.py
# ==============================
# Plan Proposal Contracts
# ==============================
from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, ConfigDict, Field


class PlanStep(BaseModel):
    model_config = ConfigDict(extra="forbid")

    step_id: str
    description: str
    step_type: str
    tool: Optional[str] = None
    agent: Optional[str] = None
    requires_approval: bool = False


class PlanApproval(BaseModel):
    model_config = ConfigDict(extra="forbid")

    step_id: str
    reason: str


class EstimatedCost(BaseModel):
    model_config = ConfigDict(extra="forbid")

    currency: str = "USD"
    amount: float = 0.0
    tokens: Optional[int] = None
    details: Dict[str, Any] = Field(default_factory=dict)


class PlanProposal(BaseModel):
    model_config = ConfigDict(extra="forbid")

    schema_version: str = "1.0"
    summary: str
    steps: List[PlanStep]
    required_tools: List[str] = Field(default_factory=list)
    approvals: List[PlanApproval] = Field(default_factory=list)
    estimated_cost: EstimatedCost

# core/contracts/reasoning_schema.py
# ==============================
# Reasoning Purpose Contract
# ==============================
"""
Reasoning purposes for LLM usage in master/.

This is a stable contract used across routing, governance, and tracing.
"""

from enum import Enum


class ReasoningPurpose(str, Enum):
    INSIGHT = "INSIGHT"
    PRIORITIZATION = "PRIORITIZATION"
    EXPLANATION = "EXPLANATION"
    UNCERTAINTY = "UNCERTAINTY"

# core/contracts/run_schema.py
# ==============================
# Run Contracts
# ==============================
"""
Run contracts for master/.

These models define the stable representation of a run, step records, trace events,
and artifact references used for auditability and pause/resume.

Intended usage:
- Memory backend persists RunRecord + StepRecord + TraceEvent
- Orchestrator reads/writes RunRecord updates through memory backend
- Gateway API returns RunRecord summaries safely
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

import time
from enum import Enum
from typing import Any, Dict, Optional
from uuid import uuid4

from pydantic import AliasChoices, BaseModel, ConfigDict, Field

# ==============================
# Enums
# ==============================
class RunStatus(str, Enum):
    """Lifecycle status for a run."""

    RUNNING = "RUNNING"
    PENDING_HUMAN = "PENDING_HUMAN"
    PENDING_USER_INPUT = "PENDING_USER_INPUT"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELLED = "CANCELLED"


class StepStatus(str, Enum):
    """Lifecycle status for a step."""

    NOT_STARTED = "NOT_STARTED"
    RUNNING = "RUNNING"
    PENDING_HUMAN = "PENDING_HUMAN"
    PENDING_USER_INPUT = "PENDING_USER_INPUT"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    SKIPPED = "SKIPPED"


class ArtifactRef(BaseModel):
    """Reference to an artifact persisted by memory backend."""

    model_config = ConfigDict(extra="forbid")

    key: str = Field(..., description="Artifact handle used by orchestrator.")
    kind: str = Field(..., description="Artifact kind (json, file, text, etc.).")
    uri: str = Field(..., description="Storage URI/path.")
    meta: Dict[str, Any] = Field(default_factory=dict, description="Optional metadata (sanitized).")


class TraceEvent(BaseModel):
    """A single trace event emitted during a run."""

    model_config = ConfigDict(extra="forbid", populate_by_name=True)

    event_id: str = Field(default_factory=lambda: str(uuid4()), description="Unique event id.")
    run_id: str = Field(..., description="Associated run id.")
    step_id: Optional[str] = Field(default=None, description="Associated step id if applicable.")
    product: str = Field(..., description="Product name.")
    flow: str = Field(..., description="Flow name.")
    kind: str = Field(
        default="event",
        validation_alias=AliasChoices("kind", "event_type"),
        serialization_alias="event_type",
        description="Machine-readable event type (e.g., step_started).",
    )
    ts: int = Field(default_factory=lambda: int(time.time()), description="Event timestamp (epoch seconds).")
    payload: Dict[str, Any] = Field(default_factory=dict, description="Structured payload (sanitized).")
    redacted: bool = Field(default=False, description="Whether payload was redacted before persistence.")


class StepRecord(BaseModel):
    """Persistent record of a single step execution."""

    model_config = ConfigDict(extra="forbid")

    run_id: str = Field(..., description="Associated run id.")
    step_id: str = Field(..., description="Step id from flow definition.")
    step_index: int = Field(default=0, description="Zero-based index within the flow.")
    name: str = Field(default="", description="Human readable step name.")
    type: str = Field(default="tool", description="Step type (tool|agent|human_approval|subflow).")
    status: StepStatus = Field(default=StepStatus.NOT_STARTED, description="Current step status.")
    started_at: Optional[int] = Field(default=None, description="Step start timestamp (epoch seconds).")
    finished_at: Optional[int] = Field(default=None, description="Step finish timestamp (epoch seconds).")
    input: Optional[Dict[str, Any]] = Field(default=None, description="Step input payload.")
    output: Optional[Dict[str, Any]] = Field(default=None, description="Step output payload.")
    error: Optional[Dict[str, Any]] = Field(default=None, description="Structured error (sanitized).")
    meta: Dict[str, Any] = Field(default_factory=dict, description="Optional metadata (backend, target, etc.).")


class RunRecord(BaseModel):
    """Persistent record of a flow run."""

    model_config = ConfigDict(extra="forbid", populate_by_name=True)

    run_id: str = Field(default_factory=lambda: str(uuid4()), description="Unique run id.")
    product: str = Field(..., description="Product name.")
    flow: str = Field(
        ...,
        description="Flow id.",
        validation_alias=AliasChoices("flow", "flow_id"),
        serialization_alias="flow",
    )
    status: RunStatus = Field(default=RunStatus.RUNNING, description="Current run status.")
    autonomy_level: Optional[str] = Field(default=None, description="Flow autonomy level.")
    started_at: int = Field(default_factory=lambda: int(time.time()), description="Run start timestamp.")
    finished_at: Optional[int] = Field(default=None, description="Run finish timestamp.")
    input: Optional[Dict[str, Any]] = Field(default=None, description="Initial payload.")
    output: Optional[Dict[str, Any]] = Field(default=None, description="Final output payload.")
    summary: Dict[str, Any] = Field(default_factory=dict, description="Summary metadata for UI/state.")


class RunOperationError(BaseModel):
    """Structured error for run operations exposed via engine/gateway."""

    code: str = Field(default="run_error")
    message: str
    details: Dict[str, Any] = Field(default_factory=dict)


class RunOperationResult(BaseModel):
    """Envelope returned by orchestrator public methods (start/resume/get)."""

    model_config = ConfigDict(extra="forbid")

    ok: bool
    data: Optional[Dict[str, Any]] = None
    error: Optional[RunOperationError] = None

    @classmethod
    def success(cls, data: Dict[str, Any]) -> "RunOperationResult":
        return cls(ok=True, data=data, error=None)

    @classmethod
    def failure(cls, *, code: str, message: str, details: Optional[Dict[str, Any]] = None) -> "RunOperationResult":
        return cls(ok=False, data=None, error=RunOperationError(code=code, message=message, details=details or {}))

# core/contracts/tool_schema.py
# ==============================
# Tool Contracts
# ==============================
"""
Tool contracts for master/.

These models define the stable envelope and metadata for tool execution across the platform.
No core module should invent its own tool result shape  use ToolEnvelope.

Intended usage:
- Tool implementations return ToolEnvelope
- Tool executor emits trace events using ToolMeta + ToolError + ToolEnvelope
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Dict, Generic, Optional, TypeVar
from uuid import uuid4

from pydantic import BaseModel, Field, ConfigDict, model_validator

# ==============================
# Typing
# ==============================
T = TypeVar("T")


class ToolErrorCode(str, Enum):
    """Standard error codes for tool failures."""
    INVALID_INPUT = "invalid_input"
    PERMISSION_DENIED = "permission_denied"
    NOT_FOUND = "not_found"
    TIMEOUT = "timeout"
    RATE_LIMITED = "rate_limited"
    BACKEND_ERROR = "backend_error"
    CONTRACT_VIOLATION = "contract_violation"
    UNKNOWN = "unknown"
    TEMPORARY = "TEMPORARY"


# ==============================
# Models
# ==============================
class ToolMeta(BaseModel):
    """Metadata describing a tool call and its execution context."""
    model_config = ConfigDict(extra="forbid")

    tool_name: str = Field(..., description="Registered tool name.")
    backend: str = Field(..., description="Execution backend (local|remote|mcp).")
    request_id: str = Field(default_factory=lambda: str(uuid4()), description="Unique id for this tool call.")
    started_at: datetime = Field(default_factory=datetime.utcnow, description="Tool call start timestamp (UTC).")
    ended_at: Optional[datetime] = Field(default=None, description="Tool call end timestamp (UTC).")

    latency_ms: Optional[int] = Field(default=None, description="Measured latency in milliseconds.")
    cost_estimate: Optional[float] = Field(default=None, description="Approx cost estimate for this tool call.")

    tags: Dict[str, str] = Field(default_factory=dict, description="Arbitrary tags (product, flow, step, etc.).")
    redacted: bool = Field(default=False, description="Whether inputs/outputs were redacted/sanitized.")


class ToolError(BaseModel):
    """Structured error for tool failures. Errors are data, not control flow."""
    model_config = ConfigDict(extra="forbid")

    code: ToolErrorCode = Field(..., description="Standard tool error code.")
    message: str = Field(..., description="Human readable message.")
    recoverable: bool = Field(default=False, description="Whether retrying might succeed.")
    details: Dict[str, Any] = Field(default_factory=dict, description="Optional structured details (sanitized).")


class ToolEnvelope(BaseModel, Generic[T]):
    """
    Standard envelope for tool results.

    Pattern:
      ok: bool
      data: T | None
      error: ToolError | None
      meta: ToolMeta
    """
    model_config = ConfigDict(extra="forbid")

    ok: bool = Field(..., description="True if tool succeeded.")
    data: Optional[T] = Field(default=None, description="Tool output payload.")
    error: Optional[ToolError] = Field(default=None, description="Tool error if ok=False.")
    meta: ToolMeta = Field(..., description="Tool execution metadata.")

    @model_validator(mode="after")
    def _enforce_error_contract(self) -> "ToolEnvelope[T]":
        if self.ok and self.error is not None:
            raise ValueError("Tool error must be None when ok=True")
        if not self.ok and self.error is None:
            raise ValueError("Tool error is required when ok=False")
        return self

    def to_dict(self) -> Dict[str, Any]:
        """Stable serialization wrapper."""
        return self.model_dump(mode="python")


class ToolResult(ToolEnvelope[Dict[str, Any]]):
    """Concrete envelope used throughout the platform (dict payload)."""

    @classmethod
    def ok(cls, data: Optional[Dict[str, Any]] = None, meta: Optional[ToolMeta] = None) -> "ToolResult":
        return cls(ok=True, data=data or {}, error=None, meta=meta or ToolMeta(tool_name="unknown", backend="local"))

    @classmethod
    def fail(cls, *, error: ToolError, meta: ToolMeta) -> "ToolResult":
        return cls(ok=False, data=None, error=error, meta=meta)

# core/contracts/user_input_schema.py
from __future__ import annotations

from typing import Any, Dict, List, Optional, Literal

from pydantic import BaseModel, ConfigDict, Field, model_validator

UserInputMode = Literal["choice_input", "free_text_input"]


class UserInputModes:
    CHOICE_INPUT = "choice_input"
    FREE_TEXT_INPUT = "free_text_input"


class UserInputRequest(BaseModel):
    model_config = ConfigDict(extra="forbid")

    schema_version: str = Field(default="1.0")
    form_id: str
    prompt: Optional[str] = None
    title: Optional[str] = None
    input_type: Optional[Literal["text", "select", "number", "boolean"]] = None
    mode: UserInputMode = Field(default=UserInputModes.CHOICE_INPUT)
    description: Optional[str] = None
    schema: Dict[str, Any] = Field(default_factory=dict)
    defaults: Dict[str, Any] = Field(default_factory=dict)
    options: Optional[Dict[str, Any]] = None
    required: List[str] = Field(default_factory=list)
    choices: Optional[List[Dict[str, Any]]] = None
    constraints: Dict[str, Any] = Field(default_factory=dict)

    @model_validator(mode="after")
    def _normalize_prompt_and_input_type(self) -> "UserInputRequest":
        if not self.prompt:
            if self.title:
                self.prompt = self.title
            else:
                raise ValueError("prompt is required")
        if not self.input_type:
            if self.mode == UserInputModes.FREE_TEXT_INPUT:
                self.input_type = "text"
            else:
                self.input_type = "select"
        return self


class UserInputResponse(BaseModel):
    model_config = ConfigDict(extra="forbid")

    schema_version: str = Field(default="1.0")
    form_id: str
    values: Dict[str, Any] = Field(default_factory=dict)
    comment: str = ""

# core/governance/__init__.py


# core/governance/hooks.py
# ==============================
# Governance Hooks
# ==============================
"""
Hook layer used by orchestrator/tools to enforce policies and emit structured decisions.

Hooks are intentionally thin:
- Evaluate allow/deny via PolicyEngine
- Redact payloads via SecurityRedactor
- Return a stable decision object for tracing

No persistence here. No logging here. Callers emit trace events.
"""

from __future__ import annotations

from dataclasses import dataclass
import json
from typing import Any, Dict, Optional

from core.config.schema import Settings
from core.contracts.agent_schema import find_control_fields, validate_agent_output_payload
from core.contracts.reasoning_schema import ReasoningPurpose
from core.contracts.flow_schema import AutonomyLevel
from core.governance.policies import PolicyDecision, PolicyEngine
from core.governance.security import SecurityRedactor
from core.orchestrator.context import RunContext, StepContext

_INJECTION_PATTERNS = (
    "ignore previous instructions",
    "dump system prompt",
    "reveal configuration",
)


@dataclass(frozen=True)
class HookDecision:
    allowed: bool
    reason: str
    details: Dict[str, Any]
    scrubbed: Dict[str, Any]

    def to_payload(self) -> Dict[str, Any]:
        payload = {"allowed": self.allowed, "reason": self.reason}
        payload.update(self.scrubbed)
        return payload


class GovernanceHooks:
    def __init__(
        self,
        *,
        settings: Settings,
        redactor: Optional[SecurityRedactor] = None,
    ) -> None:
        self.settings = settings
        self.engine = PolicyEngine(settings)
        patterns = settings.logging.redact_patterns if settings.logging.redact_patterns else None
        self.redactor = redactor or SecurityRedactor(patterns=patterns)

    # ------------------------------
    # Orchestrator hooks
    # ------------------------------

    def before_step(self, *, step_ctx: StepContext) -> HookDecision:
        step_payload = step_ctx.step.model_dump() if step_ctx.step is not None else {"id": self._step_id(step_ctx), "type": step_ctx.type}
        limit = self.settings.policies.max_steps
        if limit is not None:
            count = int(step_ctx.run.meta.get("steps_executed", 0))
            if count >= limit:
                return self._decision(
                    allowed=False,
                    reason="step_limit_exceeded",
                    details={"step_id": self._step_id(step_ctx), "requested": count + 1, "limit": limit},
                    scrubbed={"step": self.redactor.sanitize(step_payload)},
                )
        return self._decision(
            allowed=True,
            reason="ok",
            details={
                "step_id": self._step_id(step_ctx),
                "step_type": step_ctx.step.type.value if step_ctx.step is not None else step_ctx.type,
            },
            scrubbed={"step": self.redactor.sanitize(step_payload)},
        )

    def before_complete(self, *, run_ctx: RunContext, output: Dict[str, Any]) -> HookDecision:
        return self._decision(
            allowed=True,
            reason="ok",
            details={"run_id": self._run_id(run_ctx)},
            scrubbed={"output": self.redactor.sanitize(output)},
        )

    def check_autonomy(self, *, run_ctx: RunContext, autonomy: AutonomyLevel) -> HookDecision:
        decision = self.engine.evaluate_autonomy(autonomy=autonomy, run_ctx=run_ctx)
        return self._decision(
            allowed=decision.allow,
            reason=decision.reason,
            details=decision.details,
            scrubbed={"autonomy": autonomy.value},
        )

    # ------------------------------
    # Tool hooks (used by the executor layer)
    # ------------------------------

    def before_tool_call(self, *, tool_name: str, params: Dict[str, Any], ctx: StepContext) -> HookDecision:
        decision = self.engine.evaluate_tool_call(tool_name=tool_name, step_ctx=ctx)
        scrubbed = {
            "tool": tool_name,
            "params": self.redactor.sanitize(params),
            "run_id": self._run_id(ctx.run),
            "product": self._product(ctx.run),
        }
        limit = self.settings.policies.max_tool_calls
        if limit is not None:
            count = int(ctx.run.meta.get("tool_calls", 0))
            if count >= limit:
                decision = PolicyDecision(
                    allow=False,
                    reason="tool_call_limit_exceeded",
                    details={"tool": tool_name, "requested": count + 1, "limit": limit},
                )
            else:
                ctx.run.meta["tool_calls"] = count + 1
        return self._decision(decision.allow, decision.reason, decision.details, scrubbed)

    def before_model_call(
        self,
        *,
        model_name: str,
        purpose: ReasoningPurpose,
        messages: Dict[str, Any],
        max_tokens: Optional[int],
        ctx: StepContext,
    ) -> HookDecision:
        flattened = str(messages).lower()
        if any(pat in flattened for pat in _INJECTION_PATTERNS):
            return self._decision(
                allowed=False,
                reason="prompt_injection_detected",
                details={"patterns": [p for p in _INJECTION_PATTERNS if p in flattened]},
                scrubbed={
                    "model": model_name,
                    "purpose": purpose.value,
                    "run_id": self._run_id(ctx.run),
                    "product": self._product(ctx.run),
                },
            )
        decision = self.engine.evaluate_model_use(model_name=model_name, step_ctx=ctx)
        limit = self.settings.policies.model_max_tokens
        if limit is not None and max_tokens is not None and max_tokens > limit:
            decision = PolicyDecision(
                allow=False,
                reason="model_token_limit_exceeded",
                details={"model": model_name, "requested": max_tokens, "limit": limit},
            )
        run_limit = self.settings.policies.max_tokens_per_run
        if run_limit is not None:
            used = int(ctx.run.meta.get("tokens_used", 0))
            requested = int(max_tokens or 0)
            if used >= run_limit or (requested and used + requested > run_limit):
                decision = PolicyDecision(
                    allow=False,
                    reason="run_token_budget_exceeded",
                    details={"model": model_name, "used": used, "requested": requested, "limit": run_limit},
                )
        scrubbed = {
            "model": model_name,
            "purpose": purpose.value,
            "messages": self.redactor.sanitize(messages),
            "max_tokens": max_tokens,
            "tokens_used": int(ctx.run.meta.get("tokens_used", 0)),
            "run_id": self._run_id(ctx.run),
            "product": self._product(ctx.run),
        }
        return self._decision(decision.allow, decision.reason, decision.details, scrubbed)

    def before_user_input_response(
        self,
        *,
        request: Any,
        response: Any,
        ctx: StepContext,
    ) -> HookDecision:
        limit = self.settings.policies.max_payload_bytes
        payload = {"request": request, "response": response}
        if limit is not None and self._payload_size_bytes(response) > limit:
            return self._decision(
                allowed=False,
                reason="user_input_payload_limit_exceeded",
                details={"limit_bytes": limit},
                scrubbed={"payload": self.redactor.sanitize(payload), "run_id": self._run_id(ctx.run)},
            )
        return self._decision(
            allowed=True,
            reason="ok",
            details={"run_id": self._run_id(ctx.run)},
            scrubbed={"payload": self.redactor.sanitize(payload)},
        )

    def before_run_output(self, *, output: Dict[str, Any], run_ctx: RunContext) -> HookDecision:
        limit = self.settings.policies.max_payload_bytes
        if limit is not None and self._payload_size_bytes(output) > limit:
            return self._decision(
                allowed=False,
                reason="output_payload_limit_exceeded",
                details={"limit_bytes": limit},
                scrubbed={"output": self.redactor.sanitize(output), "run_id": self._run_id(run_ctx)},
            )
        return self._decision(
            allowed=True,
            reason="ok",
            details={"run_id": self._run_id(run_ctx)},
            scrubbed={"output": self.redactor.sanitize(output)},
        )

    def before_output_files(self, *, files: Any, run_ctx: RunContext) -> HookDecision:
        limit = self.settings.policies.max_payload_bytes
        if limit is not None and self._payload_size_bytes(files) > limit:
            return self._decision(
                allowed=False,
                reason="output_files_limit_exceeded",
                details={"limit_bytes": limit},
                scrubbed={"files": self.redactor.sanitize(files), "run_id": self._run_id(run_ctx)},
            )
        return self._decision(
            allowed=True,
            reason="ok",
            details={"run_id": self._run_id(run_ctx)},
            scrubbed={"files": self.redactor.sanitize(files)},
        )

    def validate_agent_output(self, *, agent_name: str, output: Dict[str, Any], ctx: StepContext) -> HookDecision:
        violations = find_control_fields(output)
        allowed = True
        reason = "ok"
        details: Dict[str, Any] = {"agent": agent_name}
        if violations:
            allowed = False
            reason = "agent_output_control_fields"
            details["violations"] = violations
        try:
            validate_agent_output_payload(output)
        except Exception as exc:
            allowed = False
            if reason == "ok":
                reason = "agent_output_invalid"
            details["error"] = str(exc)
        scrubbed = {
            "agent": agent_name,
            "output": self.redactor.sanitize(output),
            "violations": violations,
            "run_id": self._run_id(ctx.run),
            "product": self._product(ctx.run),
        }
        return self._decision(allowed, reason, details, scrubbed)

    def _decision(self, allowed: bool, reason: str, details: Dict[str, Any], scrubbed: Dict[str, Any]) -> HookDecision:
        return HookDecision(allowed=allowed, reason=reason, details=details, scrubbed=scrubbed)

    @staticmethod
    def _step_id(step_ctx: StepContext) -> str:
        return getattr(step_ctx.step, "id", "unknown_step")

    @staticmethod
    def _run_id(run_ctx: RunContext) -> str:
        record = getattr(run_ctx, "run_record", None)
        return getattr(record, "run_id", "unknown_run")

    @staticmethod
    def _product(run_ctx: RunContext) -> str:
        record = getattr(run_ctx, "run_record", None)
        return getattr(record, "product", "unknown_product")

    @staticmethod
    def _payload_size_bytes(payload: Any) -> int:
        try:
            raw = json.dumps(payload, ensure_ascii=True, separators=(",", ":"))
        except Exception:
            raw = str(payload)
        return len(raw.encode("utf-8"))

    @classmethod
    def noop(cls) -> "GovernanceHooks":
        """
        Helper used by orchestrator tests  returns a hooks instance with default Settings.
        """
        return cls(settings=Settings())

# core/governance/policies.py
# ==============================
# Governance Policies
# ==============================
"""
Policy evaluation for tools, models, and autonomy.

Design:
- Simple allow/deny evaluation with per-product overrides.
- Uses Settings + context (RunContext/StepContext) for decisions.
- v1 focus: tool + model allow/deny and autonomy gating.

No persistence. No vendor calls.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Optional

from core.config.schema import Settings
from core.contracts.flow_schema import AutonomyLevel
from core.orchestrator.context import RunContext, StepContext


@dataclass(frozen=True)
class PolicyDecision:
    allow: bool
    reason: str
    details: Dict[str, Any]


def _merge_policy_dict(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(base)
    for k, v in override.items():
        if isinstance(out.get(k), dict) and isinstance(v, dict):
            out[k] = _merge_policy_dict(out[k], v)  # type: ignore[arg-type]
        else:
            out[k] = v
    return out


def _norm(value: str) -> str:
    return value.strip().lower()


class PolicyEngine:
    def __init__(self, settings: Settings) -> None:
        self.settings = settings

    def _policy_for_product(self, product: str) -> Dict[str, Any]:
        base = self.settings.policies.model_dump()
        overrides = self.settings.policies.by_product.get(product, {}) if self.settings.policies.by_product else {}
        return _merge_policy_dict(base, overrides)

    # ------------------------------
    # Autonomy
    # ------------------------------

    def evaluate_autonomy(self, *, autonomy: AutonomyLevel, run_ctx: RunContext) -> PolicyDecision:
        pol = self._policy_for_product(run_ctx.product)
        if not pol.get("enforce", True):
            return PolicyDecision(True, "policies_disabled", {"autonomy": autonomy.value})

        if autonomy == AutonomyLevel.FULL_AUTO and not pol.get("allow_full_autonomy", False):
            return PolicyDecision(False, "full_autonomy_disabled", {"autonomy": autonomy.value})

        return PolicyDecision(True, "ok", {"autonomy": autonomy.value})

    # ------------------------------
    # Tools
    # ------------------------------

    def evaluate_tool_call(self, *, tool_name: str, step_ctx: StepContext) -> PolicyDecision:
        product = self._product_from_ctx(step_ctx)
        pol = self._policy_for_product(product)
        norm_tool = _norm(tool_name)
        if not pol.get("enforce", True):
            return PolicyDecision(True, "policies_disabled", {"tool": tool_name, "product": product})

        allowed = [_norm(t) for t in (pol.get("allowed_tools") or [])]
        blocked = {_norm(t) for t in (pol.get("blocked_tools") or [])}

        if norm_tool in blocked:
            return PolicyDecision(False, "tool_blocked", {"tool": tool_name, "product": product})

        if allowed and norm_tool not in allowed:
            return PolicyDecision(False, "tool_not_in_allowlist", {"tool": tool_name, "product": product})

        return PolicyDecision(True, "ok", {"tool": tool_name, "product": product})

    # ------------------------------
    # Models
    # ------------------------------

    def evaluate_model_use(self, *, model_name: str, step_ctx: StepContext) -> PolicyDecision:
        product = self._product_from_ctx(step_ctx)
        return self.evaluate_model_selection(product=product, model_name=model_name)

    def evaluate_model_selection(self, *, product: str, model_name: str) -> PolicyDecision:
        pol = self._policy_for_product(product)
        norm_model = _norm(model_name)
        if not pol.get("enforce", True):
            return PolicyDecision(True, "policies_disabled", {"model": model_name, "product": product})

        allowed = [_norm(m) for m in (pol.get("allowed_models") or [])]
        blocked = {_norm(m) for m in (pol.get("blocked_models") or [])}

        if norm_model in blocked:
            return PolicyDecision(False, "model_blocked", {"model": model_name, "product": product})

        if allowed and norm_model not in allowed:
            return PolicyDecision(False, "model_not_in_allowlist", {"model": model_name, "product": product})

        return PolicyDecision(True, "ok", {"model": model_name, "product": product})

    @staticmethod
    def _product_from_ctx(step_ctx: StepContext) -> str:
        run = getattr(step_ctx, "run", None)
        run_record = getattr(run, "run_record", None)
        return getattr(run_record, "product", getattr(step_ctx, "product", "unknown_product"))

# core/governance/security.py
# ==============================
# Security & Redaction
# ==============================
"""
Security redaction helpers.

Goals:
- Scrub secrets/PII from anything that might be logged/traced or shown in UI.
- Keep it deterministic and testable.
- Configurable patterns via Settings.logging.redact_patterns (and defaults here).

Scope:
- Do NOT attempt "perfect PII detection" in v1.
- Provide practical regex-based redaction + key-based redaction (e.g., password, token).
"""

from __future__ import annotations

import re
from typing import Any, Dict, Iterable, List, Pattern

from core.config.schema import Settings

DEFAULT_MASK = "***REDACTED***"
DEFAULT_MAX_TEXT_CHARS = 4096

DEFAULT_KEY_HINTS: List[str] = [
    "password",
    "passwd",
    "secret",
    "token",
    "api_key",
    "apikey",
    "authorization",
    "bearer",
    "cookie",
    "session",
    "private_key",
    "ssh_key",
]

DEFAULT_PATTERNS: List[str] = [
    r"sk-[A-Za-z0-9_-]{3,}",  # common key pattern (loose match)
    r"(?i)api[_-]?key\s*[:=]\s*\S+",
    r"(?i)authorization\s*:\s*bearer\s+\S+",
]

DEFAULT_PII_PATTERNS: List[str] = [
    r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}",
    r"(?<!\d)(?:\d[ -]?){13,16}(?!\d)",  # simple card/PAN heuristic
    r"(?<!\d)(?:\+?\d[ -]?){7,15}(?!\d)",  # loose phone number
]


def _compile(patterns: Iterable[str]) -> List[Pattern[str]]:
    compiled: List[Pattern[str]] = []
    for p in patterns:
        try:
            compiled.append(re.compile(p))
        except re.error:
            continue
    return compiled


class SecurityRedactor:
    """
    Sanitizes payloads before they reach logs, traces, or persistence.

    - Key hints mask dictionary values eagerly.
    - Regex patterns scrub inline secrets/PII.
    - Strings are clamped to avoid unbounded payload growth.
    """

    def __init__(
        self,
        *,
        patterns: List[str] | None = None,
        key_hints: List[str] | None = None,
        mask: str = DEFAULT_MASK,
        include_pii: bool = True,
        max_text_chars: int = DEFAULT_MAX_TEXT_CHARS,
    ) -> None:
        base_patterns = list(DEFAULT_PATTERNS)
        if include_pii:
            base_patterns.extend(DEFAULT_PII_PATTERNS)
        if patterns:
            base_patterns.extend(patterns)

        self.mask = mask
        self.max_text_chars = max_text_chars
        self.key_hints = [k.lower() for k in (key_hints or DEFAULT_KEY_HINTS)]
        self.patterns = _compile(base_patterns)

    def redact_text(self, text: str) -> str:
        out = text
        for p in self.patterns:
            out = p.sub(self.mask, out)
        if len(out) > self.max_text_chars:
            return f"{out[: self.max_text_chars]}{self.mask}"
        return out

    def sanitize(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Public helper used by tracing/executor code."""
        return self._redact_any(payload)  # type: ignore[return-value]

    # Backwards compatibility for older callers/tests
    scrub = sanitize
    redact_dict = sanitize

    def _redact_any(self, value: Any) -> Any:
        if value is None:
            return None
        if isinstance(value, str):
            return self.redact_text(value)
        if isinstance(value, (int, float, bool)):
            return value
        if isinstance(value, list):
            return [self._redact_any(v) for v in value]
        if isinstance(value, tuple):
            return [self._redact_any(v) for v in value]
        if isinstance(value, dict):
            masked: Dict[str, Any] = {}
            for k, v in value.items():
                key_lower = str(k).lower()
                if any(h in key_lower for h in self.key_hints):
                    masked[k] = self.mask
                else:
                    masked[k] = self._redact_any(v)
            return masked
        return self.redact_text(str(value))

    @classmethod
    def from_settings(cls, settings: Settings) -> "SecurityRedactor":
        logging_cfg = settings.logging
        if not getattr(logging_cfg, "redact", True):
            return cls(patterns=logging_cfg.redact_patterns, include_pii=False)
        max_chars = getattr(logging_cfg, "max_payload_chars", DEFAULT_MAX_TEXT_CHARS)
        return cls(patterns=logging_cfg.redact_patterns, max_text_chars=max_chars)


class Redactor(SecurityRedactor):
    """Compatibility alias used by older modules/tests."""

    pass

# core/memory/__init__.py


# core/memory/base.py
# ==============================
# Memory Backend Contracts
# ==============================
"""
Memory layer is the ONLY place where persistence is allowed.

This module defines:
- MemoryBackend interface used by orchestrator + tracing.
- Pydantic records for approvals and bundled run retrieval.

Rules:
- No vendor calls.
- No tool execution.
- Concrete persistence lives in sqlite_backend.py (or other backends).
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, ConfigDict, Field

from core.contracts.run_schema import RunRecord, StepRecord, TraceEvent


class ApprovalRecord(BaseModel):
    model_config = ConfigDict(extra="forbid")

    approval_id: str = Field(...)
    run_id: str = Field(...)
    step_id: str = Field(...)
    product: str = Field(...)
    flow: str = Field(...)
    status: str = Field(default="PENDING")  # PENDING | APPROVED | REJECTED
    requested_by: Optional[str] = Field(default=None)
    requested_at: int = Field(...)
    resolved_by: Optional[str] = Field(default=None)
    resolved_at: Optional[int] = Field(default=None)
    decision: Optional[str] = Field(default=None)  # APPROVE/REJECT or custom
    comment: Optional[str] = Field(default=None)
    payload: Dict[str, Any] = Field(default_factory=dict)  # scrubbed payload for UI display


class RunBundle(BaseModel):
    model_config = ConfigDict(extra="forbid")

    run: RunRecord = Field(...)
    steps: List[StepRecord] = Field(default_factory=list)
    events: List[TraceEvent] = Field(default_factory=list)
    approvals: List[ApprovalRecord] = Field(default_factory=list)


class MemoryBackend(ABC):
    """
    Interface used by core.orchestrator and core.memory.Tracer.

    Minimal set of operations for v1:
    - runs + steps + events
    - HITL approvals
    """

    @abstractmethod
    def create_run(self, run: RunRecord) -> None:
        raise NotImplementedError

    @abstractmethod
    def update_run_status(self, run_id: str, status: str, *, summary: Optional[Dict[str, Any]] = None) -> None:
        raise NotImplementedError

    @abstractmethod
    def update_run_output(self, run_id: str, *, output: Optional[Dict[str, Any]]) -> None:
        raise NotImplementedError

    @abstractmethod
    def add_step(self, step: StepRecord) -> None:
        raise NotImplementedError

    @abstractmethod
    def update_step(self, run_id: str, step_id: str, patch: Dict[str, Any]) -> None:
        raise NotImplementedError

    @abstractmethod
    def add_event(self, event: TraceEvent) -> None:
        raise NotImplementedError

    # For tracing convenience (Tracer calls this)
    def append_trace_event(self, event: TraceEvent) -> None:
        self.add_event(event)

    @abstractmethod
    def create_approval(self, approval: ApprovalRecord) -> None:
        raise NotImplementedError

    @abstractmethod
    def resolve_approval(
        self,
        approval_id: str,
        *,
        decision: str,
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        raise NotImplementedError

    @abstractmethod
    def get_run(self, run_id: str) -> Optional[RunBundle]:
        raise NotImplementedError

    @abstractmethod
    def list_runs(self, *, limit: int = 50, offset: int = 0) -> List[RunRecord]:
        raise NotImplementedError

    @abstractmethod
    def list_pending_approvals(self, *, limit: int = 50, offset: int = 0) -> List[ApprovalRecord]:
        raise NotImplementedError

    # Optional hooks for durable backends so tooling/migrations can introspect.
    def ensure_schema(self) -> None:
        """
        Ensure backing schema exists. In-memory backends can no-op.
        """
        return None

    def get_schema_version(self) -> int:
        """
        Return integer schema version if supported. Defaults to 0.
        """
        return 0

# core/memory/in_memory.py
# ==============================
# In-Memory Backend (Dev)
# ==============================
"""
In-memory backend for local dev/testing.

Not durable. Deterministic. No file I/O.
"""

from __future__ import annotations

import time
import threading
from typing import Any, Dict, List, Optional

from core.contracts.run_schema import RunRecord, StepRecord, TraceEvent
from core.memory.base import ApprovalRecord, MemoryBackend, RunBundle


class InMemoryBackend(MemoryBackend):
    def __init__(self) -> None:
        self._lock = threading.RLock()
        self._runs: Dict[str, RunRecord] = {}
        self._steps: Dict[str, Dict[str, StepRecord]] = {}
        self._events: Dict[str, List[TraceEvent]] = {}
        self._approvals: Dict[str, ApprovalRecord] = {}

    def create_run(self, run: RunRecord) -> None:
        with self._lock:
            self._runs[run.run_id] = run
            self._steps.setdefault(run.run_id, {})
            self._events.setdefault(run.run_id, [])

    def update_run_status(self, run_id: str, status: str, *, summary: Optional[Dict[str, Any]] = None) -> None:
        with self._lock:
            run = self._runs.get(run_id)
            if run is None:
                return
            patch: Dict[str, Any] = {"status": status}
            if summary is not None:
                patch["summary"] = summary
            self._runs[run_id] = run.model_copy(update=patch)

    def update_run_output(self, run_id: str, *, output: Optional[Dict[str, Any]]) -> None:
        with self._lock:
            run = self._runs.get(run_id)
            if run is None:
                return
            self._runs[run_id] = run.model_copy(update={"output": output})

    def add_step(self, step: StepRecord) -> None:
        with self._lock:
            self._steps.setdefault(step.run_id, {})
            self._steps[step.run_id][step.step_id] = step

    def update_step(self, run_id: str, step_id: str, patch: Dict[str, Any]) -> None:
        with self._lock:
            step = self._steps.get(run_id, {}).get(step_id)
            if step is None:
                return
            self._steps[run_id][step_id] = step.model_copy(update=patch)

    def add_event(self, event: TraceEvent) -> None:
        with self._lock:
            self._events.setdefault(event.run_id, [])
            self._events[event.run_id].append(event)

    def create_approval(self, approval: ApprovalRecord) -> None:
        with self._lock:
            self._approvals[approval.approval_id] = approval

    def resolve_approval(
        self,
        approval_id: str,
        *,
        decision: str,
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        with self._lock:
            a = self._approvals.get(approval_id)
            if a is None:
                return
            now = int(time.time())
            status = "APPROVED" if decision.upper().startswith("APPROVE") else "REJECTED"
            self._approvals[approval_id] = a.model_copy(
                update={
                    "status": status,
                    "decision": decision,
                    "resolved_by": resolved_by,
                    "comment": comment,
                    "resolved_at": now,
                }
            )

    def get_run(self, run_id: str) -> Optional[RunBundle]:
        with self._lock:
            run = self._runs.get(run_id)
            if run is None:
                return None
            steps = list(self._steps.get(run_id, {}).values())
            events = list(self._events.get(run_id, []))
            approvals = [a for a in self._approvals.values() if a.run_id == run_id]
            return RunBundle(run=run, steps=steps, events=events, approvals=approvals)

    def list_runs(self, *, limit: int = 50, offset: int = 0) -> List[RunRecord]:
        with self._lock:
            runs = list(self._runs.values())
            runs.sort(key=lambda r: r.started_at, reverse=True)
            return runs[offset : offset + limit]

    def list_pending_approvals(self, *, limit: int = 50, offset: int = 0) -> List[ApprovalRecord]:
        with self._lock:
            pending = [a for a in self._approvals.values() if a.status == "PENDING"]
            pending.sort(key=lambda a: a.requested_at, reverse=True)
            return pending[offset : offset + limit]

    def ensure_schema(self) -> None:
        # Nothing to create for in-memory backend
        return None

    def get_schema_version(self) -> int:
        return 0

# core/memory/observability_store.py
# ==============================
# Observability Store (Memory Layer)
# ==============================
"""
File-backed observability outputs owned by core/memory.

Internal-only: MemoryRouter is the sole caller; avoid new direct imports.

Layout per run:
- observability/<product>/<run_id>/input/*
- observability/<product>/<run_id>/runtime/events.jsonl
- observability/<product>/<run_id>/output/*
"""

__all__ = ["ObservabilityStore"]

from __future__ import annotations

import base64
import hashlib
import json
import re
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional


class ObservabilityStore:
    def __init__(self, *, repo_root: Path, observability_root: Optional[Path] = None) -> None:
        self.repo_root = repo_root
        self.root = observability_root or (repo_root / "observability")
        self.products_root = repo_root / "products"

    def ensure_dirs(self, *, product: str, run_id: str) -> Dict[str, Path]:
        base = self.root / product / run_id
        paths = {
            "base": base,
            "input": base / "input",
            "runtime": base / "runtime",
            "output": base / "output",
        }
        for path in paths.values():
            path.mkdir(parents=True, exist_ok=True)
        return paths

    def ensure_staging_dirs(self, *, product: str) -> Dict[str, Path]:
        base = self.products_root / product / "staging"
        paths = {
            "base": base,
            "input": base / "input",
            "output": base / "output",
        }
        for path in paths.values():
            path.mkdir(parents=True, exist_ok=True)
        return paths

    def clear_staging(self, *, product: str, clear_input: bool = True, clear_output: bool = True) -> None:
        paths = self.ensure_staging_dirs(product=product)
        if clear_input:
            _clear_dir(paths["input"])
        if clear_output:
            _clear_dir(paths["output"])

    def write_input_payload(self, *, product: str, run_id: str, payload: Dict[str, Any]) -> bool:
        paths = self.ensure_dirs(product=product, run_id=run_id)
        input_path = paths["input"] / "input.json"
        if input_path.exists():
            return False
        self._atomic_write_json(input_path, payload)
        messages = payload.get("messages")
        comments = payload.get("comments")
        self._write_once(paths["input"] / "messages.json", messages if isinstance(messages, list) else [])
        self._write_once(paths["input"] / "comments.json", comments if isinstance(comments, list) else [])
        return True

    def append_comment(
        self,
        *,
        product: str,
        run_id: str,
        comment: str,
        decision: Optional[str] = None,
        step_id: Optional[str] = None,
        ts: Optional[int] = None,
    ) -> None:
        cleaned = (comment or "").strip()
        if not cleaned:
            return
        paths = self.ensure_dirs(product=product, run_id=run_id)
        comments_path = paths["input"] / "comments.json"
        existing: List[Any] = []
        if comments_path.exists():
            try:
                loaded = json.loads(comments_path.read_text(encoding="utf-8"))
                if isinstance(loaded, list):
                    existing = loaded
            except Exception:
                existing = []
        entry: Dict[str, Any] = {"comment": cleaned}
        if decision:
            entry["decision"] = decision
        if step_id:
            entry["step_id"] = step_id
        if ts is not None:
            entry["ts"] = ts
        existing.append(entry)
        self._atomic_write_json(comments_path, existing)

    def stage_attachments(
        self,
        *,
        product: str,
        run_id: str,
        payload: Dict[str, Any],
    ) -> List[Dict[str, Any]]:
        staging_paths = self.ensure_staging_dirs(product=product)
        input_dir = staging_paths["input"]
        attachments: List[Dict[str, Any]] = []
        files = payload.get("files") or []
        if not files:
            files = [{"name": source.name} for source in input_dir.iterdir() if source.is_file()]
        for idx, file_ref in enumerate(files):
            if not isinstance(file_ref, dict):
                continue
            name = str(file_ref.get("name") or file_ref.get("file_name") or "").strip()
            if not name:
                continue
            source = input_dir / name
            stored_name = self._safe_name(name, index=idx)
            if source.exists():
                if source.name != stored_name:
                    target = input_dir / stored_name
                    if target.exists():
                        stored_name = f"{idx}_{stored_name}"
                        target = input_dir / stored_name
                    source.rename(target)
                    source = target
            target = input_dir / stored_name
            meta = {
                "name": name,
                "stored_name": stored_name,
                "content_type": _guess_content_type(name),
                "size": None,
                "sha256": None,
                "source": "ref",
                "ref": name,
            }
            if source.exists():
                meta["source"] = "upload"
                meta["ref"] = None
                meta["size"] = source.stat().st_size
                meta["sha256"] = _sha256_file(source)
            attachments.append(meta)
        self._write_once(staging_paths["input"] / "attachments.json", attachments)
        return attachments

    def move_staged_inputs_to_run(self, *, product: str, run_id: str) -> None:
        staging = self.ensure_staging_dirs(product=product)["input"]
        run_input = self.ensure_dirs(product=product, run_id=run_id)["input"]
        for source in staging.iterdir():
            if not source.is_file():
                continue
            target = run_input / source.name
            if not target.exists():
                shutil.copy2(source, target)
        _clear_dir(staging)

    def write_response(
        self,
        *,
        product: str,
        run_id: str,
        response: Dict[str, Any],
    ) -> Dict[str, Any]:
        paths = self.ensure_dirs(product=product, run_id=run_id)
        files = self._list_output_files(paths["output"])
        response["files"] = files
        output_path = paths["output"] / "response.json"
        self._atomic_write_json(output_path, response)
        path_value = str(output_path)
        try:
            path_value = str(output_path.relative_to(self.repo_root))
        except ValueError:
            path_value = str(output_path)
        return {"path": path_value, "sha256": _sha256_file(output_path), "files": files}

    def append_event(self, *, product: str, run_id: str, payload: Dict[str, Any]) -> Path:
        paths = self.ensure_dirs(product=product, run_id=run_id)
        runtime_path = paths["runtime"] / "events.jsonl"
        line = json.dumps(payload, ensure_ascii=False)
        runtime_path.open("a", encoding="utf-8").write(line + "\n")
        return runtime_path

    def write_output_files(self, *, product: str, run_id: str, files: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        staging = self.ensure_staging_dirs(product=product)["output"]
        output_dir = self.ensure_dirs(product=product, run_id=run_id)["output"]
        stored: List[Dict[str, Any]] = []
        for idx, item in enumerate(files):
            if not isinstance(item, dict):
                continue
            name = str(item.get("name") or "").strip()
            content = item.get("content_base64")
            if not name or not content:
                continue
            stored_name = self._safe_name(name, index=idx)
            staging_target = staging / stored_name
            if staging_target.exists():
                stored_name = f"{idx}_{stored_name}"
                staging_target = staging / stored_name
            try:
                raw = _decode_base64(content)
            except ValueError:
                continue
            staging_target.write_bytes(raw)
            target = output_dir / stored_name
            shutil.move(str(staging_target), str(target))
            role = item.get("role")
            if not isinstance(role, str) or not role:
                role = "primary" if Path(name).suffix.lower() == ".pdf" else "supporting"
            stored.append(
                {
                    "name": name,
                    "stored_name": stored_name,
                    "role": role,
                    "content_type": item.get("content_type") or _guess_content_type(name),
                    "size": target.stat().st_size,
                    "sha256": _sha256_file(target),
                }
            )
        _clear_dir(staging)
        return stored

    def write_user_input_response(
        self,
        *,
        product: str,
        run_id: str,
        form_id: str,
        payload: Dict[str, Any],
    ) -> Path:
        paths = self.ensure_dirs(product=product, run_id=run_id)
        runtime_dir = paths["runtime"]
        user_input_dir = runtime_dir / "user_input"
        user_input_dir.mkdir(parents=True, exist_ok=True)
        target = user_input_dir / f"{form_id}.json"
        self._atomic_write_json(target, payload)
        return target

    def _list_output_files(self, output_dir: Path) -> List[Dict[str, Any]]:
        files: List[Dict[str, Any]] = []
        for entry in sorted(output_dir.iterdir()):
            if not entry.is_file():
                continue
            if entry.name == "response.json":
                continue
            role = "supporting"
            if entry.suffix.lower() == ".pdf":
                role = "primary"
            if entry.suffix.lower() == ".html":
                role = "interactive"
            files.append(
                {
                    "name": entry.name,
                    "stored_name": entry.name,
                    "role": role,
                    "content_type": _guess_content_type(entry.name),
                    "size": entry.stat().st_size,
                    "sha256": _sha256_file(entry),
                }
            )
        unique: Dict[str, Dict[str, Any]] = {}
        for item in files:
            key = f"{item.get('stored_name')}::{item.get('sha256')}"
            unique[key] = item
        return list(unique.values())

    def _write_once(self, path: Path, payload: Any) -> None:
        if path.exists():
            return
        self._atomic_write_json(path, payload)

    def _atomic_write_json(self, path: Path, payload: Any) -> None:
        path.parent.mkdir(parents=True, exist_ok=True)
        tmp = path.with_suffix(path.suffix + ".tmp")
        tmp.write_text(json.dumps(payload, indent=2, ensure_ascii=False), encoding="utf-8")
        tmp.replace(path)

    def _safe_name(self, name: str, *, index: int) -> str:
        base = Path(name).name
        safe = re.sub(r"[^A-Za-z0-9._-]+", "_", base).strip("._")
        if not safe:
            safe = f"file_{index}"
        return safe


def _guess_content_type(name: str) -> str:
    suffix = Path(name).suffix.lower()
    if suffix == ".csv":
        return "text/csv"
    if suffix == ".json":
        return "application/json"
    if suffix == ".pdf":
        return "application/pdf"
    if suffix == ".html":
        return "text/html"
    if suffix in {".txt", ".md"}:
        return "text/plain"
    return "application/octet-stream"


def _sha256_file(path: Path) -> str:
    digest = hashlib.sha256()
    with path.open("rb") as handle:
        for chunk in iter(lambda: handle.read(8192), b""):
            digest.update(chunk)
    return digest.hexdigest()


def _clear_dir(path: Path) -> None:
    if not path.exists():
        return
    for entry in path.iterdir():
        if entry.is_dir():
            shutil.rmtree(entry, ignore_errors=True)
        else:
            entry.unlink(missing_ok=True)


def _decode_base64(value: str) -> bytes:
    try:
        return base64.b64decode(value)
    except Exception as exc:
        raise ValueError(str(exc))

# core/memory/router.py
# ==============================
# Memory Router
# ==============================
"""
Memory router provides a single interface used by orchestrator + tracer.

v1:
- Delegates all operations to a chosen backend (sqlite or in-memory).
- Keeps room for future multi-store routing (short/long/episodic) without changing callers.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional

from core.contracts.run_schema import RunRecord, StepRecord, TraceEvent
from core.config.schema import Settings
from core.memory.base import ApprovalRecord, MemoryBackend, RunBundle
from core.memory.observability_store import ObservabilityStore
from core.memory.sqlite_backend import SQLiteBackend


class MemoryRouter(MemoryBackend):
    def __init__(
        self,
        backend: MemoryBackend,
        *,
        repo_root: Optional[Path] = None,
        observability_root: Optional[Path] = None,
    ) -> None:
        self.backend = backend
        # Observability store is internal to the memory layer; keep call sites centralized here.
        self._observability = (
            ObservabilityStore(repo_root=repo_root, observability_root=observability_root)
            if repo_root
            else None
        )

    def create_run(self, run: RunRecord) -> None:
        self.backend.create_run(run)

    def update_run_status(self, run_id: str, status: str, *, summary: Optional[Dict[str, Any]] = None) -> None:
        self.backend.update_run_status(run_id, status, summary=summary)

    def update_run_output(self, run_id: str, *, output: Optional[Dict[str, Any]]) -> None:
        self.backend.update_run_output(run_id, output=output)

    def update_run_output(self, run_id: str, *, output: Optional[Dict[str, Any]]) -> None:
        self.backend.update_run_output(run_id, output=output)

    def add_step(self, step: StepRecord) -> None:
        self.backend.add_step(step)

    def update_step(self, run_id: str, step_id: str, patch: Dict[str, Any]) -> None:
        self.backend.update_step(run_id, step_id, patch)

    def add_event(self, event: TraceEvent) -> None:
        self.backend.add_event(event)

    def append_trace_event(self, event: TraceEvent) -> None:
        self.backend.append_trace_event(event)
        if self._observability is None:
            return
        self._observability.append_event(
            product=event.product,
            run_id=event.run_id,
            payload=event.model_dump(mode="json"),
        )

    def create_approval(self, approval: ApprovalRecord) -> None:
        self.backend.create_approval(approval)

    def resolve_approval(
        self,
        approval_id: str,
        *,
        decision: str,
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        self.backend.resolve_approval(approval_id, decision=decision, resolved_by=resolved_by, comment=comment)

    def append_run_comment(
        self,
        *,
        product: str,
        run_id: str,
        comment: Optional[str],
        decision: Optional[str] = None,
        step_id: Optional[str] = None,
        ts: Optional[int] = None,
    ) -> None:
        if self._observability is None:
            return
        self._observability.append_comment(
            product=product,
            run_id=run_id,
            comment=comment or "",
            decision=decision,
            step_id=step_id,
            ts=ts,
        )

    def get_run(self, run_id: str) -> Optional[RunBundle]:
        return self.backend.get_run(run_id)

    def list_runs(self, *, limit: int = 50, offset: int = 0) -> List[RunRecord]:
        return self.backend.list_runs(limit=limit, offset=offset)

    def list_pending_approvals(self, *, limit: int = 50, offset: int = 0) -> List[ApprovalRecord]:
        return self.backend.list_pending_approvals(limit=limit, offset=offset)

    def ensure_schema(self) -> None:
        self.backend.ensure_schema()

    def get_schema_version(self) -> int:
        return self.backend.get_schema_version()

    def ensure_observability_dirs(self, *, product: str, run_id: str) -> None:
        if self._observability is None:
            return
        self._observability.ensure_dirs(product=product, run_id=run_id)

    def get_observability_dirs(self, *, product: str, run_id: str) -> Dict[str, Path]:
        if self._observability is None:
            return {}
        return self._observability.ensure_dirs(product=product, run_id=run_id)

    def clear_staging(self, *, product: str, clear_input: bool = True, clear_output: bool = True) -> None:
        if self._observability is None:
            return
        self._observability.clear_staging(product=product, clear_input=clear_input, clear_output=clear_output)

    def move_staged_inputs_to_run(self, *, product: str, run_id: str) -> None:
        if self._observability is None:
            return
        self._observability.move_staged_inputs_to_run(product=product, run_id=run_id)

    def capture_run_input(self, *, product: str, run_id: str, payload: Dict[str, Any]) -> None:
        if self._observability is None:
            return
        wrote = self._observability.write_input_payload(product=product, run_id=run_id, payload=payload)
        if not wrote:
            return
        self._observability.stage_attachments(product=product, run_id=run_id, payload=payload)

    def write_run_response(self, *, product: str, run_id: str, response: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        if self._observability is None:
            return None
        return self._observability.write_response(product=product, run_id=run_id, response=response)

    def write_output_files(self, *, product: str, run_id: str, files: List[Dict[str, Any]]) -> Optional[List[Dict[str, Any]]]:
        if self._observability is None:
            return None
        return self._observability.write_output_files(product=product, run_id=run_id, files=files)

    def write_user_input_response(
        self,
        *,
        product: str,
        run_id: str,
        form_id: str,
        payload: Dict[str, Any],
    ) -> Optional[Path]:
        if self._observability is None:
            return None
        return self._observability.write_user_input_response(
            product=product,
            run_id=run_id,
            form_id=form_id,
            payload=payload,
        )

    @classmethod
    def from_settings(cls, settings: Settings) -> "MemoryRouter":
        """
        Instantiate router using repo settings.
        """
        repo_root = settings.repo_root_path()

        def _resolve(path_str: str) -> Path:
            path = Path(path_str)
            return path if path.is_absolute() else (repo_root / path)

        storage_dir = _resolve(settings.app.paths.storage_dir)
        observability_dir = _resolve(settings.app.paths.observability_dir)
        memory_dir = storage_dir / "memory"
        memory_dir.mkdir(parents=True, exist_ok=True)

        db_path = settings.secrets.memory_db_path
        db_file = _resolve(db_path) if db_path else (memory_dir / "master.sqlite")
        db_file.parent.mkdir(parents=True, exist_ok=True)

        backend = SQLiteBackend(db_path=str(db_file))
        backend.ensure_schema()
        return cls(backend, repo_root=repo_root, observability_root=observability_dir)

# core/memory/sqlite_backend.py
# ==============================
# SQLite Backend (v1)
# ==============================
"""
SQLite backend for durable runs/steps/events/approvals.

Tables:
- schema_version
- runs
- steps
- events
- approvals

Notes:
- Idempotent schema creation on init.
- Minimal migration strategy: integer schema version.
- All JSON fields stored as TEXT (json dumps).
"""

from __future__ import annotations

import json
import sqlite3
import time
from typing import Any, Dict, List, Optional, Tuple

from core.contracts.run_schema import RunRecord, StepRecord, TraceEvent
from core.memory.base import ApprovalRecord, MemoryBackend, RunBundle

MAX_PAYLOAD_CHARS = 4096
SQLITE_TIMEOUT_SECONDS = 30.0
SQLITE_CHECK_SAME_THREAD = False
SQLITE_JOURNAL_MODE = "WAL"
SQLITE_SYNCHRONOUS = "NORMAL"


def _dumps(x: Any) -> str:
    return json.dumps(x, ensure_ascii=False)


def _dumps_payload(x: Any) -> str:
    """Clamp payload size to keep DB bounded."""
    raw = _dumps(x)
    if len(raw) > MAX_PAYLOAD_CHARS:
        return raw[:MAX_PAYLOAD_CHARS]
    return raw


def _loads(s: Optional[str], default: Any) -> Any:
    if s is None:
        return default
    try:
        return json.loads(s)
    except Exception:
        return default


def _enum_value(value: Any) -> Any:
    return value.value if hasattr(value, "value") else value


class SQLiteBackend(MemoryBackend):
    def __init__(self, *, db_path: str, initialize: bool = True) -> None:
        self.db_path = db_path
        if initialize:
            self._init_db()

    def _connect(self) -> sqlite3.Connection:
        con = sqlite3.connect(
            self.db_path,
            check_same_thread=SQLITE_CHECK_SAME_THREAD,
            timeout=SQLITE_TIMEOUT_SECONDS,
        )
        con.row_factory = sqlite3.Row
        con.execute(f"PRAGMA journal_mode={SQLITE_JOURNAL_MODE};")
        con.execute(f"PRAGMA synchronous={SQLITE_SYNCHRONOUS};")
        con.execute(f"PRAGMA busy_timeout={int(SQLITE_TIMEOUT_SECONDS * 1000)};")
        con.execute("PRAGMA foreign_keys=ON;")
        return con

    def _init_db(self) -> None:
        with self._connect() as con:
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS schema_version (
                  id INTEGER PRIMARY KEY CHECK (id = 1),
                  version INTEGER NOT NULL
                )
                """
            )
            cur = con.execute("SELECT version FROM schema_version WHERE id=1")
            row = cur.fetchone()
            if row is None:
                con.execute("INSERT INTO schema_version (id, version) VALUES (1, 1)")
                version = 1
            else:
                version = int(row["version"])

            if version < 1:
                self._migrate(con, from_version=version, to_version=1)

            # v1 schema
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS runs (
                  run_id TEXT PRIMARY KEY,
                  product TEXT NOT NULL,
                  flow TEXT NOT NULL,
                  status TEXT NOT NULL,
                  autonomy TEXT NOT NULL,
                  started_at INTEGER NOT NULL,
                  finished_at INTEGER,
                  input_json TEXT,
                  output_json TEXT,
                  summary_json TEXT
                )
                """
            )
            con.execute("CREATE INDEX IF NOT EXISTS idx_runs_status ON runs(status)")
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS steps (
                  run_id TEXT NOT NULL,
                  step_id TEXT NOT NULL,
                  step_index INTEGER NOT NULL,
                  name TEXT NOT NULL,
                  type TEXT NOT NULL,
                  status TEXT NOT NULL,
                  started_at INTEGER,
                  finished_at INTEGER,
                  input_json TEXT,
                  output_json TEXT,
                  error_json TEXT,
                  meta_json TEXT,
                  PRIMARY KEY (run_id, step_id)
                )
                """
            )
            con.execute("CREATE INDEX IF NOT EXISTS idx_steps_run_idx ON steps(run_id, step_index)")
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS events (
                  id INTEGER PRIMARY KEY AUTOINCREMENT,
                  run_id TEXT NOT NULL,
                  step_id TEXT,
                  product TEXT NOT NULL,
                  flow TEXT NOT NULL,
                  kind TEXT NOT NULL,
                  ts INTEGER NOT NULL,
                  payload_json TEXT
                )
                """
            )
            con.execute("CREATE INDEX IF NOT EXISTS idx_events_run_ts ON events(run_id, ts)")
            con.execute(
                """
                CREATE TABLE IF NOT EXISTS approvals (
                  approval_id TEXT PRIMARY KEY,
                  run_id TEXT NOT NULL,
                  step_id TEXT NOT NULL,
                  product TEXT NOT NULL,
                  flow TEXT NOT NULL,
                  status TEXT NOT NULL,
                  requested_by TEXT,
                  requested_at INTEGER NOT NULL,
                  resolved_by TEXT,
                  resolved_at INTEGER,
                  decision TEXT,
                  comment TEXT,
                  payload_json TEXT
                )
                """
            )
            con.execute("CREATE INDEX IF NOT EXISTS idx_approvals_status ON approvals(status, requested_at)")
            con.commit()

    def _migrate(self, con: sqlite3.Connection, *, from_version: int, to_version: int) -> None:
        # v1 only; placeholder for future migrations
        con.execute("UPDATE schema_version SET version=? WHERE id=1", (to_version,))
        con.commit()

    def ensure_schema(self) -> None:
        self._init_db()

    def get_schema_version(self) -> int:
        with self._connect() as con:
            try:
                cur = con.execute("SELECT version FROM schema_version WHERE id=1")
            except sqlite3.OperationalError:
                return 0
            row = cur.fetchone()
            return int(row["version"]) if row else 0

    # ------------------------------
    # Runs
    # ------------------------------

    def create_run(self, run: RunRecord) -> None:
        with self._connect() as con:
            con.execute(
                """
                INSERT OR REPLACE INTO runs (
                  run_id, product, flow, status, autonomy, started_at, finished_at,
                  input_json, output_json, summary_json
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    run.run_id,
                    run.product,
                    run.flow,
                    _enum_value(run.status),
                    run.autonomy_level,
                    int(run.started_at),
                    int(run.finished_at) if run.finished_at is not None else None,
                    _dumps(run.input) if run.input is not None else None,
                    _dumps(run.output) if run.output is not None else None,
                    _dumps(run.summary) if run.summary is not None else None,
                ),
            )
            con.commit()

    def update_run_status(self, run_id: str, status: str, *, summary: Optional[Dict[str, Any]] = None) -> None:
        finished_at = int(time.time()) if status in {"COMPLETED", "FAILED", "CANCELLED"} else None
        with self._connect() as con:
            if summary is None:
                con.execute(
                    "UPDATE runs SET status=?, finished_at=COALESCE(finished_at, ?) WHERE run_id=?",
                    (status, finished_at, run_id),
                )
            else:
                con.execute(
                    "UPDATE runs SET status=?, finished_at=COALESCE(finished_at, ?), summary_json=? WHERE run_id=?",
                    (status, finished_at, _dumps(summary), run_id),
                )
            con.commit()

    def update_run_output(self, run_id: str, *, output: Optional[Dict[str, Any]]) -> None:
        with self._connect() as con:
            con.execute(
                "UPDATE runs SET output_json=? WHERE run_id=?",
                (_dumps(output) if output is not None else None, run_id),
            )
            con.commit()

    # ------------------------------
    # Steps
    # ------------------------------

    def add_step(self, step: StepRecord) -> None:
        with self._connect() as con:
            con.execute(
                """
                INSERT OR REPLACE INTO steps (
                  run_id, step_id, step_index, name, type, status, started_at, finished_at,
                  input_json, output_json, error_json, meta_json
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    step.run_id,
                    step.step_id,
                    int(step.step_index),
                    step.name,
                    _enum_value(step.type),
                    _enum_value(step.status),
                    int(step.started_at) if step.started_at is not None else None,
                    int(step.finished_at) if step.finished_at is not None else None,
                    _dumps(step.input) if step.input is not None else None,
                    _dumps(step.output) if step.output is not None else None,
                    _dumps(step.error) if step.error is not None else None,
                    _dumps(step.meta) if step.meta is not None else None,
                ),
            )
            con.commit()

    def update_step(self, run_id: str, step_id: str, patch: Dict[str, Any]) -> None:
        # patch is a dict of fields that exist on StepRecord
        fields = []
        vals: List[Any] = []
        mapping = {
            "status": "status",
            "started_at": "started_at",
            "finished_at": "finished_at",
            "input": "input_json",
            "output": "output_json",
            "error": "error_json",
            "meta": "meta_json",
        }
        for k, col in mapping.items():
            if k not in patch:
                continue
            fields.append(f"{col}=?")
            v = patch[k]
            if col.endswith("_json"):
                vals.append(_dumps(v) if v is not None else None)
            else:
                vals.append(int(v) if k in {"started_at", "finished_at"} and v is not None else v)

        if not fields:
            return

        sql = f"UPDATE steps SET {', '.join(fields)} WHERE run_id=? AND step_id=?"
        vals.extend([run_id, step_id])

        with self._connect() as con:
            con.execute(sql, tuple(vals))
            con.commit()

    # ------------------------------
    # Events (Trace)
    # ------------------------------

    def add_event(self, event: TraceEvent) -> None:
        with self._connect() as con:
            con.execute(
                """
                INSERT INTO events (run_id, step_id, product, flow, kind, ts, payload_json)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    event.run_id,
                    event.step_id,
                    event.product,
                    event.flow,
                    event.kind,
                    int(event.ts),
                    _dumps_payload(event.payload) if event.payload is not None else None,
                ),
            )
            con.commit()

    # ------------------------------
    # Approvals (HITL)
    # ------------------------------

    def create_approval(self, approval: ApprovalRecord) -> None:
        with self._connect() as con:
            con.execute(
                """
                INSERT OR REPLACE INTO approvals (
                  approval_id, run_id, step_id, product, flow, status,
                  requested_by, requested_at, resolved_by, resolved_at, decision, comment, payload_json
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    approval.approval_id,
                    approval.run_id,
                    approval.step_id,
                    approval.product,
                    approval.flow,
                    approval.status,
                    approval.requested_by,
                    int(approval.requested_at),
                    approval.resolved_by,
                    int(approval.resolved_at) if approval.resolved_at is not None else None,
                    approval.decision,
                    approval.comment,
                    _dumps_payload(approval.payload) if approval.payload is not None else None,
                ),
            )
            con.commit()

    def resolve_approval(
        self,
        approval_id: str,
        *,
        decision: str,
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        now = int(time.time())
        status = "APPROVED" if decision.upper().startswith("APPROVE") else "REJECTED"
        with self._connect() as con:
            con.execute(
                """
                UPDATE approvals
                SET status=?, decision=?, resolved_by=?, comment=?, resolved_at=?
                WHERE approval_id=?
                """,
                (status, decision, resolved_by, comment, now, approval_id),
            )
            con.commit()

    # ------------------------------
    # Queries
    # ------------------------------

    def get_run(self, run_id: str) -> Optional[RunBundle]:
        with self._connect() as con:
            r = con.execute("SELECT * FROM runs WHERE run_id=?", (run_id,)).fetchone()
            if r is None:
                return None

            run = RunRecord(
                run_id=r["run_id"],
                product=r["product"],
                flow=r["flow"],
                status=r["status"],
                autonomy_level=r["autonomy"],
                started_at=int(r["started_at"]),
                finished_at=int(r["finished_at"]) if r["finished_at"] is not None else None,
                input=_loads(r["input_json"], None),
                output=_loads(r["output_json"], None),
                summary=_loads(r["summary_json"], None),
            )

            steps_rows = con.execute(
                "SELECT * FROM steps WHERE run_id=? ORDER BY step_index ASC",
                (run_id,),
            ).fetchall()
            steps: List[StepRecord] = []
            for s in steps_rows:
                steps.append(
                    StepRecord(
                        run_id=s["run_id"],
                        step_id=s["step_id"],
                        step_index=int(s["step_index"]),
                        name=s["name"],
                        type=s["type"],
                        status=s["status"],
                        started_at=int(s["started_at"]) if s["started_at"] is not None else None,
                        finished_at=int(s["finished_at"]) if s["finished_at"] is not None else None,
                        input=_loads(s["input_json"], None),
                        output=_loads(s["output_json"], None),
                        error=_loads(s["error_json"], None),
                        meta=_loads(s["meta_json"], None) or {},
                    )
                )

            events_rows = con.execute(
                "SELECT * FROM events WHERE run_id=? ORDER BY id ASC",
                (run_id,),
            ).fetchall()
            events: List[TraceEvent] = []
            for e in events_rows:
                events.append(
                    TraceEvent(
                        kind=e["kind"],
                        run_id=e["run_id"],
                        step_id=e["step_id"],
                        product=e["product"],
                        flow=e["flow"],
                        ts=int(e["ts"]),
                        payload=_loads(e["payload_json"], {}) or {},
                    )
                )

            approvals_rows = con.execute(
                "SELECT * FROM approvals WHERE run_id=? ORDER BY requested_at DESC",
                (run_id,),
            ).fetchall()
            approvals: List[ApprovalRecord] = []
            for a in approvals_rows:
                approvals.append(
                    ApprovalRecord(
                        approval_id=a["approval_id"],
                        run_id=a["run_id"],
                        step_id=a["step_id"],
                        product=a["product"],
                        flow=a["flow"],
                        status=a["status"],
                        requested_by=a["requested_by"],
                        requested_at=int(a["requested_at"]),
                        resolved_by=a["resolved_by"],
                        resolved_at=int(a["resolved_at"]) if a["resolved_at"] is not None else None,
                        decision=a["decision"],
                        comment=a["comment"],
                        payload=_loads(a["payload_json"], {}) or {},
                    )
                )

            return RunBundle(run=run, steps=steps, events=events, approvals=approvals)

    def list_runs(self, *, limit: int = 50, offset: int = 0) -> List[RunRecord]:
        with self._connect() as con:
            rows = con.execute(
                "SELECT * FROM runs ORDER BY started_at DESC LIMIT ? OFFSET ?",
                (limit, offset),
            ).fetchall()
            out: List[RunRecord] = []
            for r in rows:
                out.append(
                    RunRecord(
                        run_id=r["run_id"],
                        product=r["product"],
                        flow=r["flow"],
                        status=r["status"],
                        autonomy_level=r["autonomy"],
                        started_at=int(r["started_at"]),
                        finished_at=int(r["finished_at"]) if r["finished_at"] is not None else None,
                        input=_loads(r["input_json"], None),
                        output=_loads(r["output_json"], None),
                        summary=_loads(r["summary_json"], None),
                    )
                )
            return out


    def list_pending_approvals(self, *, limit: int = 50, offset: int = 0) -> List[ApprovalRecord]:
        with self._connect() as con:
            rows = con.execute(
                """
                SELECT * FROM approvals
                WHERE status='PENDING'
                ORDER BY requested_at DESC
                LIMIT ? OFFSET ?
                """,
                (limit, offset),
            ).fetchall()
            out: List[ApprovalRecord] = []
            for a in rows:
                out.append(
                    ApprovalRecord(
                        approval_id=a["approval_id"],
                        run_id=a["run_id"],
                        step_id=a["step_id"],
                        product=a["product"],
                        flow=a["flow"],
                        status=a["status"],
                        requested_by=a["requested_by"],
                        requested_at=int(a["requested_at"]),
                        resolved_by=a["resolved_by"],
                        resolved_at=int(a["resolved_at"]) if a["resolved_at"] is not None else None,
                        decision=a["decision"],
                        comment=a["comment"],
                        payload=_loads(a["payload_json"], {}) or {},
                    )
                )
            return out


# Backwards-compatible alias expected by older modules/tests
SQLiteMemoryBackend = SQLiteBackend

# core/memory/tracing.py
# ==============================
# Tracing Pipeline
# ==============================
"""
Tracing pipeline.

Responsibilities:
- Accept TraceEvent (contract)
- Scrub payload via SecurityRedactor
- Persist via MemoryBackend interface only
- Optionally mirror to logs

No direct sqlite calls here.
"""

from __future__ import annotations

import logging
from typing import Optional

from core.contracts.run_schema import TraceEvent
from core.config.schema import Settings
from core.governance.security import SecurityRedactor
from core.memory.base import MemoryBackend


class Tracer:
    def __init__(
        self,
        *,
        memory: MemoryBackend,
        logger: Optional[logging.Logger] = None,
        redactor: Optional[SecurityRedactor] = None,
        mirror_to_log: bool = True,
    ) -> None:
        self.memory = memory
        self.logger = logger or logging.getLogger("master.trace")
        self.redactor = redactor or SecurityRedactor()
        self.mirror_to_log = mirror_to_log

    def emit(self, event: TraceEvent) -> None:
        sanitized_payload = self.redactor.sanitize(event.payload)
        safe = event.model_copy(
            update={
                "payload": sanitized_payload,
                "redacted": sanitized_payload != event.payload,
            }
        )
        # Persist through backend interface only
        self.memory.append_trace_event(safe)

        if self.mirror_to_log:
            self.logger.info(
                "trace",
                extra={
                    "run_id": safe.run_id,
                    "step_id": safe.step_id,
                    "product": safe.product,
                    "flow": safe.flow,
                    "kind": safe.kind,
                },
            )

    @classmethod
    def from_settings(cls, *, settings: Settings, memory: MemoryBackend) -> "Tracer":
        """
        Convenience constructor for gateway/CLI wiring.
        """
        redactor = SecurityRedactor.from_settings(settings)
        mirror = bool(getattr(settings.logging, "console", True))
        return cls(memory=memory, redactor=redactor, mirror_to_log=mirror)

# core/models/__init__.py


# core/models/providers/__init__.py


# core/models/providers/openai_provider.py
# ==============================
# OpenAI Provider (Stub)
# ==============================
"""
OpenAI provider adapter stub.

Important:
- This file does NOT make real network calls in v1.
- No environment reads here.
- In v1, this is a placeholder so the rest of the platform compiles and routes calls
  through a provider boundary.

Later:
- Wire this provider to the real OpenAI SDK.
- Read API keys from core/config/loader.py injected config (never from this module).
- Add retry, timeouts, and structured error mapping to AgentError/ToolError envelopes.
"""

from __future__ import annotations

import json
import urllib.error
import urllib.request
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, ConfigDict, Field


class OpenAIRequest(BaseModel):
    model_config = ConfigDict(extra="forbid")

    model: str = Field(..., description="Model name (router sets this)")
    messages: List[Dict[str, Any]] = Field(default_factory=list)
    temperature: float = Field(default=0.2)
    max_tokens: Optional[int] = Field(default=None)
    metadata: Dict[str, Any] = Field(default_factory=dict)


class OpenAIResponse(BaseModel):
    model_config = ConfigDict(extra="forbid")

    ok: bool = Field(default=True)
    model: str = Field(...)
    content: str = Field(default="")
    usage: Dict[str, Any] = Field(default_factory=dict)
    error: Optional[Dict[str, Any]] = Field(default=None)
    meta: Dict[str, Any] = Field(default_factory=dict)


class OpenAIProvider:
    """
    Provider boundary for OpenAI.

    config shape (example):
{
  "api_base": "...",
  "api_key_ref": "secrets/openai_api_key"   # resolved by config loader later
}
    """

    def __init__(self, *, config: Optional[Dict[str, Any]] = None) -> None:
        self.config = config or {}

    def complete(self, request: OpenAIRequest) -> OpenAIResponse:
        api_key = self.config.get("api_key")
        if not api_key:
            return OpenAIResponse(
                ok=False,
                model=request.model,
                content="",
                error={"code": "missing_api_key", "message": "OpenAI API key is not configured."},
                meta={"provider": "openai"},
            )

        api_base = self.config.get("api_base") or "https://api.openai.com/v1"
        endpoint = f"{api_base.rstrip('/')}/chat/completions"
        payload: Dict[str, Any] = {
            "model": request.model,
            "messages": request.messages,
            "temperature": request.temperature,
        }
        if request.max_tokens is not None:
            payload["max_tokens"] = request.max_tokens

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        org_id = self.config.get("org_id")
        if _should_send_org_header(org_id):
            headers["OpenAI-Organization"] = org_id
        body = json.dumps(payload).encode("utf-8")
        timeout = float(self.config.get("timeout_seconds") or 30.0)
        req = urllib.request.Request(endpoint, data=body, headers=headers, method="POST")

        request_id = None
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                raw = resp.read().decode("utf-8")
                data = json.loads(raw)
                request_id = _extract_request_id(resp.headers)
        except urllib.error.HTTPError as exc:
            raw = exc.read().decode("utf-8")
            try:
                data = json.loads(raw)
            except Exception:
                data = {"error": {"message": "OpenAI HTTP error"}}
            status = getattr(exc, "code", None)
            request_id = _extract_request_id(exc.headers) if exc.headers else None
            body_snippet = _safe_body_snippet(raw)
            error_payload = dict(data.get("error", {}) or {})
            if not error_payload.get("message"):
                if body_snippet:
                    error_payload["message"] = f"OpenAI HTTP error: {body_snippet}"
                else:
                    error_payload["message"] = "OpenAI HTTP error"
            if body_snippet:
                error_payload["response_body"] = body_snippet
            return OpenAIResponse(
                ok=False,
                model=request.model,
                content="",
                error=_build_error(
                    error_payload,
                    status=status,
                    request_id=request_id,
                ),
                meta={"provider": "openai", "status": status},
            )
        except urllib.error.URLError as exc:
            return OpenAIResponse(
                ok=False,
                model=request.model,
                content="",
                error={"code": "network_error", "message": f"OpenAI network error: {exc.reason}"},
                meta={"provider": "openai"},
            )
        except TimeoutError:
            return OpenAIResponse(
                ok=False,
                model=request.model,
                content="",
                error={"code": "timeout", "message": "OpenAI request timed out"},
                meta={"provider": "openai"},
            )
        except Exception as exc:
            return OpenAIResponse(
                ok=False,
                model=request.model,
                content="",
                error={"code": "unknown", "message": f"OpenAI request failed: {exc}"},
                meta={"provider": "openai"},
            )

        try:
            choice = data["choices"][0]
            content = choice["message"]["content"]
        except Exception:
            content = ""
        usage = data.get("usage") or {}
        return OpenAIResponse(
            ok=True,
            model=request.model,
            content=content,
            usage=usage,
            meta={"provider": "openai", "request_id": request_id},
        )


def _stub_summarize(messages: List[Dict[str, Any]]) -> str:
    if not messages:
        return "OpenAIProvider stub: no messages provided."
    last = messages[-1]
    role = str(last.get("role", "user"))
    content = str(last.get("content", ""))
    content = content.strip()
    if len(content) > 400:
        content = content[:400] + ""
    return f"OpenAIProvider stub ({role}): {content}"


def _build_error(raw_error: Dict[str, Any], *, status: Optional[int], request_id: Optional[str]) -> Dict[str, Any]:
    message = str(raw_error.get("message") or "OpenAI request failed")
    err_type = str(raw_error.get("type") or "")
    code = str(raw_error.get("code") or "")
    retryable = bool(status in {429, 500, 502, 503, 504})
    if status == 401:
        err_code = "auth_error"
    elif status == 429:
        err_code = "rate_limited"
    elif status in {400, 404, 422}:
        err_code = "invalid_request"
    elif status is None:
        err_code = "unknown"
    else:
        err_code = "http_error"
    return {
        "code": err_code,
        "message": message,
        "http_status": status,
        "request_id": request_id,
        "retryable": retryable,
        "type": err_type,
        "provider_code": code,
        "response_body": raw_error.get("response_body"),
    }


def _safe_body_snippet(raw: str, *, limit: int = 500) -> str:
    if not raw:
        return ""
    snippet = raw[:limit]
    if "sk-" in snippet:
        snippet = snippet.replace("sk-", "[REDACTED]-")
    return snippet


def _should_send_org_header(org_id: Any) -> bool:
    if not isinstance(org_id, str):
        return False
    value = org_id.strip()
    if not value:
        return False
    upper = value.upper()
    if "PUT_" in upper or "PLACEHOLDER" in upper or "YOUR_" in upper or "ORG_ID" in upper:
        return False
    return True


def _extract_request_id(headers: Any) -> Optional[str]:
    if headers is None:
        return None
    return headers.get("x-request-id") or headers.get("openai-request-id") or headers.get("request-id")

# core/models/router.py
# ==============================
# Model Router
# ==============================
"""
Model routing for master/ (v1).

Goals:
- Centralize all model selection decisions behind a single interface.
- Avoid vendor-specific imports outside providers/.
- No env reads here. Configuration is injected by the caller.

v1 keeps this minimal:
- ModelRouter resolves a provider + model name based on simple inputs:
  product, purpose, and optional override fields.

Later upgrades can add:
- per-agent/per-flow overrides
- budget-aware routing
- fallback models
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Optional

from core.config.schema import Settings
from core.contracts.reasoning_schema import ReasoningPurpose
from core.governance.policies import PolicyEngine
from core.models.providers.openai_provider import OpenAIProvider, OpenAIRequest, OpenAIResponse


@dataclass(frozen=True)
class ModelSelection:
    provider: str
    model: str


class ModelRouter:
    """
    Minimal model router.

    Config shape (example):
{
  "default_provider": "openai",
  "default_model": "gpt-4o-mini",
  "by_product": {
     "agentaura": {"model": "gpt-4o"},
  },
  "by_purpose": {
     "reasoning": {"model": "gpt-4o"},
     "cheap": {"model": "gpt-4o-mini"}
  }
}
    """

    def __init__(
        self,
        *,
        config: Optional[Dict[str, Any]] = None,
        providers: Optional[Dict[str, Any]] = None,
        policy_engine: Optional[PolicyEngine] = None,
    ) -> None:
        self.config = config or {}
        self.providers = providers or {"openai": OpenAIProvider(config=self.config.get("openai", {}))}
        self.policy_engine = policy_engine

    def select(
        self,
        *,
        product: str,
        purpose: ReasoningPurpose,
        override_model: Optional[str] = None,
        override_provider: Optional[str] = None,
    ) -> ModelSelection:
        if override_provider and override_model:
            return ModelSelection(provider=override_provider, model=override_model)

        default_provider = str(self.config.get("default_provider", "openai"))
        default_model = str(self.config.get("default_model", "gpt-4o-mini"))

        by_product = self.config.get("by_product", {}) or {}
        by_purpose = self.config.get("by_purpose", {}) or {}

        model = default_model
        if isinstance(by_product, dict) and product in by_product and isinstance(by_product[product], dict):
            model = str(by_product[product].get("model", model))
        purpose_key = purpose.value
        if isinstance(by_purpose, dict) and purpose_key in by_purpose and isinstance(by_purpose[purpose_key], dict):
            model = str(by_purpose[purpose_key].get("model", model))

        provider = default_provider
        if override_provider:
            provider = override_provider
        if override_model:
            model = override_model

        selection = ModelSelection(provider=provider, model=model)

        if self.policy_engine is not None:
            decision = self.policy_engine.evaluate_model_selection(product=product, model_name=selection.model)
            if not decision.allow:
                raise PermissionError(decision.reason or "Model blocked by policy")

        return selection

    def completion_openai(
        self,
        *,
        product: str,
        purpose: ReasoningPurpose,
        request: OpenAIRequest,
        override_model: Optional[str] = None,
    ) -> OpenAIResponse:
        sel = self.select(product=product, purpose=purpose, override_model=override_model, override_provider="openai")
        provider = self._get_provider("openai")
        req = request.model_copy(
            update={
                "model": sel.model,
                "metadata": {
                    **(request.metadata or {}),
                    "router_provider": sel.provider,
                    "router_model": sel.model,
                    "reasoning_purpose": purpose.value,
                },
            },
        )
        return provider.complete(req)

    def _get_provider(self, name: str) -> Any:
        p = self.providers.get(name)
        if p is None:
            raise KeyError(f"Unknown model provider: {name}")
        return p

    @classmethod
    def from_settings(cls, settings: Settings, *, providers: Optional[Dict[str, Any]] = None) -> "ModelRouter":
        config = settings.models.routing.model_dump()
        config["openai"] = settings.models.openai.model_dump()
        policy_engine = PolicyEngine(settings)
        return cls(config=config, providers=providers, policy_engine=policy_engine)

# core/orchestrator/__init__.py


# core/orchestrator/context.py
# ==============================
# Orchestrator Context
# ==============================
"""
RunContext and StepContext for orchestrator execution.

Principles:
- Context is the in-memory working set for a run.
- Context is NOT persistence. Persistence happens via core/memory/* only.
- Context provides:
    - metadata (safe, non-secret)
    - artifacts (references + inline working objects)
    - trace hook placeholder (emit events via tracing pipeline elsewhere)

Intended usage:
- Orchestrator constructs RunContext at run start (or resume)
- Each step receives a StepContext derived from RunContext
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from typing import Any, Callable, Dict, Optional

from pydantic import BaseModel, ConfigDict, Field

from core.contracts.flow_schema import StepDef
from core.contracts.run_schema import RunStatus, StepStatus

TraceHook = Callable[[str, Dict[str, Any]], None]


class RunContext(BaseModel):
    """
    Lightweight run context shared across step execution.

    Provides:
    - run metadata (ids, payload, artifacts)
    - trace hook used by agents/tools

    RunContext is request-scoped; do not reuse across runs.
    """

    model_config = ConfigDict(extra="forbid", arbitrary_types_allowed=True)

    run_id: str
    product: str
    flow: str
    status: RunStatus = RunStatus.RUNNING
    payload: Dict[str, Any] = Field(default_factory=dict)
    artifacts: Dict[str, Any] = Field(default_factory=dict)
    meta: Dict[str, Any] = Field(default_factory=dict)
    trace: Optional[TraceHook] = Field(default=None)

    def emit(self, event_type: str, payload: Dict[str, Any]) -> None:
        if self.trace is None:
            return
        self.trace(event_type, payload)

    def new_step(
        self,
        step_def: Optional[StepDef] = None,
        *,
        step_id: Optional[str] = None,
        step_type: Optional[str] = None,
        backend: Optional[str] = None,
        target: Optional[str] = None,
    ) -> "StepContext":
        if step_def is not None:
            step_id = step_def.id or step_id or "step"
            step_type = step_def.type.value if hasattr(step_def.type, "value") else str(step_def.type)
            backend = backend or (step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend)
            target = target or step_def.agent or step_def.tool
        if step_id is None or step_type is None:
            raise ValueError("step_id and step_type are required when step_def is not provided")
        return StepContext(
            run=self,
            step=step_def,
            step_id=step_id,
            type=step_type,
            backend=backend,
            target=target,
        )


class StepContext(BaseModel):
    """Execution context for a single step."""

    model_config = ConfigDict(extra="forbid", arbitrary_types_allowed=True)

    run: RunContext
    step: Optional[StepDef] = Field(default=None)
    step_id: str
    type: str
    backend: Optional[str] = None
    target: Optional[str] = None
    status: StepStatus = StepStatus.NOT_STARTED
    attempt: int = 0

    def emit(self, event_type: str, payload: Dict[str, Any]) -> None:
        merged = {"step_id": self.step_id, **payload}
        self.run.emit(event_type, merged)

    @property
    def run_id(self) -> str:
        return self.run.run_id

    @property
    def product(self) -> str:
        return self.run.product

    @property
    def flow(self) -> str:
        return self.run.flow

# core/orchestrator/engine.py
# ==============================
# Orchestrator Engine
# ==============================
from __future__ import annotations

import hashlib
import json
import time
from datetime import datetime, timezone
from typing import Any, Callable, Dict, Optional, List
from uuid import uuid4

from core.agents.registry import AgentRegistry
from core.config.schema import Settings
from core.contracts.flow_schema import FlowDef, StepDef, StepType
from core.contracts.run_schema import (
    RunOperationResult,
    RunRecord,
    RunStatus,
    StepRecord,
    StepStatus,
    TraceEvent,
)
from core.contracts.user_input_schema import UserInputRequest, UserInputResponse, UserInputModes
from core.governance.hooks import GovernanceHooks
from core.governance.security import SecurityRedactor
from core.memory.tracing import Tracer
from core.memory.router import MemoryRouter
from core.orchestrator.context import RunContext
from core.orchestrator.flow_loader import FlowLoader
from core.orchestrator.hitl import HitlService
from core.orchestrator.state import is_valid_run_transition, to_run_state
from core.orchestrator.step_executor import StepExecutor
from core.tools.executor import ToolExecutor
from core.tools.registry import ToolRegistry


def _new_run_id() -> str:
    ts = datetime.now().strftime("%Y-%m-%d-%H%M%S%f")
    return f"run_{ts}_{uuid4().hex[:8]}"


def _payload_size_bytes(payload: Dict[str, Any]) -> int:
    try:
        raw = json.dumps(payload, ensure_ascii=True, separators=(",", ":"))
    except Exception:
        raw = str(payload)
    return len(raw.encode("utf-8"))


class OrchestratorEngine:
    """
    Orchestrator entrypoint. Holds only shared dependencies; all run state is request-scoped.
    """
    __slots__ = ("flow_loader", "step_executor", "memory", "tracer", "governance", "hitl")
    def __init__(
        self,
        *,
        flow_loader: FlowLoader,
        step_executor: StepExecutor,
        memory: MemoryRouter,
        tracer: Tracer,
        governance: GovernanceHooks,
    ) -> None:
        self.flow_loader = flow_loader
        self.step_executor = step_executor
        self.memory = memory
        self.tracer = tracer
        self.governance = governance
        self.hitl = HitlService(memory)

    @classmethod
    def from_settings(
        cls,
        settings: Settings,
        *,
        memory: Optional[MemoryRouter] = None,
        tracer: Optional[Tracer] = None,
        sleep_fn: Optional[Callable[[float], None]] = None,
    ) -> "OrchestratorEngine":
        repo_root = settings.repo_root_path()
        products_root = repo_root / settings.products.products_dir
        flow_loader = FlowLoader(products_root=products_root)
        memory_router = memory or MemoryRouter.from_settings(settings)
        redactor = SecurityRedactor.from_settings(settings)
        tracer_instance = tracer or Tracer.from_settings(settings=settings, memory=memory_router)
        governance = GovernanceHooks(settings=settings, redactor=redactor)
        tool_executor = ToolExecutor(registry=ToolRegistry, hooks=governance, redactor=redactor)
        step_executor = StepExecutor(
            tool_executor=tool_executor,
            governance=governance,
            agent_registry=AgentRegistry,
            sleep_fn=sleep_fn or time.sleep,
        )
        return cls(
            flow_loader=flow_loader,
            step_executor=step_executor,
            memory=memory_router,
            tracer=tracer_instance,
            governance=governance,
        )

    # ------------------------------------------------------------------ API
    def run_flow(
        self,
        *,
        product: str,
        flow: str,
        payload: Dict[str, Any],
        requested_by: Optional[str] = None,
    ) -> RunOperationResult:
        try:
            flow_def = self.flow_loader.load(product=product, flow=flow)
            run_id = _new_run_id()
            run_ctx = RunContext(run_id=run_id, product=product, flow=flow, payload=payload)
            run_ctx.trace = self._trace_hook(run_ctx)

            payload_limit = self.governance.settings.policies.max_payload_bytes
            if payload_limit is not None:
                size_bytes = _payload_size_bytes(payload)
                if size_bytes > payload_limit:
                    return self._reject_run(
                        run_id=run_id,
                        product=product,
                        flow=flow,
                        payload=payload,
                        code="payload_limit_exceeded",
                        message="Payload exceeds configured limit.",
                        details={"size_bytes": size_bytes, "limit_bytes": payload_limit},
                    )

            step_limit = self.governance.settings.policies.max_steps
            if step_limit is not None and len(flow_def.steps) > step_limit:
                return self._reject_run(
                    run_id=run_id,
                    product=product,
                    flow=flow,
                    payload=payload,
                    code="max_steps_exceeded",
                    message="Flow exceeds configured step limit.",
                    details={"step_count": len(flow_def.steps), "limit": step_limit},
                )

            autonomy_decision = self.governance.check_autonomy(
                run_ctx=run_ctx,
                autonomy=flow_def.autonomy_level,
            )
            if not autonomy_decision.allowed:
                now = int(time.time())
                run_record = RunRecord(
                    run_id=run_id,
                    product=product,
                    flow=flow,
                    status=RunStatus.FAILED,
                    autonomy_level=str(flow_def.autonomy_level.value),
                    started_at=now,
                    finished_at=now,
                    input=payload,
                    summary={
                        "error": autonomy_decision.reason or "autonomy_denied",
                        "autonomy_level": flow_def.autonomy_level.value,
                    },
                )
                self.memory.create_run(run_record)
                self._emit_event(
                    kind="autonomy_denied",
                    run_id=run_id,
                    step_id=None,
                    product=product,
                    flow=flow,
                    payload={
                        "reason": autonomy_decision.reason,
                        "autonomy_level": flow_def.autonomy_level.value,
                    },
                )
                return RunOperationResult.failure(
                    code="autonomy_denied",
                    message=autonomy_decision.reason or "Autonomy denied by policy.",
                )

            run_record = RunRecord(
                run_id=run_id,
                product=product,
                flow=flow,
                status=RunStatus.RUNNING,
                autonomy_level=str(flow_def.autonomy_level.value),
                input=payload,
                summary={
                    "current_step_index": 0,
                    "steps_executed": 0,
                    "tool_calls": 0,
                    "tokens_used": 0,
                },
            )
            self.memory.create_run(run_record)
            run_ctx.meta.update({"steps_executed": 0, "tool_calls": 0, "tokens_used": 0})
            self.memory.clear_staging(product=product, clear_input=False, clear_output=True)
            self._attach_run_dirs(run_ctx)
            self._stage_inputs(run_ctx)

            self._emit_event(
                kind="run_started",
                run_id=run_id,
                step_id=None,
                product=product,
                flow=flow,
                payload={"autonomy_level": flow_def.autonomy_level.value},
            )

            status = self._execute_from_index(
                flow_def=flow_def,
                run_ctx=run_ctx,
                start_index=0,
                requested_by=requested_by,
            )
            return RunOperationResult.success({"run_id": run_id, "status": status})
        except Exception as exc:
            return RunOperationResult.failure(code="run_failed", message=str(exc))

    def get_run(self, *, run_id: str) -> RunOperationResult:
        bundle = self.memory.get_run(run_id)
        if bundle is None:
            return RunOperationResult.failure(code="not_found", message=f"Unknown run_id: {run_id}")
        return RunOperationResult.success(
            {
                "run_id": run_id,
                "run": bundle.run.model_dump(),
                "steps": [s.model_dump() for s in bundle.steps],
                "approvals": [a.model_dump() for a in bundle.approvals],
            }
        )

    def resume_run(
        self,
        *,
        run_id: str,
        approval_payload: Optional[Dict[str, Any]] = None,
        user_input_response: Optional[Dict[str, Any]] = None,
        decision: str = "APPROVED",
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> RunOperationResult:
        bundle = self.memory.get_run(run_id)
        if bundle is None:
            return RunOperationResult.failure(code="not_found", message=f"Unknown run_id: {run_id}")

        if bundle.run.status == RunStatus.PENDING_USER_INPUT:
            return self._resume_user_input(
                bundle=bundle,
                user_input_response=user_input_response,
                resolved_by=resolved_by,
                comment=comment,
            )

        if bundle.run.status != RunStatus.PENDING_HUMAN:
            return RunOperationResult.failure(code="invalid_state", message="Run is not awaiting approval.")

        pending = [a for a in bundle.approvals if a.status == "PENDING"]
        if not pending:
            return RunOperationResult.failure(code="invalid_state", message="No pending approvals.")

        approval = pending[0]
        payload = approval_payload or {}
        if "approved" not in payload:
            return RunOperationResult.failure(code="missing_approval_field", message="Approval payload must include 'approved' flag.")

        self.hitl.resolve_approval(
            approval_id=approval.approval_id,
            decision=decision,
            resolved_by=resolved_by,
            comment=comment,
        )
        self.memory.append_run_comment(
            product=bundle.run.product,
            run_id=run_id,
            comment=comment,
            decision=decision,
            step_id=approval.step_id,
            ts=int(time.time()),
        )

        step_status = StepStatus.COMPLETED
        if not payload.get("approved") or decision.upper() != "APPROVED":
            step_status = StepStatus.FAILED

        self.memory.update_step(
            run_id,
            approval.step_id,
            {
                "status": step_status.value,
                "finished_at": int(time.time()),
                "output": {
                    "approval": {
                        "decision": decision,
                        "comment": comment,
                        "payload": payload,
                    }
                },
            },
        )

        if step_status == StepStatus.FAILED:
            if comment:
                replan_payload = dict(bundle.run.input or {})
                replan_payload.update(
                    {
                        "replan_comment": comment,
                        "previous_run": {
                            "run": bundle.run.model_dump(),
                            "steps": [s.model_dump() for s in bundle.steps],
                            "approvals": [a.model_dump() for a in bundle.approvals],
                        },
                    }
                )
                replan_flow = self.flow_loader.load(product=bundle.run.product, flow=bundle.run.flow)
                plan_index = None
                plan_def = None
                for idx, definition in enumerate(replan_flow.steps):
                    if (definition.id or f"step_{idx}") in {"plan", "planning"}:
                        plan_index = idx
                        plan_def = definition
                        break
                self._transition_run_status(
                    run_id=run_id,
                    product=bundle.run.product,
                    flow=bundle.run.flow,
                    current_status=bundle.run.status,
                    target_status=RunStatus.RUNNING,
                    step_id=approval.step_id,
                    summary={**(bundle.run.summary or {}), "current_step_index": plan_index or 0, "replan_of": run_id},
                    reason="replan_after_rejection",
                )
                replan_ctx = RunContext(
                    run_id=run_id,
                    product=bundle.run.product,
                    flow=bundle.run.flow,
                    payload=replan_payload,
                )
                self._init_run_meta(replan_ctx, summary=bundle.run.summary, steps=bundle.steps)
                replan_ctx.trace = self._trace_hook(replan_ctx)
                self._attach_run_dirs(replan_ctx)
                self._stage_inputs(replan_ctx)
                self._rehydrate_artifacts(bundle.steps, replan_ctx)
                self._emit_event(
                    kind="run_replan_started",
                    run_id=run_id,
                    step_id=None,
                    product=bundle.run.product,
                    flow=bundle.run.flow,
                    payload={"previous_run": run_id, "start_index": plan_index or 0},
                )
                next_index = 0
                if plan_def is not None and plan_index is not None:
                    replan_step_id = f"replan_plan_{int(time.time())}"
                    step_record = StepRecord(
                        run_id=run_id,
                        step_id=replan_step_id,
                        step_index=len(bundle.steps),
                        name=plan_def.name or "replan_plan",
                        type=plan_def.type.value,
                        status=StepStatus.RUNNING,
                        started_at=int(time.time()),
                        input={"params": plan_def.params or {}},
                        meta={"backend": plan_def.backend.value if getattr(plan_def.backend, "value", None) else plan_def.backend},
                    )
                    self.memory.add_step(step_record)
                    self._emit_event(
                        kind="step_started",
                        run_id=run_id,
                        step_id=replan_step_id,
                        product=bundle.run.product,
                        flow=bundle.run.flow,
                        payload={"step_index": step_record.step_index, "type": plan_def.type.value, "name": step_record.name},
                    )
                    try:
                        plan_result = self.step_executor.execute(run_ctx=replan_ctx, step_def=plan_def, step_id=replan_step_id)
                        self.memory.update_step(
                            run_id,
                            replan_step_id,
                            {"status": StepStatus.COMPLETED.value, "finished_at": int(time.time()), "output": plan_result},
                        )
                        self._emit_event(
                            kind="step_completed",
                            run_id=run_id,
                            step_id=replan_step_id,
                            product=bundle.run.product,
                            flow=bundle.run.flow,
                            payload={"ok": True},
                        )
                        next_index = self._resolve_plan_next_index(replan_flow, plan_index, plan_result)
                    except Exception as exc:
                        self.memory.update_step(
                            run_id,
                            replan_step_id,
                            {
                                "status": StepStatus.FAILED.value,
                                "finished_at": int(time.time()),
                                "error": {"message": str(exc), "type": type(exc).__name__},
                            },
                        )
                        self._transition_run_status(
                            run_id=run_id,
                            product=bundle.run.product,
                            flow=bundle.run.flow,
                            current_status=RunStatus.RUNNING,
                            target_status=RunStatus.FAILED,
                            step_id=replan_step_id,
                            summary=self._summary_with_counters(replan_ctx, {"failed_step_id": replan_step_id}),
                            reason="replan_failed",
                        )
                        self._emit_event(
                            kind="step_failed",
                            run_id=run_id,
                            step_id=replan_step_id,
                            product=bundle.run.product,
                            flow=bundle.run.flow,
                            payload={"error": {"message": str(exc), "type": type(exc).__name__}},
                        )
                        self._persist_run_output(replan_ctx)
                        return RunOperationResult.success({"run_id": run_id, "status": RunStatus.FAILED.value})
                status = self._execute_from_index(
                    flow_def=replan_flow,
                    run_ctx=replan_ctx,
                    start_index=next_index,
                    requested_by=resolved_by,
                )
                return RunOperationResult.success({"run_id": run_id, "status": status})
            self._transition_run_status(
                run_id=run_id,
                product=bundle.run.product,
                flow=bundle.run.flow,
                current_status=bundle.run.status,
                target_status=RunStatus.FAILED,
                step_id=approval.step_id,
                summary={**(bundle.run.summary or {}), "rejection": decision},
                reason="approval_rejected",
            )
            self._emit_event(
                kind="run_rejected",
                run_id=run_id,
                step_id=approval.step_id,
                product=bundle.run.product,
                flow=bundle.run.flow,
                payload={"decision": decision, "approved": payload.get("approved"), "comment": comment},
            )
            return RunOperationResult.success({"run_id": run_id, "status": RunStatus.FAILED.value})

        flow_def = self.flow_loader.load(product=bundle.run.product, flow=bundle.run.flow)
        next_index = self._find_step_index(flow_def, approval.step_id) + 1
        self._transition_run_status(
            run_id=run_id,
            product=bundle.run.product,
            flow=bundle.run.flow,
            current_status=bundle.run.status,
            target_status=RunStatus.RUNNING,
            step_id=approval.step_id,
            summary={**(bundle.run.summary or {}), "current_step_index": next_index},
            reason="approval_resumed",
        )
        self._emit_event(
            kind="run_resumed",
            run_id=run_id,
            step_id=approval.step_id,
            product=bundle.run.product,
            flow=bundle.run.flow,
            payload={"decision": decision, "comment": comment},
        )

        merged_payload = dict(bundle.run.input or {})
        merged_payload.update(payload)
        run_ctx = RunContext(run_id=run_id, product=bundle.run.product, flow=bundle.run.flow, payload=merged_payload)
        self._init_run_meta(run_ctx, summary=bundle.run.summary, steps=bundle.steps)
        run_ctx.trace = self._trace_hook(run_ctx)
        self._attach_run_dirs(run_ctx)
        self._rehydrate_artifacts(bundle.steps, run_ctx)

        status = self._execute_from_index(
            flow_def=flow_def,
            run_ctx=run_ctx,
            start_index=next_index,
            requested_by=resolved_by,
        )
        return RunOperationResult.success({"run_id": run_id, "status": status})

    def _resume_user_input(
        self,
        *,
        bundle,
        user_input_response: Optional[Dict[str, Any]],
        resolved_by: Optional[str],
        comment: Optional[str],
    ) -> RunOperationResult:
        response_payload = user_input_response or {}
        try:
            response = UserInputResponse.model_validate(response_payload)
        except Exception as exc:
            return RunOperationResult.failure(code="invalid_input", message=str(exc))

        flow_def = self.flow_loader.load(product=bundle.run.product, flow=bundle.run.flow)
        pending_step = next(
            (s for s in bundle.steps if _is_step_status(s.status, StepStatus.PENDING_USER_INPUT)),
            None,
        )
        if pending_step is None:
            return RunOperationResult.failure(code="invalid_state", message="No pending user input.")

        step_id = pending_step.step_id
        step_def = next((s for s in flow_def.steps if (s.id or "") == step_id), None)
        if step_def is None:
            return RunOperationResult.failure(code="invalid_state", message="Pending step not found in flow.")

        try:
            request = UserInputRequest.model_validate(step_def.params or {})
        except Exception as exc:
            return RunOperationResult.failure(code="invalid_state", message=str(exc))

        if response.form_id != request.form_id:
            return RunOperationResult.failure(code="invalid_input", message="form_id does not match pending request.")

        run_ctx = RunContext(run_id=bundle.run.run_id, product=bundle.run.product, flow=bundle.run.flow, payload=bundle.run.input or {})
        self._init_run_meta(run_ctx, summary=bundle.run.summary, steps=bundle.steps)
        run_ctx.trace = self._trace_hook(run_ctx)

        step_ctx = run_ctx.new_step(
            step_def=step_def,
            step_id=step_id,
            step_type=step_def.type.value,
            backend=step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend,
            target=step_def.agent or step_def.tool,
        )
        decision = self.governance.before_user_input_response(
            request=request.model_dump(mode="json"),
            response=response.model_dump(mode="json"),
            ctx=step_ctx,
        )
        if not decision.allowed:
            self._emit_event(
                kind="user_input_denied",
                run_id=bundle.run.run_id,
                step_id=step_id,
                product=bundle.run.product,
                flow=bundle.run.flow,
                payload={"reason": decision.reason, "details": decision.details},
            )
            return RunOperationResult.failure(code="policy_blocked", message=decision.reason, details=decision.details)

        errors = _validate_user_input_values(request, response.values)
        if errors:
            self._emit_event(
                kind="user_input_validation_failed",
                run_id=bundle.run.run_id,
                step_id=step_id,
                product=bundle.run.product,
                flow=bundle.run.flow,
                payload={"form_id": request.form_id, "errors": errors},
            )
            return RunOperationResult.failure(code="invalid_input", message="User input validation failed.", details={"errors": errors})

        self.memory.update_step(
            bundle.run.run_id,
            step_id,
            {
                "status": StepStatus.COMPLETED.value,
                "finished_at": int(time.time()),
                "output": {"user_input": response.model_dump(mode="json")},
            },
        )

        self.memory.write_user_input_response(
            product=bundle.run.product,
            run_id=bundle.run.run_id,
            form_id=request.form_id,
            payload=response.model_dump(mode="json"),
        )

        self._emit_event(
            kind="user_input_received",
            run_id=bundle.run.run_id,
            step_id=step_id,
            product=bundle.run.product,
            flow=bundle.run.flow,
            payload={
                "form_id": request.form_id,
                "mode": request.mode,
                "values": response.values,
                "comment": response.comment or comment or "",
            },
        )

        next_index = self._find_step_index(flow_def, step_id) + 1
        self._transition_run_status(
            run_id=bundle.run.run_id,
            product=bundle.run.product,
            flow=bundle.run.flow,
            current_status=bundle.run.status,
            target_status=RunStatus.RUNNING,
            step_id=step_id,
            summary={"current_step_index": next_index},
            reason="user_input_resumed",
        )

        self._attach_run_dirs(run_ctx)
        self._rehydrate_artifacts(bundle.steps, run_ctx)
        _store_user_input_artifacts(run_ctx, request.form_id, response.values, response.comment)

        status = self._execute_from_index(
            flow_def=flow_def,
            run_ctx=run_ctx,
            start_index=next_index,
            requested_by=resolved_by,
        )
        return RunOperationResult.success({"run_id": bundle.run.run_id, "status": status})

    # ------------------------------------------------------------------ internals
    def _trace_hook(self, run_ctx: RunContext):
        def _hook(event_type: str, payload: Dict[str, Any]) -> None:
            self._emit_event(
                kind=event_type,
                run_id=run_ctx.run_id,
                step_id=payload.get("step_id"),
                product=run_ctx.product,
                flow=run_ctx.flow,
                payload=payload,
            )

        return _hook

    def _transition_run_status(
        self,
        *,
        run_id: str,
        product: str,
        flow: str,
        current_status: RunStatus | str,
        target_status: RunStatus | str,
        step_id: Optional[str],
        summary: Optional[Dict[str, Any]] = None,
        reason: Optional[str] = None,
    ) -> RunStatus:
        current = _coerce_run_status(current_status)
        target = _coerce_run_status(target_status)
        if not is_valid_run_transition(current, target):
            raise ValueError(f"Invalid run transition: {to_run_state(current).value} -> {to_run_state(target).value}")
        if current != target:
            self._emit_event(
                kind="run_state_transition",
                run_id=run_id,
                step_id=step_id,
                product=product,
                flow=flow,
                payload={
                    "from": to_run_state(current).value,
                    "to": to_run_state(target).value,
                    "reason": reason or "",
                },
            )
        self.memory.update_run_status(run_id, target.value, summary=summary)
        return target

    def _execute_from_index(
        self,
        *,
        flow_def: FlowDef,
        run_ctx: RunContext,
        start_index: int,
        requested_by: Optional[str],
    ) -> str:
        idx = start_index
        current_status = RunStatus.RUNNING
        last_result_data: Optional[Dict[str, Any]] = None
        while idx < len(flow_def.steps):
            step_def = flow_def.steps[idx]
            step_id = step_def.id or f"step_{idx}"
            if idx > 0:
                prev_def = flow_def.steps[idx - 1]
                if (
                    prev_def.type == StepType.USER_INPUT
                    and (prev_def.params or {}).get("mode") == UserInputModes.FREE_TEXT_INPUT
                    and step_def.type in {StepType.AGENT, StepType.TOOL}
                ):
                    self._transition_run_status(
                        run_id=run_ctx.run_id,
                        product=run_ctx.product,
                        flow=run_ctx.flow,
                        current_status=current_status,
                        target_status=RunStatus.FAILED,
                        step_id=step_id,
                        summary={"failed_step_id": step_id},
                        reason="free_text_guard_blocked",
                    )
                    current_status = RunStatus.FAILED
                    self._emit_event(
                        kind="free_text_guard_blocked",
                        run_id=run_ctx.run_id,
                        step_id=step_id,
                        product=run_ctx.product,
                        flow=run_ctx.flow,
                        payload={"message": "Free-text input cannot directly trigger tools or agents."},
                    )
                    self._persist_run_output(run_ctx)
                    return RunStatus.FAILED.value

            step_record = StepRecord(
                run_id=run_ctx.run_id,
                step_id=step_id,
                step_index=idx,
                name=step_def.name or step_id,
                type=step_def.type.value,
                status=StepStatus.RUNNING,
                started_at=int(time.time()),
                input={"params": step_def.params or {}},
                meta={"backend": step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend},
            )
            self.memory.add_step(step_record)

            step_ctx = run_ctx.new_step(
                step_def=step_def,
                step_id=step_id,
                step_type=step_def.type.value,
                backend=step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend,
                target=step_def.agent or step_def.tool,
            )

            decision = self.governance.before_step(step_ctx=step_ctx)
            if not decision.allowed:
                self._emit_event(
                    kind="before_step_denied",
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    payload={"reason": decision.reason},
                )
                self.memory.update_step(
                    run_ctx.run_id,
                    step_id,
                    {
                        "status": StepStatus.FAILED.value,
                        "finished_at": int(time.time()),
                        "error": {"message": decision.reason, "type": "PermissionError"},
                    },
                )
                self._transition_run_status(
                    run_id=run_ctx.run_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    current_status=current_status,
                    target_status=RunStatus.FAILED,
                    step_id=step_id,
                    summary=self._summary_with_counters(run_ctx, {"failed_step_id": step_id, "reason": decision.reason}),
                    reason="governance_denied",
                )
                current_status = RunStatus.FAILED
                self._persist_run_output(run_ctx)
                return RunStatus.FAILED.value

            run_ctx.meta["steps_executed"] = int(run_ctx.meta.get("steps_executed", 0)) + 1

            self._emit_event(
                kind="step_started",
                run_id=run_ctx.run_id,
                step_id=step_id,
                product=run_ctx.product,
                flow=run_ctx.flow,
                payload={"step_index": idx, "type": step_def.type.value, "name": step_record.name},
            )

            if step_def.type == StepType.HUMAN_APPROVAL:
                approval_payload = self._build_approval_payload(run_ctx, step_record, step_def)
                approval = self.hitl.create_approval(
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    requested_by=requested_by,
                    payload=approval_payload,
                )
                self.memory.update_step(
                    run_ctx.run_id,
                    step_id,
                    {
                        "status": StepStatus.PENDING_HUMAN.value,
                        "output": {"approval_id": approval.approval_id},
                    },
                )
                current_status = self._transition_run_status(
                    run_id=run_ctx.run_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    current_status=current_status,
                    target_status=RunStatus.PENDING_HUMAN,
                    step_id=step_id,
                    summary=self._summary_with_counters(run_ctx, {"current_step_index": idx}),
                    reason="approval_requested",
                )
                self._emit_event(
                    kind="pending_human",
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    payload={
                        "approval_id": approval.approval_id,
                        "approval_context": approval_payload.get("approval_context"),
                    },
                )
                return RunStatus.PENDING_HUMAN.value

            if step_def.type == StepType.USER_INPUT:
                try:
                    request = UserInputRequest.model_validate(step_def.params or {})
                except Exception as exc:
                    self.memory.update_step(
                        run_ctx.run_id,
                        step_id,
                        {
                            "status": StepStatus.FAILED.value,
                            "finished_at": int(time.time()),
                            "error": {"message": str(exc), "type": type(exc).__name__},
                        },
                    )
                self._transition_run_status(
                    run_id=run_ctx.run_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    current_status=current_status,
                    target_status=RunStatus.FAILED,
                    step_id=step_id,
                    summary=self._summary_with_counters(run_ctx, {"failed_step_id": step_id}),
                    reason="user_input_invalid_request",
                )
                current_status = RunStatus.FAILED
                    self._emit_event(
                        kind="step_failed",
                        run_id=run_ctx.run_id,
                        step_id=step_id,
                        product=run_ctx.product,
                        flow=run_ctx.flow,
                        payload={"error": {"message": str(exc), "type": type(exc).__name__}},
                    )
                    self._persist_run_output(run_ctx)
                    return RunStatus.FAILED.value

                schema_summary = _summarize_schema(request.schema)
                self._emit_event(
                    kind="user_input_requested",
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    payload={
                        "form_id": request.form_id,
                        "title": request.title,
                        "mode": request.mode,
                        "required": request.required,
                        "defaults": request.defaults,
                        "schema_summary": schema_summary,
                    },
                )
                self.memory.update_step(
                    run_ctx.run_id,
                    step_id,
                    {
                        "status": StepStatus.PENDING_USER_INPUT.value,
                        "output": {"user_input_request": {"form_id": request.form_id}},
                    },
                )
                current_status = self._transition_run_status(
                    run_id=run_ctx.run_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    current_status=current_status,
                    target_status=RunStatus.PENDING_USER_INPUT,
                    step_id=step_id,
                    summary=self._summary_with_counters(
                        run_ctx,
                        {"current_step_index": idx, "form_id": request.form_id},
                    ),
                    reason="user_input_requested",
                )
                return RunStatus.PENDING_USER_INPUT.value

            if step_def.type == StepType.PLAN_PROPOSAL:
                if step_def.agent is None:
                    self._transition_run_status(
                        run_id=run_ctx.run_id,
                        product=run_ctx.product,
                        flow=run_ctx.flow,
                        current_status=current_status,
                        target_status=RunStatus.FAILED,
                        step_id=step_id,
                        summary=self._summary_with_counters(run_ctx, {"failed_step_id": step_id}),
                        reason="plan_proposal_missing_agent",
                    )
                    current_status = RunStatus.FAILED
                    self._emit_event(
                        kind="step_failed",
                        run_id=run_ctx.run_id,
                        step_id=step_id,
                        product=run_ctx.product,
                        flow=run_ctx.flow,
                        payload={"error": {"message": "plan_proposal step missing agent", "type": "ValueError"}},
                    )
                    self._persist_run_output(run_ctx)
                    return RunStatus.FAILED.value

            try:
                result = self.step_executor.execute(run_ctx=run_ctx, step_def=step_def, step_id=step_id)
                result = self._persist_output_files(run_ctx, result)
                if isinstance(result, dict):
                    data = result.get("data")
                    if isinstance(data, dict) and data:
                        last_result_data = data
                self.memory.update_step(
                    run_ctx.run_id,
                    step_id,
                    {"status": StepStatus.COMPLETED.value, "finished_at": int(time.time()), "output": result},
                )
                self._emit_event(
                    kind="step_completed",
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    payload={"ok": True},
                )
            except Exception as exc:
                self.memory.update_step(
                    run_ctx.run_id,
                    step_id,
                    {
                        "status": StepStatus.FAILED.value,
                        "finished_at": int(time.time()),
                        "error": {"message": str(exc), "type": type(exc).__name__},
                    },
                )
                self._transition_run_status(
                    run_id=run_ctx.run_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    current_status=current_status,
                    target_status=RunStatus.FAILED,
                    step_id=step_id,
                    summary=self._summary_with_counters(run_ctx, {"failed_step_id": step_id}),
                    reason="step_failed",
                )
                current_status = RunStatus.FAILED
                self._emit_event(
                    kind="step_failed",
                    run_id=run_ctx.run_id,
                    step_id=step_id,
                    product=run_ctx.product,
                    flow=run_ctx.flow,
                    payload={"error": {"message": str(exc), "type": type(exc).__name__}},
                )
                self._persist_run_output(run_ctx)
                return RunStatus.FAILED.value

            next_index = idx + 1
            if step_id in {"plan", "planning"}:
                next_index = self._resolve_plan_next_index(flow_def, idx, result)
            self.memory.update_run_status(
                run_ctx.run_id,
                RunStatus.RUNNING.value,
                summary=self._summary_with_counters(run_ctx, {"current_step_index": next_index}),
            )
            idx = next_index

        if last_result_data is None:
        self._transition_run_status(
            run_id=run_ctx.run_id,
            product=run_ctx.product,
            flow=run_ctx.flow,
            current_status=current_status,
            target_status=RunStatus.FAILED,
            step_id="output",
            summary=self._summary_with_counters(run_ctx, {"failed_step_id": "output", "reason": "missing_run_output"}),
            reason="missing_run_output",
        )
            self._emit_event(
                kind="run_failed",
                run_id=run_ctx.run_id,
                step_id=None,
                product=run_ctx.product,
                flow=run_ctx.flow,
                payload={"error": {"message": "Missing run output", "type": "RuntimeError"}},
            )
            self._persist_run_output(run_ctx)
            return RunStatus.FAILED.value

        normalized_output = self._normalize_run_output(last_result_data)
        decision = self.governance.before_run_output(output=normalized_output, run_ctx=run_ctx)
        if not decision.allowed:
            self._transition_run_status(
                run_id=run_ctx.run_id,
                product=run_ctx.product,
                flow=run_ctx.flow,
                current_status=current_status,
                target_status=RunStatus.FAILED,
                step_id="output",
                summary=self._summary_with_counters(run_ctx, {"failed_step_id": "output", "reason": decision.reason}),
                reason="output_denied",
            )
            self._emit_event(
                kind="output_denied",
                run_id=run_ctx.run_id,
                step_id=None,
                product=run_ctx.product,
                flow=run_ctx.flow,
                payload={"reason": decision.reason, "details": decision.details},
            )
            self._persist_run_output(run_ctx)
            return RunStatus.FAILED.value
        self.memory.update_run_output(run_ctx.run_id, output=normalized_output)
        self._transition_run_status(
            run_id=run_ctx.run_id,
            product=run_ctx.product,
            flow=run_ctx.flow,
            current_status=current_status,
            target_status=RunStatus.COMPLETED,
            step_id=None,
            summary=self._summary_with_counters(run_ctx, {"current_step_index": len(flow_def.steps)}),
            reason="run_completed",
        )
        self._emit_event(
            kind="run_completed",
            run_id=run_ctx.run_id,
            step_id=None,
            product=run_ctx.product,
            flow=run_ctx.flow,
            payload={"ok": True},
        )
        self._persist_run_output(run_ctx)
        return RunStatus.COMPLETED.value

    def _normalize_run_output(self, data: Dict[str, Any]) -> Dict[str, Any]:
        data = {k: v for k, v in data.items() if k != "output_files"}
        summary = data.get("summary")
        details = data.get("details")
        if isinstance(summary, str) and isinstance(details, dict):
            output = dict(details)
            output["summary"] = summary
            return output
        return data

    def _persist_output_files(self, run_ctx: RunContext, result: Dict[str, Any]) -> Dict[str, Any]:
        if not isinstance(result, dict):
            return result
        data = result.get("data")
        if not isinstance(data, dict):
            return result
        files = data.get("output_files")
        if not isinstance(files, list) or not files:
            return result
        decision = self.governance.before_output_files(files=files, run_ctx=run_ctx)
        if not decision.allowed:
            self._emit_event(
                kind="output_files_denied",
                run_id=run_ctx.run_id,
                step_id=None,
                product=run_ctx.product,
                flow=run_ctx.flow,
                payload={"reason": decision.reason, "details": decision.details},
            )
            raise RuntimeError(decision.reason or "output_files_denied")
        stored = self.memory.write_output_files(product=run_ctx.product, run_id=run_ctx.run_id, files=files) or []
        updated = dict(result)
        updated_data = dict(data)
        updated_data["output_files"] = stored
        updated["data"] = updated_data
        return updated

    def _find_step_index(self, flow_def: FlowDef, step_id: str) -> int:
        for idx, definition in enumerate(flow_def.steps):
            if (definition.id or f"step_{idx}") == step_id:
                return idx
        raise ValueError(f"Cannot map approval step '{step_id}' to flow definition.")

    def _resolve_plan_next_index(self, flow_def: FlowDef, current_index: int, result: Dict[str, Any]) -> int:
        data = result.get("data") if isinstance(result, dict) else None
        start_index = None
        if isinstance(data, dict):
            candidate_index = data.get("start_index")
            if isinstance(candidate_index, int):
                start_index = candidate_index
            else:
                for key in ("start_step_id", "start_from", "start_step", "start_at"):
                    step_id = data.get(key)
                    if step_id:
                        try:
                            start_index = self._find_step_index(flow_def, step_id)
                        except ValueError:
                            start_index = None
                        break
        if start_index is None:
            return current_index + 1
        if start_index <= current_index:
            return current_index + 1
        if start_index > len(flow_def.steps):
            return len(flow_def.steps)
        return start_index

    def _emit_event(
        self,
        *,
        kind: str,
        run_id: str,
        step_id: Optional[str],
        product: str,
        flow: str,
        payload: Dict[str, Any],
    ) -> None:
        evt = TraceEvent(
            kind=kind,
            run_id=run_id,
            step_id=step_id,
            product=product,
            flow=flow,
            ts=int(time.time()),
            payload=payload,
        )
        self.tracer.emit(evt)

    def _reject_run(
        self,
        *,
        run_id: str,
        product: str,
        flow: str,
        payload: Dict[str, Any],
        code: str,
        message: str,
        details: Dict[str, Any],
    ) -> RunOperationResult:
        now = int(time.time())
        run_record = RunRecord(
            run_id=run_id,
            product=product,
            flow=flow,
            status=RunStatus.FAILED,
            autonomy_level=None,
            started_at=now,
            finished_at=now,
            input=payload,
            summary={"error": {"code": code, "message": message, "details": details}},
        )
        self.memory.create_run(run_record)
        self._emit_event(
            kind="run_rejected",
            run_id=run_id,
            step_id=None,
            product=product,
            flow=flow,
            payload={"code": code, "message": message, "details": details},
        )
        error_details = dict(details)
        error_details["run_id"] = run_id
        return RunOperationResult.failure(code=code, message=message, details=error_details)

    def _persist_run_output(self, run_ctx: RunContext) -> None:
        bundle = self.memory.get_run(run_ctx.run_id)
        if bundle is None:
            return
        run = bundle.run
        status = run.status.value if hasattr(run.status, "value") else str(run.status)
        result = run.output if status == RunStatus.COMPLETED.value else None
        if isinstance(result, dict) and "output_files" in result:
            result = {k: v for k, v in result.items() if k != "output_files"}
        if status == RunStatus.COMPLETED.value and result is None:
            status = RunStatus.FAILED.value
            error = {"code": "missing_output", "message": "Missing run output", "step_id": None, "details": {}}
        error = None
        if status != RunStatus.COMPLETED.value:
            failed = next((s for s in bundle.steps if s.status == StepStatus.FAILED), None)
            if failed:
                if failed.error and isinstance(failed.error, dict):
                    error = {
                        "code": "step_failed",
                        "message": failed.error.get("message") or "Step failed.",
                        "step_id": failed.step_id,
                        "details": failed.error,
                    }
                else:
                    error = {"code": "step_failed", "message": "Step failed.", "step_id": failed.step_id, "details": {}}
            elif run.summary:
                error = {
                    "code": "run_failed",
                    "message": run.summary.get("reason") or run.summary.get("error") or "Run failed.",
                    "step_id": None,
                    "details": run.summary or {},
                }
        response = {
            "response_version": "1.0",
            "run_id": run.run_id,
            "product": run.product,
            "flow": run.flow,
            "status": status,
            "result": result if status != RunStatus.COMPLETED.value else (result or {"kind": "files"}),
            "error": error,
            "finished_at": run.finished_at,
            "finished_at_iso": datetime.fromtimestamp(run.finished_at, tz=timezone.utc).isoformat()
            if run.finished_at
            else None,
        }
        output_info = self.memory.write_run_response(product=run.product, run_id=run.run_id, response=response)
        if output_info:
            self._emit_event(
                kind="output_written",
                run_id=run.run_id,
                step_id=None,
                product=run.product,
                flow=run.flow,
                payload=output_info,
            )

    def _rehydrate_artifacts(self, steps: List[StepRecord], run_ctx: RunContext) -> None:
        for step in steps:
            output = step.output or {}
            if not isinstance(output, dict):
                continue
            meta = output.get("meta")
            data = output.get("data")
            if not isinstance(meta, dict) or data is None:
                user_input = output.get("user_input")
                if isinstance(user_input, dict):
                    form_id = user_input.get("form_id")
                    values = user_input.get("values")
                    comment = user_input.get("comment")
                    if isinstance(form_id, str) and isinstance(values, dict):
                        _store_user_input_artifacts(run_ctx, form_id, values, comment)
                continue
            tool_name = meta.get("tool_name")
            agent_name = meta.get("agent_name")
            if tool_name:
                run_ctx.artifacts[f"tool.{tool_name}.output"] = data
                run_ctx.artifacts[f"tool.{tool_name}.meta"] = meta
            if agent_name:
                run_ctx.artifacts[f"agent.{agent_name}.output"] = data
                run_ctx.artifacts[f"agent.{agent_name}.meta"] = meta

    def _init_run_meta(
        self,
        run_ctx: RunContext,
        *,
        summary: Optional[Dict[str, Any]] = None,
        steps: Optional[List[StepRecord]] = None,
    ) -> None:
        summary = summary or {}
        def _as_int(value: Any) -> Optional[int]:
            try:
                return int(value)
            except Exception:
                return None

        steps_executed = _as_int(summary.get("steps_executed"))
        if steps_executed is None and steps is not None:
            steps_executed = sum(1 for s in steps if not _is_step_status(s.status, StepStatus.NOT_STARTED))
        run_ctx.meta["steps_executed"] = steps_executed or 0
        run_ctx.meta["tool_calls"] = _as_int(summary.get("tool_calls")) or 0
        run_ctx.meta["tokens_used"] = _as_int(summary.get("tokens_used")) or 0

    @staticmethod
    def _summary_with_counters(run_ctx: RunContext, summary: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        merged = dict(summary or {})
        for key in ("steps_executed", "tool_calls", "tokens_used"):
            if key in run_ctx.meta:
                merged[key] = run_ctx.meta.get(key)
        return merged

    def _stage_inputs(self, run_ctx: RunContext) -> None:
        self.memory.ensure_observability_dirs(product=run_ctx.product, run_id=run_ctx.run_id)
        payload = run_ctx.payload or {}
        self.memory.capture_run_input(product=run_ctx.product, run_id=run_ctx.run_id, payload=payload)
        self.memory.move_staged_inputs_to_run(product=run_ctx.product, run_id=run_ctx.run_id)

    def _attach_run_dirs(self, run_ctx: RunContext) -> None:
        paths = self.memory.get_observability_dirs(product=run_ctx.product, run_id=run_ctx.run_id)
        if not paths:
            return
        input_dir = paths.get("input")
        output_dir = paths.get("output")
        if input_dir:
            run_ctx.meta["input_dir"] = str(input_dir)
        if output_dir:
            run_ctx.meta["output_dir"] = str(output_dir)

    def _build_approval_payload(self, run_ctx: RunContext, step_record: StepRecord, step_def: StepDef) -> Dict[str, Any]:
        intent = (
            run_ctx.payload.get("prompt")
            or run_ctx.payload.get("intent")
            or run_ctx.payload.get("instructions")
            or run_ctx.payload.get("notes")
            or ""
        )
        params = step_def.params or {}
        approval_context = params.get("approval_context") if isinstance(params, dict) else None
        return {
            "step": step_record.model_dump(),
            "intent": intent,
            "approval_context": approval_context,
            "artifacts": {"keys": sorted(run_ctx.artifacts.keys())},
        }

# Backwards compatibility for older imports/tests
Engine = OrchestratorEngine


def _summarize_schema(schema: Dict[str, Any]) -> Dict[str, Any]:
    try:
        encoded = json.dumps(schema, sort_keys=True, ensure_ascii=True).encode("utf-8")
        digest = hashlib.sha256(encoded).hexdigest()
    except Exception:
        digest = "unknown"
    props = schema.get("properties") if isinstance(schema, dict) else {}
    prop_keys = []
    if isinstance(props, dict):
        prop_keys = list(props.keys())
    return {"properties": prop_keys[:10], "property_count": len(prop_keys), "sha256": digest}


def _validate_user_input_values(request: UserInputRequest, values: Dict[str, Any]) -> List[str]:
    errors: List[str] = []
    mode = request.mode or UserInputModes.CHOICE_INPUT
    if mode == UserInputModes.FREE_TEXT_INPUT:
        text_value = values.get("text")
        if not isinstance(text_value, str) or not text_value.strip():
            errors.append("missing_or_empty:text")
        return errors
    if mode != UserInputModes.CHOICE_INPUT:
        errors.append("invalid_mode")
        return errors
    for key in request.required:
        if key not in values:
            errors.append(f"missing_required:{key}")
    props = request.schema.get("properties") if isinstance(request.schema, dict) else {}
    if isinstance(props, dict):
        for key, spec in props.items():
            if key not in values:
                continue
            value = values.get(key)
            if not isinstance(spec, dict):
                continue
            expected_type = spec.get("type")
            if expected_type:
                if expected_type == "string" and not isinstance(value, str):
                    errors.append(f"type_mismatch:{key}")
                if expected_type == "number" and not isinstance(value, (int, float)):
                    errors.append(f"type_mismatch:{key}")
                if expected_type == "integer" and not isinstance(value, int):
                    errors.append(f"type_mismatch:{key}")
                if expected_type == "boolean" and not isinstance(value, bool):
                    errors.append(f"type_mismatch:{key}")
            enum = spec.get("enum")
            if isinstance(enum, list) and value not in enum:
                errors.append(f"enum_mismatch:{key}")
    return errors


def _store_user_input_artifacts(run_ctx: RunContext, form_id: str, values: Dict[str, Any], comment: Optional[str]) -> None:
    bucket = run_ctx.artifacts.setdefault("user_input", {})
    if isinstance(bucket, dict):
        bucket[form_id] = {"values": values, "comment": comment or ""}


def _is_step_status(value: Any, status: StepStatus) -> bool:
    if isinstance(value, StepStatus):
        return value == status
    if isinstance(value, str):
        return value == status.value
    return False


def _coerce_run_status(value: RunStatus | str) -> RunStatus:
    if isinstance(value, RunStatus):
        return value
    try:
        return RunStatus(value)
    except Exception:
        return RunStatus.RUNNING

# core/orchestrator/error_policy.py
# ==============================
# Error Policy
# ==============================
"""
Retry/backoff policy evaluation for orchestrator steps.

This module is intentionally small and pure:
- No persistence
- No tool calls
- No environment reads

Intended usage:
- Step executor consults should_retry(...) after failures
- Orchestrator uses backoff_seconds(...) to sleep externally (if desired)
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Sequence

from core.contracts.flow_schema import RetryPolicy

# ==============================
# Decision Model
# ==============================
@dataclass(frozen=True)
class RetryDecision:
    """Result of evaluating whether a retry should occur."""
    should_retry: bool
    reason: str
    next_backoff_seconds: float


# ==============================
# Policy Evaluation
# ==============================
def evaluate_retry(
    *,
    attempt_index: int,
    retry_policy: Optional[RetryPolicy],
    error_code: Optional[str] = None,
) -> RetryDecision:
    """
    Evaluate retry decision for a failed attempt.

    Parameters:
    - attempt_index: 1-based attempt number (1 = first attempt already executed)
    - retry_policy: RetryPolicy or None
    - error_code: Optional string code from error envelope

    Returns:
    - RetryDecision including should_retry and backoff
    """
    if retry_policy is None:
        return RetryDecision(False, "no_retry_policy", 0.0)

    max_attempts = retry_policy.max_attempts
    if attempt_index >= max_attempts:
        return RetryDecision(False, "max_attempts_reached", 0.0)

    if not _is_retryable_code(error_code, retry_policy.retry_on_codes):
        return RetryDecision(False, "error_code_not_retryable", 0.0)

    return RetryDecision(True, "retry_allowed", float(retry_policy.backoff_seconds))


def backoff_seconds(retry_policy: Optional[RetryPolicy]) -> float:
    """Return backoff seconds for a retry policy (0.0 if none)."""
    if retry_policy is None:
        return 0.0
    return float(retry_policy.backoff_seconds)


# ==============================
# Helpers
# ==============================
def _is_retryable_code(error_code: Optional[str], retry_on_codes: Sequence[str]) -> bool:
    """
    Determine if error_code is retryable.
    Rules:
    - If retry_on_codes list is empty: treat as retryable for any error_code (including None)
    - If list is not empty: only retry when error_code matches one of the entries
    """
    if len(retry_on_codes) == 0:
        return True
    if error_code is None:
        return False
    return error_code in set(retry_on_codes)

# core/orchestrator/flow_loader.py
# ==============================
# Flow Loader
# ==============================
"""
Load and validate FlowDef from YAML or JSON.

Requirements:
- Supports YAML (.yaml/.yml) and JSON (.json)
- Returns core.contracts.flow_schema.FlowDef
- Does NOT execute anything; pure parsing + validation
- No persistence and no environment reads

Intended usage:
- Orchestrator calls FlowLoader.load_from_path(...) to get a validated FlowDef
- Gateway/UI may call this to list flows and validate configs
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List, Union

from pydantic import ValidationError

from core.contracts.flow_schema import FlowDef

# ==============================
# Errors
# ==============================
class FlowLoadError(RuntimeError):
    """Raised when a flow cannot be loaded or validated."""


# ==============================
# Loader
# ==============================
class FlowLoader:
    """
    Flow loader for YAML/JSON flow definitions.

    Public methods:
    - load(product, flow) -> FlowDef (from products/<product>/flows/<flow>.yaml)
    - load_from_path(path) -> FlowDef
    - load_from_obj(obj) -> FlowDef
    """

    def __init__(self, *, products_root: Union[str, Path]) -> None:
        self.products_root = Path(products_root)

    def load(self, *, product: str, flow: str) -> FlowDef:
        path = self.products_root / product / "flows" / f"{flow}.yaml"
        return self.load_from_path(path)

    # ==============================
    # Public API
    # ==============================
    @staticmethod
    def load_from_path(path: Union[str, Path]) -> FlowDef:
        p = Path(path)
        if not p.exists():
            raise FlowLoadError(f"Flow file not found: {p}")

        suffix = p.suffix.lower()
        if suffix in {".yaml", ".yml"}:
            data = FlowLoader._read_yaml(p)
        elif suffix == ".json":
            data = FlowLoader._read_json(p)
        else:
            raise FlowLoadError(f"Unsupported flow format '{suffix}'. Use .yaml/.yml or .json")

        return FlowLoader.load_from_obj(data)

    @staticmethod
    def load_from_obj(obj: Dict[str, Any]) -> FlowDef:
        """
        Validate a raw dict into FlowDef.

        Raises FlowLoadError with readable validation messages.
        """
        try:
            normalized = FlowLoader._normalize(obj)
            return FlowDef.model_validate(normalized)
        except ValidationError as e:
            raise FlowLoadError(f"Flow validation error: {e}") from e

    # ==============================
    # File Readers
    # ==============================
    @staticmethod
    def _read_json(path: Path) -> Dict[str, Any]:
        try:
            raw = path.read_text(encoding="utf-8")
            data = json.loads(raw)
            if not isinstance(data, dict):
                raise FlowLoadError("Top-level JSON must be an object/dict.")
            return data
        except json.JSONDecodeError as e:
            raise FlowLoadError(f"Invalid JSON in {path}: {e}") from e

    @staticmethod
    def _read_yaml(path: Path) -> Dict[str, Any]:
        try:
            import yaml  # type: ignore
        except Exception as e:
            raise FlowLoadError(
                "PyYAML is required to load .yaml flows. Add 'pyyaml' to dependencies."
            ) from e

        try:
            raw = path.read_text(encoding="utf-8")
            data = yaml.safe_load(raw)
            if not isinstance(data, dict):
                raise FlowLoadError("Top-level YAML must be a mapping/dict.")
            return data
        except Exception as e:
            raise FlowLoadError(f"Invalid YAML in {path}: {e}") from e

    # ==============================
    # Normalization helpers
    # ==============================
    @staticmethod
    def _normalize(data: Dict[str, Any]) -> Dict[str, Any]:
        normalized = dict(data)
        flow_name = normalized.pop("name", None)
        flow_id = normalized.get("id") or flow_name
        if not flow_id:
            raise FlowLoadError("Flow missing required 'id'.")
        normalized["id"] = flow_id

        steps = normalized.get("steps")
        if not isinstance(steps, list):
            raise FlowLoadError("Flow missing 'steps' list.")
        normalized["steps"] = FlowLoader._normalize_steps(steps)

        if flow_name:
            metadata = dict(normalized.get("metadata") or {})
            metadata.setdefault("display_name", flow_name)
            normalized["metadata"] = metadata

        return normalized

    @staticmethod
    def _normalize_steps(steps: List[Any]) -> List[Dict[str, Any]]:
        normalized: List[Dict[str, Any]] = []
        for idx, raw in enumerate(steps):
            if not isinstance(raw, dict):
                raise FlowLoadError(f"Step {idx} is not a mapping/dict.")
            step = dict(raw)
            step_name = step.get("name")
            step_id = step.get("id") or step_name or f"step_{idx}"
            step["id"] = step_id
            normalized.append(step)
        return normalized

# core/orchestrator/hitl.py
# ==============================
# Human-in-the-Loop (HITL)
# ==============================
"""
HITL helpers:
- Create approval requests
- Pause runs (PENDING_HUMAN)
- Resolve approvals

Rules:
- No direct DB calls here. Use MemoryBackend interface only.
- Keep payload scrubbed BEFORE calling into here (ideally via governance hooks/security).
"""

from __future__ import annotations

import time
import uuid
from typing import Any, Dict, Optional

from core.memory.base import ApprovalRecord
from core.memory.router import MemoryRouter


def new_approval_id() -> str:
    return f"appr_{uuid.uuid4().hex}"


class HitlService:
    def __init__(self, memory: MemoryRouter) -> None:
        self.memory = memory

    def create_approval(
        self,
        *,
        run_id: str,
        step_id: str,
        product: str,
        flow: str,
        requested_by: Optional[str],
        payload: Dict[str, Any],
    ) -> ApprovalRecord:
        now = int(time.time())
        approval = ApprovalRecord(
            approval_id=new_approval_id(),
            run_id=run_id,
            step_id=step_id,
            product=product,
            flow=flow,
            status="PENDING",
            requested_by=requested_by,
            requested_at=now,
            payload=payload,
        )
        self.memory.create_approval(approval)
        return approval

    def resolve_approval(
        self,
        *,
        approval_id: str,
        decision: str,
        resolved_by: Optional[str] = None,
        comment: Optional[str] = None,
    ) -> None:
        self.memory.resolve_approval(
            approval_id,
            decision=decision,
            resolved_by=resolved_by,
            comment=comment,
        )

# core/orchestrator/state.py
# ==============================
# Orchestrator State
# ==============================
"""
Orchestrator state enums and helpers.

These are the canonical runtime statuses used by the orchestrator.
They intentionally reuse the platform contracts from core/contracts/run_schema.py.

Intended usage:
- Orchestrator sets RunStatus / StepStatus on RunRecord / StepRecord
- Gateway/UI reads these statuses for run tracking and approvals
"""

# ==============================
# Imports
# ==============================
from __future__ import annotations

from enum import Enum
from typing import FrozenSet

from core.contracts.run_schema import RunStatus as RunStatus  # re-export
from core.contracts.run_schema import StepStatus as StepStatus  # re-export

# ==============================
# Status Groups
# ==============================
RUN_TERMINAL: FrozenSet[RunStatus] = frozenset(
    {
        RunStatus.COMPLETED,
        RunStatus.FAILED,
        RunStatus.CANCELLED,
    }
)

RUN_ACTIVE: FrozenSet[RunStatus] = frozenset(
    {
        RunStatus.RUNNING,
        RunStatus.PENDING_HUMAN,
        RunStatus.PENDING_USER_INPUT,
    }
)

STEP_TERMINAL: FrozenSet[StepStatus] = frozenset(
    {
        StepStatus.COMPLETED,
        StepStatus.FAILED,
        StepStatus.SKIPPED,
    }
)

STEP_ACTIVE: FrozenSet[StepStatus] = frozenset(
    {
        StepStatus.RUNNING,
        StepStatus.PENDING_HUMAN,
        StepStatus.PENDING_USER_INPUT,
    }
)


class RunState(str, Enum):
    """Finite-state machine states for deterministic runs."""

    RUNNING = "RUNNING"
    PENDING_USER_INPUT = "PENDING_USER_INPUT"
    PENDING_APPROVAL = "PENDING_APPROVAL"
    FAILED = "FAILED"
    COMPLETED = "COMPLETED"


_RUN_STATUS_TO_STATE = {
    RunStatus.RUNNING: RunState.RUNNING,
    RunStatus.PENDING_USER_INPUT: RunState.PENDING_USER_INPUT,
    RunStatus.PENDING_HUMAN: RunState.PENDING_APPROVAL,
    RunStatus.FAILED: RunState.FAILED,
    RunStatus.COMPLETED: RunState.COMPLETED,
    RunStatus.CANCELLED: RunState.FAILED,
}

_ALLOWED_TRANSITIONS = {
    RunState.RUNNING: {RunState.PENDING_USER_INPUT, RunState.PENDING_APPROVAL, RunState.FAILED, RunState.COMPLETED},
    RunState.PENDING_USER_INPUT: {RunState.RUNNING, RunState.FAILED},
    RunState.PENDING_APPROVAL: {RunState.RUNNING, RunState.FAILED},
    RunState.FAILED: set(),
    RunState.COMPLETED: set(),
}


def to_run_state(status: RunStatus | str) -> RunState:
    if isinstance(status, RunStatus):
        return _RUN_STATUS_TO_STATE.get(status, RunState.FAILED)
    try:
        return _RUN_STATUS_TO_STATE.get(RunStatus(status), RunState.FAILED)
    except Exception:
        return RunState.FAILED


def is_valid_run_transition(current: RunStatus | str, target: RunStatus | str) -> bool:
    current_state = to_run_state(current)
    target_state = to_run_state(target)
    if current_state == target_state:
        return True
    return target_state in _ALLOWED_TRANSITIONS.get(current_state, set())


def require_valid_transition(current: RunStatus | str, target: RunStatus | str) -> None:
    if not is_valid_run_transition(current, target):
        raise ValueError(f"Invalid run state transition: {to_run_state(current).value} -> {to_run_state(target).value}")

# core/orchestrator/step_executor.py
# ==============================
# Step Executor
# ==============================
from __future__ import annotations

import time
from typing import Callable, Dict, Optional

from core.agents.registry import AgentRegistry
from core.contracts.agent_schema import AgentResult
from core.governance.hooks import GovernanceHooks
from core.contracts.flow_schema import StepDef, StepType, RetryPolicy
from core.contracts.plan_schema import PlanProposal
from core.contracts.run_schema import StepStatus
from core.contracts.tool_schema import ToolResult
from core.orchestrator.context import RunContext, StepContext
from core.orchestrator.templating import render_params
from core.tools.executor import ToolExecutor
from core.orchestrator.error_policy import evaluate_retry


class StepExecutor:
    """
    Executes a single StepDef using registered agents/tools.
    """

    def __init__(
        self,
        *,
        tool_executor: ToolExecutor,
        governance: GovernanceHooks,
        agent_registry: AgentRegistry = AgentRegistry,
        sleep_fn: Callable[[float], None] = time.sleep,
    ) -> None:
        self.tool_executor = tool_executor
        self.governance = governance
        self.agent_registry = agent_registry
        self.sleep_fn = sleep_fn

    def execute(
        self,
        *,
        run_ctx: RunContext,
        step_def: StepDef,
        step_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        resolved_step_id = step_id or step_def.id or "step"
        step_ctx = run_ctx.new_step(
            step_def=step_def,
            step_id=resolved_step_id,
            step_type=step_def.type.value if isinstance(step_def.type, StepType) else str(step_def.type),
            backend=step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend,
            target=step_def.agent or step_def.tool,
        )

        if step_def.type == StepType.TOOL:
            context = {"payload": run_ctx.payload, "artifacts": run_ctx.artifacts}
            rendered_params = render_params(step_def.params or {}, context)
            step_def = step_def.model_copy(update={"params": rendered_params})
            tool_result = self._execute_tool(step_ctx=step_ctx, step_def=step_def)
            if tool_result.ok:
                run_ctx.artifacts[f"tool.{step_def.tool}.output"] = tool_result.data
                run_ctx.artifacts[f"tool.{step_def.tool}.meta"] = tool_result.meta.model_dump(mode="json")
            return tool_result.model_dump(mode="json")

        if step_def.type == StepType.USER_INPUT:
            raise ValueError("user_input steps are orchestrator-managed; use OrchestratorEngine to pause/resume.")

        if step_def.type == StepType.AGENT:
            if not step_def.agent:
                raise ValueError("agent step missing 'agent' field")
            agent = self.agent_registry.resolve(step_def.agent)
            result: AgentResult = agent.run(step_ctx)
            if not result.ok:
                raise RuntimeError(result.error.message if result.error else "agent_failed")
            decision = self.governance.validate_agent_output(
                agent_name=step_def.agent,
                output=result.data or {},
                ctx=step_ctx,
            )
            if not decision.allowed:
                step_ctx.emit(
                    "agent_output_denied",
                    {"agent": step_def.agent, "reason": decision.reason, "details": decision.details},
                )
                raise RuntimeError(decision.reason or "agent_output_denied")
            step_ctx.emit(
                "agent.executed",
                {
                    "agent": step_def.agent,
                    "result": result.model_dump(mode="json"),
                },
            )
            run_ctx.artifacts[f"agent.{step_def.agent}.output"] = result.data
            run_ctx.artifacts[f"agent.{step_def.agent}.meta"] = result.meta.model_dump(mode="json")
            return result.model_dump(mode="json")

        if step_def.type == StepType.PLAN_PROPOSAL:
            if not step_def.agent:
                raise ValueError("plan_proposal step missing 'agent' field")
            agent = self.agent_registry.resolve(step_def.agent)
            result = agent.run(step_ctx)
            if not result.ok:
                raise RuntimeError(result.error.message if result.error else "plan_proposal_failed")
            decision = self.governance.validate_agent_output(
                agent_name=step_def.agent,
                output=result.data or {},
                ctx=step_ctx,
            )
            if not decision.allowed:
                step_ctx.emit(
                    "agent_output_denied",
                    {"agent": step_def.agent, "reason": decision.reason, "details": decision.details},
                )
                raise RuntimeError(decision.reason or "agent_output_denied")
            step_ctx.emit(
                "agent.executed",
                {
                    "agent": step_def.agent,
                    "result": result.model_dump(mode="json"),
                },
            )
            try:
                plan = PlanProposal.model_validate(result.data or {})
            except Exception as exc:
                step_ctx.emit("plan_validation_failed", {"error": str(exc)})
                raise RuntimeError("plan_validation_failed")
            plan_payload = plan.model_dump(mode="json")
            run_ctx.artifacts["plan.proposal"] = plan_payload
            step_ctx.emit("plan_proposed", {"plan": _summarize_plan(plan)})
            result = result.model_copy(update={"data": plan_payload})
            return result.model_dump(mode="json")

        if step_def.type == StepType.SUBFLOW:
            raise NotImplementedError("subflow execution is not implemented in v1")

        raise ValueError(f"Unsupported step type: {step_def.type}")

    def _execute_tool(self, *, step_ctx: StepContext, step_def: StepDef) -> ToolResult:
        if not step_def.tool:
            raise ValueError("tool step missing 'tool' field")

        params = step_def.params or {}
        attempt = 1
        retry_policy: Optional[RetryPolicy] = step_def.retry
        while True:
            step_ctx.emit("tool_call_attempt_started", {"attempt": attempt, "tool": step_def.tool})
            result = self.tool_executor.execute(tool_name=step_def.tool, params=params, ctx=step_ctx)
            if result.ok:
                step_ctx.emit("tool_call_succeeded", {"attempt": attempt, "tool": step_def.tool})
                return result

            error_code = None
            error_type = None
            if result.error:
                error_code = result.error.code.value if hasattr(result.error.code, "value") else str(result.error.code)
                error_type = result.error.code.name if hasattr(result.error.code, "name") else type(result.error).__name__
            step_ctx.emit(
                "tool_call_attempt_failed",
                {
                    "attempt": attempt,
                    "tool": step_def.tool,
                    "error_code": error_code,
                    "error_type": error_type,
                    "message": result.error.message if result.error else "tool_failed",
                },
            )

            decision = evaluate_retry(attempt_index=attempt, retry_policy=retry_policy, error_code=error_code)
            if not decision.should_retry:
                raise RuntimeError(result.error.message if result.error else "tool_failed")

            delay = decision.next_backoff_seconds
            step_ctx.emit(
                "tool_call_retry_scheduled",
                {"attempt": attempt + 1, "tool": step_def.tool, "delay_ms": int(delay * 1000)},
            )
            if delay > 0:
                self.sleep_fn(delay)
            attempt += 1

def build_step_context(run_ctx: RunContext, *, step_id: Optional[str], step_def: StepDef) -> StepContext:
    resolved_step_id = step_id or step_def.id or "step"
    return run_ctx.new_step(
        step_id=resolved_step_id,
        step_type=step_def.type.value if isinstance(step_def.type, StepType) else str(step_def.type),
        backend=step_def.backend.value if getattr(step_def.backend, "value", None) else step_def.backend,
        target=step_def.agent or step_def.tool,
    )


def _summarize_plan(plan: PlanProposal) -> Dict[str, Any]:
    step_ids = [step.step_id for step in plan.steps]
    return {
        "summary": plan.summary,
        "steps_count": len(plan.steps),
        "step_ids": step_ids[:10],
        "required_tools": plan.required_tools,
        "approvals_count": len(plan.approvals),
        "estimated_cost": plan.estimated_cost.model_dump(mode="json"),
    }

# core/orchestrator/templating.py
# ==============================
# Template Rendering
# ==============================
"""
Shared template rendering helpers for orchestrator/agents.

Supports strict rendering for message templates and lenient rendering for tool params.
"""

# Public surface; keep deterministic and minimal.
__all__ = ["render_template", "render_messages", "render_params"]

from __future__ import annotations

import json
import re
from typing import Any, Dict, Iterable, List


_TOKEN_RE = re.compile(r"\{\{\s*([a-zA-Z_][\w\.]*)\s*\}\}")


def render_template(template: str, context: Dict[str, Any]) -> str:
    def replace(match: re.Match[str]) -> str:
        path = match.group(1)
        value = _resolve_path(context, path)
        return _stringify(value)

    missing = _missing_keys(template, context)
    if missing:
        raise KeyError(f"Missing placeholders: {', '.join(sorted(missing))}")
    return _TOKEN_RE.sub(replace, template)


def render_messages(messages: Iterable[Dict[str, Any]], context: Dict[str, Any]) -> List[Dict[str, Any]]:
    rendered: List[Dict[str, Any]] = []
    for msg in messages:
        item = dict(msg)
        content = item.get("content")
        if isinstance(content, str):
            item["content"] = render_template(content, context)
        rendered.append(item)
    return rendered


def render_params(params: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
    def render(value: Any) -> Any:
        if isinstance(value, str):
            full_match = _TOKEN_RE.fullmatch(value)
            if full_match:
                try:
                    return _resolve_path(context, full_match.group(1))
                except KeyError:
                    return None

            def replace(match: re.Match[str]) -> str:
                try:
                    resolved = _resolve_path(context, match.group(1))
                except KeyError:
                    return ""
                return str(resolved) if resolved is not None else ""

            return _TOKEN_RE.sub(replace, value)
        if isinstance(value, dict):
            return {k: render(v) for k, v in value.items()}
        if isinstance(value, list):
            return [render(item) for item in value]
        return value

    return {k: render(v) for k, v in params.items()}


def _missing_keys(template: str, context: Dict[str, Any]) -> List[str]:
    missing: List[str] = []
    for match in _TOKEN_RE.finditer(template):
        path = match.group(1)
        try:
            _resolve_path(context, path)
        except KeyError:
            missing.append(path)
    return missing


def _resolve_path(context: Dict[str, Any], path: str) -> Any:
    parts = path.split(".")
    if not parts:
        raise KeyError(path)
    root = parts[0]
    if root not in context:
        raise KeyError(path)
    current: Any = context[root]
    remainder = parts[1:]
    if root == "artifacts":
        current, remainder = _resolve_dotted_key(current, remainder, path)
    for part in remainder:
        if isinstance(current, dict) and part in current:
            current = current[part]
        elif isinstance(current, list):
            try:
                idx = int(part)
            except ValueError as exc:
                raise KeyError(path) from exc
            if idx < 0 or idx >= len(current):
                raise KeyError(path)
            current = current[idx]
        else:
            raise KeyError(path)
    return current


def _resolve_dotted_key(current: Any, remainder: List[str], path: str) -> tuple[Any, List[str]]:
    if not isinstance(current, dict) or not remainder:
        return current, remainder
    for split in range(len(remainder), 0, -1):
        key = ".".join(remainder[:split])
        if key in current:
            return current[key], remainder[split:]
    raise KeyError(path)


def _stringify(value: Any) -> str:
    if isinstance(value, str):
        return value
    if isinstance(value, (dict, list)):
        return json.dumps(value, ensure_ascii=True, default=str)
    return str(value)

# core/tools/__init__.py


# core/tools/backends/__init__.py


# core/tools/backends/local_backend.py
# ==============================
# Local Tool Backend
# ==============================
"""
Local backend executes in-process Python tool implementations.

Rules:
- No persistence here.
- No direct logging of sensitive fields; executor handles redaction + tracing.
"""

from __future__ import annotations

from typing import Any, Dict

from core.contracts.tool_schema import ToolResult
from core.orchestrator.context import StepContext
from core.tools.base import BaseTool


class LocalToolBackend:
    name: str = "local"

    def run(self, tool: BaseTool, params: Dict[str, Any], ctx: StepContext) -> ToolResult:
        return tool.run(params=params, ctx=ctx)

# core/tools/backends/mcp_backend.py
# ==============================
# MCP Backend (Stub)
# ==============================
"""
MCP backend adapter surface (minimal).

v1:
- Defines list_tools() and call_tool()
- Disabled by default (executor must opt-in via config)
- Not implemented; returns clear error envelopes
"""

from __future__ import annotations

from typing import Any, Dict, List, Optional

from core.contracts.tool_schema import ToolError, ToolResult
from core.orchestrator.context import StepContext
from core.tools.base import BaseTool


class MCPBackend:
    name: str = "mcp"

    def __init__(self, *, server_name: Optional[str] = None) -> None:
        self.server_name = server_name

    def list_tools(self) -> List[Dict[str, Any]]:
        raise NotImplementedError("MCPBackend.list_tools not implemented in v1.")

    def call_tool(self, *, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        raise NotImplementedError("MCPBackend.call_tool not implemented in v1.")

    def run(self, tool: BaseTool, params: Dict[str, Any], ctx: StepContext) -> ToolResult:
        err = ToolError(
            code="MCP_BACKEND_NOT_IMPLEMENTED",
            message="MCP backend is disabled/not implemented in v1.",
            details={"server": self.server_name, "tool": getattr(tool, 'name', tool.__class__.__name__)},
        )
        return ToolResult(ok=False, data=None, error=err, meta={"backend": self.name})

# core/tools/backends/remote_backend.py
# ==============================
# Remote Tool Backend (Stub)
# ==============================
"""
Remote backend is a placeholder for calling tools hosted remotely (HTTP/gRPC).

v1:
- Provide clean interface
- Disabled by default
- Raises NotImplementedError with clear guidance
"""

from __future__ import annotations

from typing import Any, Dict, Optional

from core.contracts.tool_schema import ToolError, ToolResult
from core.orchestrator.context import StepContext
from core.tools.base import BaseTool


class RemoteToolBackend:
    name: str = "remote_agent"

    def __init__(self, *, endpoint: Optional[str] = None) -> None:
        self.endpoint = endpoint

    def run(self, tool: BaseTool, params: Dict[str, Any], ctx: StepContext) -> ToolResult:
        err = ToolError(
            code="REMOTE_BACKEND_NOT_IMPLEMENTED",
            message="RemoteToolBackend is not implemented in v1. Use local backend or implement HTTP/gRPC adapter.",
            details={"endpoint": self.endpoint, "tool": getattr(tool, "name", tool.__class__.__name__)},
        )
        return ToolResult(ok=False, data=None, error=err, meta={"backend": self.name})

# core/tools/base.py
# ==============================
# Base Tool Contract
# ==============================
"""
Base tool contract for master/.

Rules:
- Tools are executed ONLY through core/tools/executor.py (later phase).
- Tools do not read env vars directly. Config is injected.
- Tools return ToolResult from core/contracts/tool_schema.py (standard envelope).
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional

from core.contracts.tool_schema import ToolResult
from core.orchestrator.context import StepContext


class BaseTool(ABC):
    """
    Base class for all tools (core + products).

    Naming:
- Each concrete tool must provide a stable 'name' used in flows.
    """

    name: str

    def __init__(self, *, config: Optional[Dict[str, Any]] = None) -> None:
        self.config = config or {}

    @abstractmethod
    def run(self, params: Dict[str, Any], ctx: StepContext) -> ToolResult:
        """
        Execute the tool.

        params:
- validated/typed upstream (executor may validate later)

        ctx:
- step/run context, artifacts, trace hook
        """
        raise NotImplementedError

# core/tools/executor.py
# ==============================
# Tool Executor
# ==============================
"""
Central tool execution entrypoint.

Rules:
- ONLY place tools are invoked.
- Applies governance hooks (if available) before execution.
- Applies security redaction before emitting trace/log events.
- Never raises raw exceptions; always returns ToolResult envelope.

Execution routing:
- Default: local backend (runs python implementation)
- Optional: remote/mcp backends (disabled unless explicitly enabled by config)

Dependencies:
- ToolRegistry (resolve tool)
- Governance hooks (optional)
- Security redaction (optional)
- StepContext trace hook (optional)
"""

from __future__ import annotations

import time
from typing import Any, Dict, Optional

from core.contracts.tool_schema import ToolError, ToolErrorCode, ToolMeta, ToolResult
from core.governance.hooks import GovernanceHooks, HookDecision
from core.governance.security import SecurityRedactor
from core.orchestrator.context import StepContext
from core.tools.backends.local_backend import LocalToolBackend
from core.tools.backends.mcp_backend import MCPBackend
from core.tools.backends.remote_backend import RemoteToolBackend
from core.tools.registry import ToolRegistry


class ToolExecutor:
    def __init__(
        self,
        *,
        registry: ToolRegistry,
        hooks: Optional[GovernanceHooks] = None,
        redactor: Optional[SecurityRedactor] = None,
        backend_mode: str = "local",
        backend_config: Optional[Dict[str, Any]] = None,
    ) -> None:
        self.registry = registry
        self.hooks = hooks
        self.redactor = redactor or SecurityRedactor()
        self.backend_mode = backend_mode
        self.backend_config = backend_config or {}

        self._local = LocalToolBackend()
        self._remote = RemoteToolBackend(endpoint=self.backend_config.get("remote_endpoint"))
        self._mcp = MCPBackend(server_name=self.backend_config.get("mcp_server"))

    def execute(self, *, tool_name: str, params: Dict[str, Any], ctx: StepContext) -> ToolResult:
        started = time.time()

        # Resolve tool
        try:
            tool = self.registry.resolve(tool_name)
        except Exception as e:
            meta = self._meta(tool_name)
            err = ToolError(code=ToolErrorCode.NOT_FOUND, message=str(e), details={"tool": tool_name})
            return ToolResult(ok=False, data=None, error=err, meta=meta)

        safe_params = self.redactor.sanitize(params)

        if self.hooks is not None:
            decision = self.hooks.before_tool_call(tool_name=tool_name, params=params, ctx=ctx)
            if not decision.allowed:
                return self._deny(ctx, decision, tool_name)
        else:
            decision = None  # type: ignore[assignment]

        # Execute
        try:
            if self.backend_mode == "local":
                result = self._local.run(tool=tool, params=params, ctx=ctx)
            elif self.backend_mode == "remote_agent":
                result = self._remote.run(tool=tool, params=params, ctx=ctx)
            elif self.backend_mode == "mcp":
                enabled = bool(self.backend_config.get("enable_mcp", False))
                if not enabled:
                    err = ToolError(
                        code=ToolErrorCode.PERMISSION_DENIED,
                        message="MCP backend is disabled. Set configs to enable_mcp=true to use it.",
                        details={"tool": tool_name},
                    )
                    meta = self._meta(tool_name).model_copy(update={"backend": "mcp"})
                    result = ToolResult(ok=False, data=None, error=err, meta=meta)
                else:
                    result = self._mcp.run(tool=tool, params=params, ctx=ctx)
            else:
                err = ToolError(
                    code=ToolErrorCode.UNKNOWN,
                    message=f"Unknown tool backend_mode: {self.backend_mode}",
                    details={"backend_mode": self.backend_mode},
                )
                result = ToolResult(ok=False, data=None, error=err, meta=self._meta(tool_name))
        except Exception as e:
            err = ToolError(
                code=ToolErrorCode.BACKEND_ERROR,
                message="Tool execution failed.",
                details={"tool": tool_name, "exc": repr(e)},
            )
            result = ToolResult(ok=False, data=None, error=err, meta=self._meta(tool_name))

        elapsed_ms = int((time.time() - started) * 1000)

        # Emit trace/log event (sanitized)
        safe_result = self._safe_tool_result(result)
        self._emit(
            ctx,
            kind="tool.executed",
            payload={
                "tool": tool_name,
                "params": safe_params,
                "result": safe_result,
                "latency_ms": elapsed_ms,
                "backend": self.backend_mode,
            },
        )

        # Always return envelope
        meta = result.meta or self._meta(tool_name)
        updated_meta = meta.model_copy(update={"latency_ms": elapsed_ms, "backend": self.backend_mode})
        return result.model_copy(update={"meta": updated_meta})

    def _deny(self, ctx: StepContext, decision: HookDecision, tool_name: str) -> ToolResult:
        err = ToolError(
            code=ToolErrorCode.PERMISSION_DENIED,
            message=decision.reason or "Blocked by governance",
            details=decision.details,
        )
        payload = decision.to_payload()
        payload["tool"] = tool_name
        self._emit(ctx, kind="governance.decision", payload=payload)
        return ToolResult(ok=False, data=None, error=err, meta=self._meta(tool_name))

    def _emit(self, ctx: StepContext, *, kind: str, payload: Dict[str, Any]) -> None:
        ctx.emit(kind, self.redactor.sanitize(payload))

    def _safe_tool_result(self, result: ToolResult) -> Dict[str, Any]:
        """
        Avoid leaking sensitive data in trace/log channels.
        Keep structure stable for observability.
        """
        data = result.model_dump()
        redacted = self.redactor.redact_dict(data)
        return _strip_large_fields(redacted)

    def _meta(self, tool_name: str) -> ToolMeta:
        return ToolMeta(tool_name=tool_name, backend=self.backend_mode)


def _strip_large_fields(value: Any) -> Any:
    if isinstance(value, dict):
        cleaned: Dict[str, Any] = {}
        for key, val in value.items():
            if key in {"content_base64", "file_bytes", "bytes"}:
                continue
            if isinstance(val, dict) and key == "output_files":
                cleaned[key] = _strip_large_fields(val)
            else:
                cleaned[key] = _strip_large_fields(val)
        return cleaned
    if isinstance(value, list):
        return [_strip_large_fields(item) for item in value]
    return value

# core/tools/registry.py
# ==============================
# Tool Registry
# ==============================
"""
Global tool registry.

    Design:
    - Registry stores name -> tool factory (no shared instances)
- Products can register their tools during boot (gateway startup, or product loader)
- Resolution is by string name used in StepDef.tool
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional

from core.tools.base import BaseTool


ToolFactory = Callable[[], BaseTool]


@dataclass(frozen=True)
class ToolRegistration:
    name: str
    factory: ToolFactory
    meta: Dict[str, Any]


class ToolRegistry:
    """
    Global tool registry (class-level for simplicity).
    """

    _tools: Dict[str, ToolRegistration] = {}

    @classmethod
    def clear(cls) -> None:
        cls._tools.clear()

    @classmethod
    def register(
        cls,
        name: str,
        factory: ToolFactory | BaseTool,
        *,
        meta: Optional[Dict[str, Any]] = None,
        overwrite: bool = False,
    ) -> None:
        norm = _norm(name)
        if not overwrite and norm in cls._tools:
            raise ValueError(f"Tool already registered: {name}")

        if isinstance(factory, BaseTool):
            raise ValueError("ToolRegistry.register requires a factory to avoid shared state across runs.")
        actual_factory = factory

        cls._tools[norm] = ToolRegistration(name=norm, factory=actual_factory, meta=meta or {})

    @classmethod
    def resolve(cls, name: str) -> BaseTool:
        norm = _norm(name)
        reg = cls._tools.get(norm)
        if reg is None:
            raise KeyError(f"Unknown tool: {name}")
        return reg.factory()

    @classmethod
    def has(cls, name: str) -> bool:
        return _norm(name) in cls._tools

    @classmethod
    def list(cls) -> Dict[str, Dict[str, Any]]:
        return {k: {"name": v.name, "meta": v.meta} for k, v in cls._tools.items()}


def _norm(name: str) -> str:
    return name.strip().lower().replace(" ", "_")

# core/utils/__init__.py


# core/utils/product_loader.py
# ==============================
# Product Loader & Registration
# ==============================
"""
Deterministic discovery + registration for product packs.

Responsibilities (v1):
- Parse products/*/manifest.yaml into ProductMeta objects
- Load product-local config (config/product.yaml)
- Enumerate flows under products/<name>/flows/*.yaml
- Import products/<name>/registry.py safely and call register(registries)
"""

# Public surface for product discovery/registration; keep minimal and stable.
__all__ = [
    "discover_products",
    "register_enabled_products",
    "ProductCatalog",
    "ProductMeta",
    "ProductLoadError",
    "ProductRegistries",
]

from __future__ import annotations

import importlib.util
import logging
import sys
from dataclasses import dataclass, field
from pathlib import Path
from types import ModuleType
from typing import Any, Dict, List, Optional, Sequence

import yaml
from pydantic import BaseModel, Field, ValidationError, ConfigDict

from core.agents.registry import AgentRegistry
from core.agents.llm_reasoner import build as build_llm_reasoner
from core.config.schema import Settings
from core.tools.registry import ToolRegistry

logger = logging.getLogger(__name__)


# ==============================
# Manifest + Config Schemas
# ==============================
class UiPanel(BaseModel):
    id: str
    title: str


class UiConfig(BaseModel):
    enabled: bool = True
    nav_label: Optional[str] = None
    panels: List[UiPanel] = Field(default_factory=list)
    icon: Optional[str] = None
    category: Optional[str] = None


class ExposedApi(BaseModel):
    enabled: bool = True
    allowed_flows: List[str] = Field(default_factory=list)


class ProductManifest(BaseModel):
    name: str
    display_name: Optional[str] = None
    description: Optional[str] = None
    version: Optional[str] = None

    default_flow: Optional[str] = None
    exposed_api: ExposedApi = Field(default_factory=ExposedApi)
    ui_enabled: bool = True
    ui: UiConfig = Field(default_factory=UiConfig)
    flows: List[str] = Field(default_factory=list, description="Optional curated list of flow names")


class ProductConfigModel(BaseModel):
    model_config = ConfigDict(extra="allow")

    name: str
    defaults: Dict[str, Any] = Field(default_factory=dict)
    limits: Dict[str, Any] = Field(default_factory=dict)
    flags: Dict[str, Any] = Field(default_factory=dict)
    metadata: Dict[str, Any] = Field(default_factory=dict)


# ==============================
# Catalog Data Structures
# ==============================
@dataclass(frozen=True)
class ProductMeta:
    name: str
    display_name: str
    description: Optional[str]
    version: Optional[str]
    default_flow: Optional[str]
    expose_api: bool
    ui_enabled: bool
    flows: List[str]
    ui: UiConfig
    root_dir: str
    manifest_path: str
    config_path: str
    registry_path: str
    enabled: bool


@dataclass(frozen=True)
class ProductLoadError:
    product: Optional[str]
    path: str
    message: str


@dataclass(frozen=True)
class ProductRegistries:
    agent_registry: Any
    tool_registry: Any
    settings: Settings


@dataclass
class ProductCatalog:
    products: Dict[str, ProductMeta] = field(default_factory=dict)
    configs: Dict[str, ProductConfigModel] = field(default_factory=dict)
    flows: Dict[str, List[str]] = field(default_factory=dict)
    errors: List[ProductLoadError] = field(default_factory=list)

    def enabled_products(self) -> List[str]:
        return [name for name, meta in self.products.items() if meta.enabled]


# ==============================
# Discovery
# ==============================
def discover_products(settings: Settings, *, repo_root: Optional[Path | str] = None) -> ProductCatalog:
    """
    Discover product manifests/configs/flows under repo_root / products_dir.
    """
    root = Path(repo_root or settings.repo_root_path()).resolve()
    products_root = root / settings.products.products_dir
    catalog = ProductCatalog()

    if not products_root.exists():
        logger.warning("Products directory does not exist: %s", products_root)
        return catalog

    manifest_paths = sorted(products_root.glob("*/manifest.yaml"))

    enabled_allowlist = set(settings.products.enabled or [])
    auto_enable = settings.products.auto_enable or not enabled_allowlist

    for manifest_path in manifest_paths:
        product_root = manifest_path.parent
        try:
            manifest_data = _read_yaml(manifest_path)
        except Exception as exc:
            catalog.errors.append(
                ProductLoadError(product=None, path=str(manifest_path), message=str(exc))
            )
            continue
        if manifest_data is None:
            catalog.errors.append(
                ProductLoadError(product=None, path=str(manifest_path), message="manifest empty or unreadable")
            )
            continue
        try:
            manifest = ProductManifest.model_validate(manifest_data)
        except ValidationError as exc:
            catalog.errors.append(
                ProductLoadError(product=None, path=str(manifest_path), message=str(exc))
            )
            continue

        enabled = auto_enable or manifest.name in enabled_allowlist
        config_path = product_root / "config" / "product.yaml"
        try:
            config_data = _read_yaml(config_path)
        except Exception as exc:
            catalog.errors.append(
                ProductLoadError(product=manifest.name, path=str(config_path), message=str(exc))
            )
            continue
        if config_data is None:
            catalog.errors.append(
                ProductLoadError(
                    product=manifest.name,
                    path=str(config_path),
                    message="Missing product config (config/product.yaml)",
                )
            )
            continue
        if "name" not in config_data:
            config_data["name"] = manifest.name
        try:
            product_config = ProductConfigModel.model_validate(config_data)
        except ValidationError as exc:
            catalog.errors.append(
                ProductLoadError(product=manifest.name, path=str(config_path), message=str(exc))
            )
            continue

        registry_path = product_root / "registry.py"
        if not registry_path.exists():
            catalog.errors.append(
                ProductLoadError(
                    product=manifest.name,
                    path=str(registry_path),
                    message="registry.py is required for every product pack",
                )
            )
            continue

        flow_names = _list_flow_names(product_root / "flows")

        meta = ProductMeta(
            name=manifest.name,
            display_name=manifest.display_name or manifest.name,
            description=manifest.description,
            version=manifest.version,
            default_flow=manifest.default_flow,
            expose_api=bool(manifest.exposed_api.enabled),
            ui_enabled=bool(manifest.ui_enabled and manifest.ui.enabled),
            flows=flow_names or manifest.flows,
            ui=manifest.ui,
            root_dir=str(product_root),
            manifest_path=str(manifest_path),
            config_path=str(config_path),
            registry_path=str(registry_path),
            enabled=enabled,
        )

        catalog.products[manifest.name] = meta
        catalog.configs[manifest.name] = product_config
        catalog.flows[manifest.name] = flow_names

    return catalog


# ==============================
# Registration
# ==============================
def register_enabled_products(
    catalog: ProductCatalog,
    *,
    settings: Settings,
    agent_registry: Any = AgentRegistry,
    tool_registry: Any = ToolRegistry,
) -> List[ProductLoadError]:
    _register_core_agents(agent_registry)
    registries = ProductRegistries(
        agent_registry=agent_registry,
        tool_registry=tool_registry,
        settings=settings,
    )
    errors: List[ProductLoadError] = []

    for meta in catalog.products.values():
        if not meta.enabled:
            continue
        try:
            module = _import_registry_module(meta)
            register_fn = getattr(module, "register", None)
            if register_fn is None:
                raise AttributeError("registry.py must define register(registries: ProductRegistries)")
            register_fn(registries)
        except Exception as exc:  # pragma: no cover - error path
            err = ProductLoadError(product=meta.name, path=meta.registry_path, message=str(exc))
            errors.append(err)
            logger.warning("Failed to register product %s: %s", meta.name, exc)

    catalog.errors.extend(errors)
    return errors


def _register_core_agents(agent_registry: Any) -> None:
    has_fn = getattr(agent_registry, "has", None)
    if callable(has_fn):
        if not has_fn("llm_reasoner"):
            agent_registry.register(build_llm_reasoner().name, build_llm_reasoner)


# ==============================
# Helpers
# ==============================
def _read_yaml(path: Path) -> Optional[Dict[str, Any]]:
    if not path.exists():
        return None
    raw = path.read_text(encoding="utf-8").strip()
    if not raw:
        return None
    data = yaml.safe_load(raw)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError(f"YAML root must be a mapping: {path}")
    return data


def _list_flow_names(flows_dir: Path) -> List[str]:
    if not flows_dir.exists():
        return []
    names: List[str] = []
    for path in sorted(flows_dir.glob("*")):
        if path.is_file() and path.suffix.lower() in {".yaml", ".yml"}:
            names.append(path.stem)
    return names


def _import_registry_module(meta: ProductMeta) -> ModuleType:
    module_name = f"products.{meta.name}.registry_autoload"
    path = Path(meta.registry_path)
    spec = importlib.util.spec_from_file_location(module_name, path)
    if spec is None or spec.loader is None:
        raise RuntimeError(f"Cannot import registry module for {meta.name}")
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module
